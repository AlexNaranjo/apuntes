\section{Diferenciación}

\begin{defn}[Función\IS diferenciable]
 $F$ diferenciable en $\gor{a}$ si 
 
 $$\exists \text{ aplicación lineal L} \tlq \frac{F(\gx)-F(\ga)-L(\gx-\ga)}{||\gx-\ga||} \underbrace{\rightarrow}_{\gx\rightarrow\ga} 0$$
$$ = \lim_{\gor{h} \rightarrow \gor{0}} \frac{\md{F(\ga+\gor{h}) - F(\ga) - L\gor{h}}}{||\gor{h}||}$$

\end{defn}


\obs
\begin{itemize}
\item Si existe, $L$ es única.
\end{itemize}

\begin{proof}
Supongamos que existen $L_1,L_2$.
\[0=\lim_{\gor{h} \rightarrow \gor{0}} \frac{F(\gor{a}+\gor{h}) - F(\ga)-L_1\gor{h}}{||\gor{h}||} = \lim_{\gor{h} \rightarrow \gor{0}} \frac{F(\gor{a}+\gor{h}) - F(\ga)-L_2\gor{h}}{||\gor{h}||}\].

$$\text{ Sumando: } 0 = \lim_{\gor{h} \rightarrow \gor{0}} \frac{||F(\gor{a}+\gor{h}) - F(\ga)-L_1\gor{h}|| + ||F(\gor{a}+\gor{h}) - F(\ga) -L_2\gor{h}||}{||\gor{h}||}$$

\obs $||A-B|| = ||A+(-B)|| \leq ||A||+||B||$

$$\leq \lim_{\gor{h} \rightarrow \gor{0}} \frac{2\cdot\md{F(\ga + \gor{h}) - F(\ga)} + \md{L_1\gor{h}} + \md{L_2\gor{h}}}{\md{\gor{h}}}$$

Completar la contradicción.
\end{proof}

\paragraph{Notación: (Diferencia de $F$ en $\ga$)}

$$L\equiv DF(\ga)$$ 

\paragraph{Proposición:}
$$F \text{ diferenciable en } \ga \implies F \text{ continua en } \ga$$
\begin{proof}
 $$\lim_{\gor{h} \rightarrow \gor{0}} \frac{\md{F(\ga+\gor{h}) - F(\ga) - L\gor{h}}}{\md{\gor{h}}} = 0$$
 Esta es la definición de diferenciable. Para que este límite sea 0, el numerador tiene que tender a 0, por lo que $F(\ga+\gor{h}) - F(\ga) \rightarrow 0$
\end{proof}

\obs
$F$ diferenciable en $\ga$.

$\appl{F}{\real^N}{\real^M}$

Sabemos:
 $$0 = \lim_{\gor{h} \rightarrow \gor{0}} \frac{||F(\ga+\gor{h}) - F(\ga) - L\gor{h}}{||\gor{h}||} = 0 $$
 
 En particular (tomando  h = $t \gor{e_1})$

$$ \lim_{\gor{t} \rightarrow \gor{0}}\frac{a}{b} = \lim_{\gor{t} \rightarrow \gor{0}}\norm{\underbrace{\frac{1}{t} F(\ga+t\gor{e_1})-F(\ga))-L\gor{e_1}}_{\gor{W}(t)\in\real^N}}$$
 Tomando la componente k-esima:
\begin{gather*}
 0 = \mylim{t}{0}{\frac{F_K(a+te_i)-F_k(a)}{t} - L_{ki}}\\
 L_{ki} = \mylim{t}{0} {\frac{F_k(a+te_i) - F_k(a)}{t}} = \deriv{ F_k}{x_i}(\ga)
\end{gather*}

\paragraph{Nomenclatura: }
Aproximación lineal $\sim$ Diferencial.

Matriz jacobiana $\sim$ Jacobiana.

\begin{theorem}
 Matriz asociada a $DF(\ga) \equiv $ Matriz de las derivadas parciales de F.
 
 $$DF(\ga) \equiv \begin{pmatrix}
                \dpa{F_1}{x_1} & \cdot & \dpa{F_1}{x_N}\\
                \vdots& \ddots & \vdots\\
                \dpa{F_N}{x_1} & \cdot & \dpa{F_N}{x_N}
                \end{pmatrix}
$$
\end{theorem}

\begin{theorem}
 $F$ diferencialbe en $\ga \implies \exists \deriv{F_k}{x_i}(\ga), i=1,2,...,N \y k = 1,2,...,M$
\end{theorem}

El contraejemplo para demostrar $\Leftarrow$ es el mismo que en los límites a lo largo de rectas.

$f(x,y) = \left\{ \begin{matrix}

\frac{xy^2}{x+y^2} & (x,y) = (0,0) \\ 
0 & (x,y)=(0,0)
           
          \end{matrix}\right.
$
\paragraph{Comentarios sobre notación: }
\begin{itemize}
 \item $\appl{\delta}{\real}{\real^M}$. Utilizamos notación vectorial en vez de matricial (porque tendríamos una matriz columna).\\
 Ejemplo: la velocidad (en un instante de tiempo, un punto en el espacio).
 \item $\appl{F}{\real^N}{\real}$ (función escalar):

 COMPLETAR
 Se suele llamar vector gradiente.
 \item 
\end{itemize}

\subsection{Regla de la cadena: }
\paragraph{Derivada de una composición:\\}

COMPLETAR DIBUJITO

$\appl{F}{\real^N}{\real^M}$. 

$\appl{G}{\real^M}{\real^K}$.

$\appl{H=G\circ F}{\real^N}{\real^K}$.

$ \gx \in \real^N, \gy \in \real^M$

$F$ diferenciable en $\ga$, $G$ diferenciable en $F(\gor{a})$. Entonces $H=G\circ F$ es diferenciable en $\ga $.
Además la expresión matricial es:

$\underbrace{DH(\ga)}_{K\times N} = \underbrace{DG(F(\ga))}_{K\times M}\cdot \underbrace{DF(\ga)}_{M\times N}$
 
\obs
\paragraph{Notación de Leibniz:}

Para calcular 1 único elemento de la matriz diferencial (el de la fila $i$, columna $j$):

$$\deriv{H_i}{x_j}(\ga) = \displaystyle\sum_{k=1}^M \deriv{G_i}{y_k}\cdot\deriv{F_k}{x_j}$$
Con cuidado de $\displaystyle \deriv{G_i}{y_k}$ evaluado en $\displaystyle F(\ga)$ y $\displaystyle\deriv{F_k}{x_j}$ evaluado en $\ga$.

\paragraph{Aplicaciones y ejemplos:}
\begin{itemize}
 \item 
 $\appl{F}{\real^N}{\real}$
 
 $\appl{\sigma}{\real}{\real^N}$
 
 Sea $g\equiv F\circ \sigma \equiv \text{ Comportamiento de F a lo largo de la curva } \sigma, \appl{g}{\real}{\real}$.

$$g'(t_0) = DF(\sigma(t_0))D\sigma(t_0) = \underbrace{...}_{\text{Notación matricial}} = \underbrace{\pesc{\nabla F(\sigma(t_0))}{\sigma'(t_0)}}_{\text{Notación vectorial}}$$

 
 \item 
 $\sigma(t) = t\gor{b} + (1-t)\ga$
 
 $\appl{F}{\real^N}{\real^M}$
 
 $F\circ \sigma(t) \equiv g(t)$
 
 COMPLETAR
\end{itemize}

\subsection{Extensiones del teorema del Valor Medio}
\begin{itemize}
 \item Original:
 $\appl{f}{\real}{\real}$ diferenciable. 
 
 $f(b)-f(a) = f'(c)(b-a)$ para algún $c\in[a,b]$
 
 \item
  
 $F : \real^N  \longrightarrow \real$
 
 $\sigma(t)  = t(\gor{b})+(1-t)\gor{a}$
 
 $g  = F\circ \sigma$
 $\appl{g}{\real }{\real}$
 
 $F(\gor{b}-\gor{a}) = g(1)-g(0)  = g'(s) \text{ para algún }s\in[0,1]$
 
  
  Peeeeero...
  $$\appl{F}{\real^N}{\real^2}$$
  $$F(\gor{b})-F(\ga) = \begin{pmatrix}
                         \pesc{\nabla F_1(\gor{c_1}),{\gor{b}-\ga}}\\
                         \pesc{\nabla F_2(\gor{c_2}),\gor{b}-\ga}
                        \end{pmatrix}
$$
  Tenemos 2 $c$ distintos, uno para cada $f$, por lo que este teorema pierde sentido.
  
  \item Versión para funciones matriciales:
  
  \begin{theorem} [Extensión del valor medio]
  Sea $f \in C^1$ en un abierto que contenga $[a,b]$.
  $$\norm{F(\gor{b}-\ga)} \leq |||DF(\gor{c})|||\cdot\norm{\gor{b}-\ga}$$ 
  
  Siendo c un punto del segmento que une $\ga$ y $\gb$ en el que $|||DF(tb+(1-t)a)|||$ alcanza su máximo.
   
  \end{theorem}

  
  
  \begin{proof}
   i) $$\appl{f}{\real}{\real}$$
   $$f(\gor{b}-f(\ga) = g(1)-g(0) = \int_0^1g'(s)ds \text{ con } g(t) = f(tb+(1-t)a)$$
   
   ii)  $$\appl{h}{\real^N}{\real}$$
   $$h(\gor{b}-h(\ga) = g(1)-g(0) = \int_0^1g'(s)ds = \int_0^1 \pesc{\nabla h(s\ga+(1-s)\gor{b}),(\gor{b}-\ga)}$$
   $$g(t) = h(tb+(1-t)a)$$
   
   iii) $$\gor{G} = (G_1,...,G_M), G_i = \int_0^1H_i(t)dt$$
   Con $\gor{H} = (H_1(t),...,H_M(t))$
   
   
   $$\norm{\gor{G}}^2 = \pesc{\gor{G},\gor{G}} = \sum_{i=1}^M \left(\int_0^1 H_i(t)dt\right) \underbrace{\left(\int_0^1 H_i(s)ds\right)}_{G_i}$$
 
   $$\norm{\gor{G}}^2 = \displaystyle\int_0^1 \left(\underbrace{\sum_{i=1}^M G_i H_i (t)}_{\pesc{\gor{G},\gor{H}(t)}\leq \norm{\gor{G}}\cdot \norm{\gor{H}}}\right)dt$$
   Conclusión:
   $$\norm{\gor{G}}^2 \leq \displaystyle\int_0^1\norm{G}\cdot\norm{H(t)}dt$$
   
   iv) $\appl{F}{\real^N}{\real^M}$
   
   $\appl{F_i}{\real^N}{\real}$
   
   $\underbrace{F_i(\gor{b})-F_i(\ga)}_{G_i} = \displaystyle\int_0^1 \underbrace{\pesc{\nabla F_i (s\gor{b}+(1-s)\ga ),(\gor{b}-\ga)}}_{H_i(t)}dt$
   
   Por el apartado iii tenemos que:
   
   
   $$\gor{H}(t) = \begin{pmatrix}
                   H_1(t)\\
                   \vdots\\
                   H_M(t)
                  \end{pmatrix}
                = \begin{pmatrix}
                   \pesc{\nabla F_1(tb+(1-t)a),b-a}\\
                   \vdots\\
                   \pesc{\nabla F_M(tb+(1-t)a),b-a}
                  \end{pmatrix}
		= \left(DF(...)\right)\begin{pmatrix}
		                        b_1-a_1\\
		                        \vdots\\
		                        b_M-a_M
		                       \end{pmatrix}
$$

$$\norm{H(t)} = \norm{DF(...)(\gor{b}-\ga)} \leq \norm{DF}\cdot\norm{\gor{b}-\ga}$$


$$\norm{F(\gor{b})-F(\ga)} \leq \displaystyle\int_0^1 \norm{\nabla DF_i(tb+(1-t)a),b-a}dt$$

Aplicando: $A\gor{v} \leq |||A|||\cdot \norm{\gor{v}}$

$$\norm{F(\gor{b})-F(\ga)} \leq \displaystyle\int_0^1 |||DF(*)|||\cdot\norm{\gb-\ga}dt$$
$$= \norm{\gb - \ga} \displaystyle \int_0^1 |||DF(tb+(1-t)a)||| dt \leq |||DF(\gor{c})|||\cdot\norm{\gb-\ga}$$ 

Siendo c un punto del segmento que une $\ga$ y $\gb$ en el que $|||DF(tb+(1-t)a)|||$ alcanza su máximo.
   
Conclusión:

$$\norm{F(\gor{b})-F(\ga)} \leq \norm{DF}\cdot\norm{\gor{b}-\ga}$$
  \end{proof}

\end{itemize}

\paragraph{Aplicación:\\}

$\appl{F}{\real^N}{\real^M}, F \in C^1$, definida en un conjunto abierto y conexo.

$DF(\gx) \equiv 0, \forall \implies F \equiv $ cte.	

\subsection{Derivada direccional: }

$\appl{F}{\real^N}{\real^M}$ (escalar)

$\ga \sim$ Recta que pasa por $\ga$ con dirección $\gor{v}$.

$r(t) = \ga + t\gor{v}$. 

\obs
Como una recta tiene infinitos vectores directores (dependiendo de la longitud), siempre tomaremos vectores directores unitarios, con $\norm{\gor{v}} = 1$.


Vamos a estudiar: $g(t) = F(\ga + t\gor{v}) = F \circ r (t)$.

$t \sim 0 \dimplies \ga + t\gor{v} \sim \ga$
\begin{defn} [Regla de la cadena]
$$g'(0) = \displaystyle\lim_{h \rightarrow 0} \frac{g(h)-g(0)}{h} = \displaystyle\lim_{h \rightarrow 0} \frac{F(\ga+h\gor{v})-F(\ga)}{h} \equiv D_{\gor{v}}F(\ga)$$. 
\end{defn}

\obs
La existencia de $D_{\gor{v}}F(\ga), \forall \gor{v}\in \real^N$ NO garantiza que $F$ sea derivable.


Si sabemos que $F$ SÍ es diferenciable podemos usar la regla de la cadena obteniendo:

$D_{\gor{v}}F(\ga) = g'(0) = D(F\circ r)(0) = ... = \pesc{\nabla F(\ga),\gor{v}}$


\paragraph{Aplicación:} 
\begin{itemize}
 \item 
 Dirección de máximo crecimiento:

$D_{\gor{v}}F(\ga) = \pesc{\nabla F(\ga),\gor{v}}\leq \norm{\nabla F(\ga)}\cdot \underbrace{\norm{\gor{v}}}_{\equiv 1}$

Conclusión:
\begin{align*}
D_{\gor{v}}F(\ga) &\leq \norm{\nabla F(\ga)}\\
&\uparrow\\
\text{El }= \text{se obtien}&\text{e cuando }\gor{v} = \displaystyle \frac{\nabla F(\ga)}{\norm{\nabla F(\ga)}}. 
\end{align*}

 
 \item
 Vector perpendicular a los conjuntos de nivel
 
 $\appl{F}{\real^N}{\real^M}$
 
 $S = \{ \gx \in \real^N \tq F(\gx) = 0\}$ (Conjunto de nivel)
 
 $\ga \in S$
 
 Entonces: $\nabla F(\ga) \perp S$
\end{itemize}

\begin{theorem}[Derivadas parciales continuas implican función diferenciable]
Si existen todas las derivadas parciales y son continuas $\implies F$ diferenciable en $\ga$.
 
\end{theorem}

Contraejemplo de la no reciprocidad: $f(x) = x^2 sin\left(\frac{1}{x}\right)$

\begin{proof}
 $\appl{F}{\real^2}{\real}$
 
 $$¿\frac{\left|F(a+a,b+k) - F(a,b) - \deriv{F}{x}(a,b) h - \deriv{F}{y}(a,b)k\right|}{\norm{(h,k)}}\longrightarrow 0?$$
 
 Sumamos y restamos al numerador $F(a,b+k)$.
 
 $$\frac{\left|\left(\underbrace{F(a+h,b+k) - F(a,b+k)}_{\deriv{F}{x}(a+\tilde{h},b+k) \text{ para algún } 0 \leq\tilde{h}\leq h} -  \deriv{F}{x}(a,b) h\right) + \left(\underbrace{F(a,b+k) - F(a,b)}_{\deriv{F}{x}(a+h,b+\tilde{k}) \text{ si } 0 \leq\tilde{k}\leq k}- \deriv{F}{y}(a,b) k\right)\right|}{\sqrt{h^2+k^2}}$$

 $$0\leq\frac{\left|\deriv{F}{x}(a+\tilde{h},b+k)-\deriv{F}{x}(a,b)\right| \cdot |h| + \left| \deriv{F}{y}(a,b+\tilde{k}) - \deriv{F}{y}(a,b)\right| \cdot |k|}{\sqrt{h^2+k^2}} = (*)$$
 
 Aquí es donde aplicamos que las derivadas parciales son continuas: como $h$ y $k$ son pequeños (por lo tanto $\tilde{h}<h$ también lo será) los puntos $(a,b)$ y $(a+h,b+k)$ también están cerca, por lo que sus imágenes por la derivada estarán también cerca, es decir, $|\deriv{F}{x}(a,b)-\deriv{F}{x}(a+\tilde{h},b+k)| \rightarrow 0$ y lo mismo con la otra.
 
 Conclusión:
 
 \begin{align*}
0 \leq (*) \leq \varepsilon \frac{|h|+|k|}{\sqrt{h^2+k^2}} &\leq C\varepsilon \rightarrow 0 \text{ cuando } \gor{h},\gor{k} \rightarrow \gor{0}\\
&\uparrow\\
\text{El numerdador es la} & \text{ norma 1 y el denominador la norma 2.}\\
\text{En } \real^N &\text{ todas las normas son equivalentes.}  
 \end{align*}
 
 
\end{proof}


\subsection{Derivadas iteradas:}

\paragraph{Notación:}

$\deriv{}{y}\left(\deriv{f}{x}\right) \equiv \deriv{^2f}{x \partial y}$

\begin{theorem}[Euler (orden de las derivadas)]
Si las derivadas segundas son continuas, entonces:
$$\deriv{^2f}{x_i\partial x_j} = \deriv{^2 f}{x_j \partial x_i}$$
\end{theorem}

\input{CALII/maximos_minimos_calculo2.tex}

\subsection{Desarrollo de Taylor}

$\appl{F}{\real^N}{\real}. F\in C^k$\footnote{F es k veces derivable}. 

Queremos desarrolar $F$ alrededor de $\ga \in \real^N$.

Dimensión 1) $g(x) = g(0) + g'(0)x + \frac{g''(0)}{2!}x^2 + ... + \frac{g^{k)}(0)}{k!}x^k + \underbrace{error}_{\frac{g^{k+1)}(s)}{(k+1)!}x^{(k+1)}}$

$F(\ga + \gor{h}) = F(\ga) + ...$

Más dimensiones) 

Tomamos $g(t) \equiv F(t(\ga + \gor{h}) + (1-t)\ga)$. Así hemos reducido el cálculo a dimensión 1.

%\begin{gather}

$$g'(t) = \pesc{\nabla F(a+th),h} = \sum_{i=1}^N \deriv{F}{x_i}(a+th)\cdot h_i$$
$$g'(0) = \pesc{\nabla F(\ga), \gor{h}}$$
$$g''(t) = \sum_{i=1}^N\left(\sum_{j=1}^N \deriv{}{x_j}\deriv{F}{x_i}(\ga+\gor{h})\cdot{h_j}\right)h_i = \sum_{i,j = 1}^N \deriv{^2F}{x_i \partial x_j}(\ga+t\gor{h})h_ih_j $$

Iterando:

$$\frac{g^{s)} (0)}{s!} = \frac{1}{s!}\sum_{i_1,i_2,...,i_s=1}^N \frac{\partial^s F}{\partial x_{i_1},x_{i_2},...,x_{i_s}}
$$%\end{gather}
                                                                                          
El hesiano aparece en:
$$g''(t) = \sum_{i=1}^N\left(\sum_{j=1}^N \deriv{}{x_j}\deriv{F}{x_i}(\ga+\gor{h})\cdot{h_j}\right)h_i = \sum_{i,j = 1}^N \deriv{^2F}{x_i \partial x_j}(\ga+t\gor{h})h_ih_j = ... =
$$$$\frac{1}{2} (h_1,...,h_N) \cdot \left(D^2F(\ga)\right) \cdot \begin{pmatrix}
h_1\\
\vdots\\
h_N                                                                                                                                                                                                                                       \end{pmatrix}
$$

\paragraph{Desarollo de Taylor en general:}

$$F(\gor{a}+\gor{h}) = F(\ga) + \pesc{\nabla F(\ga),\gor{h}} + \frac{1}{2} \gor{h}^T D^2F(\ga)\gor{h} + \frac{1}{3!}\sum_{i,j,k=1}^N \frac{\partial^3F}{\partial x_k,\partial x_j, \partial x_i} (\ga) h_kh_jh_i + $$

\begin{theorem}
 $$\frac{|F(\ga+\gor{h} - P_{s,a}(\gor{h})|}{\norm{\gor{h}}^s} \rightarrow 0, \text{ Cuando } \gor{h} \rightarrow 0$$
 Además $P_{s,a}(\gor{h}$ es el único polinomio de orden S que hace que el límite sea 0).
\end{theorem}

Con estos conocimientos son posibles de realizar todos los ejercicios de la hoja de problemas 2