\section{Lenguaje de las formas diferenciales}

\paragraph{0-formas}
\index{Formas\IS 0}

Son funciones escalares definidas en un abierto de $\real^n$
\[\appl{f}{\Omega\subset\real^N}{\real}\]

Operaciones habituales:
\begin{itemize}
\item Suma: sí
\item Producto: sí
\item Composiciones: no (porque no cuadran las dimensiones)
\end{itemize}

\paragraph{1-formas}
\index{Formas\IS 1}

Sea $\mathcal{C} = \{e_1,e_2,...,e_n\}$ la base canónica en $\real^N$.

Sea $L$ una aplicación lineal
\[\appl{L}{\real^N}{\real}\]

Que recordamos que cumplen:
\[ L(\gx+\gy) = L(\gx)+L(\gy); L(\lambda\gx) = \lambda L(\gx)\]

Definimos $\gy\in\real^N \leadsto \gy = \displaystyle\sum_1^n y_i e_i$, con lo que \[L(\gy) = \sum y_i L(e_i)\]

Entonces \[\left.\begin{array}{cc}
v_i = L(e_i)\\
y_i = P_i(\gy)
\end{array}\right\} \rightarrow L(\gy) = \sum_i v_iP_i(y)\]

Siendo $P_i$ las proyecciones, una base del espacio dual.

\textbf{Notación:}

$P_i \equiv dx_i$.

$dx_i[\gy] \equiv P_i(\gy) = y_i$

Entonces, dado un $\gv$ podemos construir 
\[L \equiv \sum_i^N v_idx_i\]

\[L[\gy] = \sum_i^N v_idx_i[\gy] = \sum_i^N v_iy_i\]

\begin{defn}[1-forma]
\[\omega(\gx)= \sum_1^N F_i(\gx) dx_i\]

\begin{itemize}
\item Se evalúa en $\gx\in\real$
\item Actúa sobre $\gy\in\real^N$ 
\end{itemize}

Es decir, \[\omega(\gx)[\gy] = \left(\sum F_i(\gx)dx_i\right)[\gy] = \sum F_i(\gx)dx_i[\gy] = \sum F_i(\gx)y_i\]
\end{defn}

Indicaremos con paréntesis el punto en el que estamos evaluando, y con corchetes el punto en el que estamso actuando.

\textbf{Operaciones:}
\begin{itemize}
\item Sumar: sí (lo razonable)
\item Multiplicar: por una función escalar sí está definida.
\end{itemize}


\paragraph{Ejemplo:}

Supongamos $f$ una función escalar (una 0-forma).

\[\grad f(\gx) = \left( \dpa{f}{x_i}(\gx)\right)\, i=1,...,N\]

Nos podemos construir una 1-forma desde el gradiente

\[\dpa{f}{x_i}(\gx)dx_i \]

A esta 1-forma en particular la llamaremos $df(\gx)$.

¿Utilidad? Ya la veremos, pero es una forma de escribir el producto escalar.
\[\pesc{\grad f(\gx),\gy} = df(\gx)[\gy]\]


\paragraph{2-formas}
\index{Formas\IS 2}

Punto de partida: Aplicaciones \textbf{bilineales alternadas}

\[\appl{\Phi}{\real^N\x\real^N}{\real}\]

Que cumplen \begin{itemize}
\item $\Phi([\gu,\gv]) = - \Phi([\gv,\gu]) \implies \Phi(\gu,\gu)=0$
\item $ \Phi([\gu+\gv,\gw]) = \Phi ([\gu,\gw]) + \Phi([u,w])$
\item$\Phi([\lambda \gu,\gv]) = \lambda \Phi([\gu,\gv])$
\end{itemize}

Consecuencias:

\begin{itemize}
\item $\Phi(\gor{r}, \gor{s}+\gor{t}) = \Phi(\gor{r}+\gor{s}) + \Phi(\gor{r}+\gor{t})$
\item $\Phi(\gu,\mu\gv) = \mu\Phi(\gu,\gv)$
\end{itemize}


\paragraph{Ejemplo} en $\real^3$ para facilitar las cuentas.

\[\Phi(\gu,\gv) = \Phi(u_1e_1+u_2e_2+u_3e_3,v_1e_1+v_2e_2+v_3e_3)\]
Aplicando las propiedades anteriores obtenemos:

\begin{gather*}
\overbrace{u_1v_1\Phi(e_1,e_1)}^{\equiv 0} + u_1v_2\Phi(e_1,e_2) + u_1v_3+\Phi(e_1,e_3)+\\
u_2v_1+\Phi(e_2,e_1)+u_2v_2+\Phi(e_2,e_2)+u_2v_3+\Phi(e_2,e_3)+\\
u_3v_1\Phi(e_3,e_1)+u_3v_2+\Phi(e_3,e_2)+u_3v_3+\Phi(e_3,e_3) = \\
\underbrace{(u_1v_2-u_2v_1)}_{\left|\begin{matrix}
u_1&u_2\\v_1&v_2
\end{matrix}\right|}\overbrace{\Phi(e_1,e_2)}^{C_1}+(u_1v_3-u_3v_1)\Phi(e_1,e_3)+(u_2v_3-u_3v_2)\Phi(e_2,e_3)
\end{gather*}

Hemos demostrado que \[\Phi(\gu,\gv) = C_1B_{12}(\gu,\gv) + C_2B_{13}(\gu,\gv) + C_3B_{23}(\gu,\gv)\]

\subparagraph{Notación:} $B_ij = dx_i\y dx_j$

\[dx\y dx_j [\gu,\gv] = \det \begin{pmatrix}
u_i&u_j\\v_i&v_j
\end{pmatrix} = \det \begin{pmatrix}
dx_i[\gu]&dx_j[\gu]\\dx_[\gv]&dx_j[\gv]
\end{pmatrix}\]

\begin{defn}[2-forma]
\[\beta = \sum_{i,j=1}^N F_i(\gx) dx_i\y dx_j\]
\begin{itemize}
\item Se evalúan en puntos $x\in\real^N$
\item Actúan sobre pares de vecotres $[\gu,\gv]\in\real^N\x\real^N$.
\end{itemize}

Es decir:

\[\beta(\gx)[\gu,\gv] = \sum F_{ij}(\gx) dx_i\y dx_j[\gu,\gv] = \sum F_{ij} \det \begin{pmatrix}
u_i&v_i\\u_j&v_j
\end{pmatrix}\]

\emph{Ojo} El cambio del orden (en el determiante)es aposta por la segunda propiedad de las 2 formas
\end{defn}


\subsubsection{K-Forma}

Vamos a dar una definición general de una k-forma.

Elementos básicos:
\[dx_{i_1} \y dx_{i_2}\y...\y dx_{i_k}[\gu^1,\gu^2,...,\gu^k] = \det\begin{pmatrix}
u_{i_1}^1 & ... & u_{i_k}^1\\
\vdots & \ddots & \vdots\\
u_{i_1}^k & ... & u_{i_k}^k
\end{pmatrix}\]

\paragraph{K-forma}

\[
\sum_{i_1,...,i_k=1}^N F_{i_1,...,i_k}(\gx)dx_{i_1} \y ... \y dx_{i_k}
\]

\begin{itemize}
\item Se evalúan en puntos $\gx\in\real^N$
\item Actúa sobre grupos de $K$ vectores.
\end{itemize}

\obs $i_j = i_s \implies dx_{i_j}\y dx_{i_s} = 0$

Esto nos dice que en $\real^N$, teniendo $K$-formas (con $K<N$) tenemos $\comb{N}{K}$ combinaciones distintas.

\obs Si $K>N$ y $\omega$ es una $k-forma \implies \omega \equiv 0$


\paragraph{Ejemplo:} En $\real^3$.

\begin{itemize}
\item 0-forma $\leadsto f(x,y,z) = 0$
\item 1-forma $\leadsto f_1(x,y,z)dx + f_2(x,y,z)dy + f_3(x,y,z)dz$
\item 2-forma $\leadsto g_1(x,y,z)dydz + g_2(x,y,z)dzdx + g_3(x,y,z)dxdy$
\item 3-formas $\leadsto h(x,y,z)dxdydz$
\end{itemize}

\index{Orden cíclico}
\emph{Ojo} Al cambio en la 2-forma, que es $dzdx$. Esto es para seguir el \textbf{orden cíclico} (por temas de la orientación). Esto es $x\to y \to z \to x$


\obs Las funciones escalares las podemos interpretar como 0-formas y como 3-formas.

Los campos vectoriales los podemos interpretar como 1-formas y también como 2-formas.

\paragraph{Notación}
Para escribir un conjunto de subíndices $\{i_1,i_2,...,i_k\} \equiv I$

También acortaremos  $dx_{i_1} \y dx_{i_2} \y ... \y dx_{i_k} \equiv dx_I$. 

La definición quedaría $\displaystyle \sum_I F_I(\gx)dx_I$

\subsection{Operaciones}
Siempre se puede multiplicar por 0-formas y sumar (formas del mismo orden). Estas operaciones son triviales porque son operaciones internas.

Vamos a definir las operaciones externas:

\begin{defn}[Producto \IS exterior (de k-formas)]
Sea \[\omega = \sum_I F_I dx_I (k-forma\in\real^N)\]
\[\beta = \sum_J G_j dx_J (s-forma\in\real^N)\]

\[\omega\y\beta = \sum_{I,J} F_IG_J dx_I\y dx_J (k+s-forma)\]
\end{defn}

\obs Si $K+S>N \implies \omega\y\beta=0$


\paragraph{Ejemplo} $\real^3$

Sea \[\omega = f_1(x,y,z)dx + f_2(x,y,z)dy + f_3(x,y,z) dz\]
\[\beta= g_1(x,y,z)dx + g_2 (x,y,z) dy + f_3 (x,y,z) dz\]

Vamos a calcular $\omega\y\beta$

\[
\omega\y\beta  = f_1g_1dx\y dx + f_1g_2dx\y dy + f_1g_3dx\y dz + f_2g_1dy\y dx + f_2g_2dy\y dy + f_2g_3dy\y dz+ f_3g_1dz\y dx+f_3g_2dz\y dy+f_3g_3dz\y dz
\]
Tachamos los que sean 0 ($dx\y dx = 0$) y tenemos cuidado con el orden cíclico.

\[
(f_2g_3-f_3g_2)dy\y dz + (f_3g_1-f_1g_3)dz\y dx + (f_1g_2 - f_2g_1) dx \y dy
\]

Partiendo de 2 campos vectoriales que eran 1-formas hemos llegado a una 2-forma. 

\obs Acabamos de llegar al producto vectorial de $\real^3$ 

\[\overrightarrow{F}\x\overrightarrow{G} = 
\left((f_2g_3-f_3g_2),(f_3g_1-f_1g_3),(f_1g_2 - f_2g_1)\right)\]

\begin{defn}[Diferencial \IS exterior (de k-formas)]

\[d(\sum_I F_i(\gx)dx_I) = \sum_I \underbrace{dF_I}_{1-forma} \overbrace{\y}^{Prod.ext} \underbrace{dx_I}_{k-forma}\]
\end{defn}

\paragraph{Ejemplo} en $\real^3$

Sean $G = (g_1,g_2,g_3)$

$\omega = $

Vamos a calcular $d\omega$

\[d\omega dg_1\y dy\y dz + dg_2 \y dz\y dz + dg_3 \y dx \y dy = COMPLETAR = \dpa{g_1}{y} + \dpa{g_2}{y}+\dpa{g_3}{z}dx\y dy\y dz\] ¡Que es la divergencia!

\paragraph{Ejemplo 2}

\[d(F_1 dx + F_2dx+F_3dx)\]
\[ = dF_1\y dx + dF_2 \y dy + dF_3\y dz\]
\[\left(\dpa{F_1}{x}dx + \dpa{F_1}{x}dy + \dpa{F_1}{x}dz +
\dpa{F_2}{x}dx + \dpa{F_2}{x}dy + \dpa{F_2}{x}dz+
\dpa{F_3}{x}dx + \dpa{F_3}{x}dy + \dpa{F_3}{x}dz\right)\]
\[\left(\dpa{F_3}{y} - \dpa{F_2}{z} \right)dy\y dz + \left(\dpa{F_1}{z} - \dpa{F_3}{dx}\right)dz \y dx + \left(\dpa{F_2}{x} - \dpa{F_1}{y}\right) dx \y dy\]

Nos queda un campo de la forma:

\[\left(\dpa{F_3}{y} - \dpa{F_2}{z} \right) ,\left(\dpa{F_1}{z} - \dpa{F_3}{x}\right),\left(\dpa{F_2}{x} - \dpa{F_1}{y}\right)\]
Que es el rotacional.

\paragraph{Conclusión}
Tenemos un campo en $\real^3$ que podemos interpretar como 1-forma o como 2-forma. 

\begin{itemize}
\item La diferencial exterior de un campo interpretado como 1-forma tendremos la 2-forma asociada a la divergencia.

\item La diferencial exterior de un campo interpretado como 2-forma tendremos la 3-forma asociada al rotacional.

\item El producto exterior de 2 campos interpretados como 2-formas nos da el campo aosciado al producto vectorial (o algo parecido. Revisar)

\item ¿Cómo tengo que interpretar los campos para conseguir un producto escalar?

\end{itemize} 


\paragraph{Propiedades}
\begin{itemize}
\item $d(\omega + \beta) = d\omega + d\beta$
\item $\omega = \sum_I F_i dx_i$ una k-forma

$f\leadsto 0-forma$

$f\omega = \sum_I fF_Idx_I$

$d(f\omega) = \sum_I d(fF_I) \y dx_I$, donde $d(fF_I) = \sum_{j=1}^N \dpa{f}{x_j}dF_Ix_j + \sum_{j=1}^N f\dpa{F_I}{x_j}dx_j$

Es decir, tenemos:

Revisar
\begin{gather*}
\sum_{I,J} \dpa{f}{x_j} F_Idx_j\y dx_i + \sum_{I,J} f\dpa{F_I}{x_j}dx_j\y dx_I\\
 = \sum_{I,J} \underbrace{\dpa{f}{x_j}dx_j}_{\equiv df} \y F_Idx_I + \underbrace{\sum_{I}\underbrace{\left(\sum_J \dpa{F_I}{x_j}dx_j\right)}_{dF_I}) \y dx_I }_{d\omega}\\
 = \sum_I df\y F_I dx_I \y d\omega = \\
 \underbrace{df \y \sum_IF_Idx_I}_{\omega} + d\omega 
\end{gather*}
\paragraph{Conclusión} Hemos llegado a demostrar que el producto de la derivada es primero derivado por ...

\[d(f\omega) = df\y\omega + fd\omega\]
\begin{itemize}
\item df $\to$ 1-forma
\item $\omega \to $ k-forma
\item $f \to$ 0-forma
\item $d\omega$ k+1-forma.
\end{itemize}

\item $\omega  =\sum f_idx_i; \beta = \sum_j  g_jx_j$

\begin{gather*}
\dpa(\omega \y \beta) = d\left(\sum_{i,j=1}^N f_ig_jdx_y\y dx_j\right)\\
=\sum_{i,j=1}^N d(f_ig_j) \y dx_i\y dx_j\\
= \sum_{i,j=1}^N \left(\sum_{k=1}^N \dpa{(f_ig_j)}{x_k} dx_k\right)\y dx_i\y dx_j\\
=\sum_{i,j,k=1}^N \dpa{f_i}{x_k}g_j + f_i\dpa{g_j}{x_k}dx_k\y dx_i\y dx_j\\
= \sum_{i,j,k=1}^N \dpa{f_i}{x_k}g_j dx_k\y dx_i\y dx_j + \sum_{i,j,k=1}^N f_i\dpa{g_j}{x_k} dx_k\y dx_i\y dx_j\\
\text{Vamos a intentar encontrar }\omega,\beta\\
= \sum_{i,j,k=1}^N \dpa{f_i}{x_k}dx_k\y dx_i\y(g_jdx_j) + \sum_{i,j,k=1}^N\dpa{g_j}{x_k}dx_k\y f_idx_i \y dx_j \\
= \sum_{i,j} \dpa{f_j}{x_k}dx_k\y dx_i \y \underbrace{\left(\sum_j g_jdx_j\right)}_{\beta} + \sum_{j,k}  \dpa{g_j}{x_k}dx_k\y \underbrace{\left(\sum_i f_idx_i\right)}_{\omega} \y dx_j\\
= \underbrace{\sum_i \underbrace{\left(\sum_k \dpa{f_i}{x_k}dx_k\right)}_{df_i}\y dx_j\y \beta }_{d\omega\y \beta} - \underbrace{\sum_{j,k} \omega \y \dpa{g_j}{x_k}dx_k \y dx_j}_{d\beta}
\end{gather*}

Si $\omega,\beta$ 1-formas $\implies d(\omega \y \beta) = d\omega \y \beta - \omega \y d\beta$.

\item $\omega$ k-forma, $\beta$ s-forma.
Repitiendo las cuentas hasta cuando llegamos a intercambiar algo, que nos queda \[d\omega \y \beta + (-1)^k \omega \y d\beta\]
\index{Derivada de producto exterior de k-formas}

\item $\omega$ k-forma con coeficientes $C^2$. Entonces $d(d\omega) \equiv 0$.

La prueba es: no la pienso copiar ni de coña.
\end{itemize}


\subsubsection{Pull-back}
Entramos en como transformar k-formas de $\real^N$ a $\real^M$. Partimos de la base de que existe una transformación $T$ que va de $\real^N \to \real^M$, tal que $T(s)=x$ y buscamos una $T^{\ast} \tlq \real^M\to\real^N$.

En caso de 0-formas, el \emph{pull-back} es lo mismo que la composición.

Supongamos que tenemos una $\omega$ k-forma en $\real^N$.
Para construir $T^{\ast}$:

tenemos $\gor{s} \in \real^N, \gv_1,\gv_2,..,\gv_k$ vectores en $\real^N$.

Queremos definir $T^{\ast}\omega$ en términos de $T$ y $\omega$.

\[
(T^{\ast}\omega)(\underbrace{\gor{s}}_{\in\real^N}) [\underbrace{\gv_1}_{\in\real^N},...,\gv_k] = \omega(\underbrace{T(s)}_{\in\real^M}) [\underbrace{DT(s)\gv_j}_{\in\real^M}]
\]

\obs


\[\omega(T(s)) [DT(s)\gv]\equiv \sum f_i(T(s))dx_i[DT(s)\gv]\]

\[DT(s) = \begin{pmatrix}
\dpa{T_1}{s_1}(s) & ... & \dpa{T_1}{s_N}\\
\vdots & \ddots & \vdots \\
\dpa{T_M}{s_1} & \dots & \dpa{T_M}{s_N}
\end{pmatrix} \cdot \begin{pmatrix}
v_1\\
\downarrow\\
v_N
\end{pmatrix}\]

¿Que significa $dx_i[DT(s)\gv]$? Vamos a ver que pasa con el producto de una de las filas de la matriz.

\[dx_i[DT(s)\gv] = \dpa{T_i}{s_1}v_1 + ... + \dpa{T_i}{s_N}v_n\]
Podemos darnos cuenta de que $v_1 = ds_1[\gv]$. Con esto tenemos:
\[\underbrace{\left(\dpa{T_i}{s_1}ds_1 + ... + \dpa{T_i}{s_N}ds_N \right)}_{dT_i}[\gv]\]


\paragraph{Ejemplos}

\subparagraph{Ej 1)} Sea  $f(x)dx_i$ una 1-forma de la que queremos calcular el \emph{pull-back}

\[T^{\ast}(fdx_i)(s)[v] = f(T(s)) dx_1[DT(s)\gv]\]
Supongamos $f\equiv 1$
\[T^{\ast}(fdx_i)(s)[v] = dx_1[DT(s)\gv] = dT_i[\gv]\]
\textbf{Conclusión: } $T^{\ast}dx_i = dT_i$.

\subparagraph{Ej 2)} Sea $\omega = \sum_i f_i dx_i$ una 1-forma de la que queremos calcular el \emph{pull-back}

\[ 
 (T^{\ast} \omega )(s)[\gv]= \sum_i f_i(T(s))dx_i [DT(s)\gv] = \sum_if_i(T(s)) dT_i[\gv] = T^{\ast} (\sum_i f_idx_i) = \sum_i f_i \circ T dT_i
\]

\textbf{Conclusión: } $T^{\ast} (\sum_i f_idx_i) = \sum_i f_i \circ T dT_i$

\subparagraph{Ej 3)} ¿Cómo se comporta con el producto exterior? Vamos a trabajar con $f\equiv 1$.

\[
T^{\ast}(dx_i\y dx_j) [\gu,\gv] = dx_i\y dx_j \left[DT(s)[\gu], DT(s)[\gv]\right] =\]\[ \left|\begin{matrix}
dx_i[DT(s)\gu] & dx_j[DT(s)\gu] \\
dx_i[DT(s)\gv] & dx_j[DT(s)\gv] 
\end{matrix}\right| = \left| \begin{matrix}
dT_i[\gu] & dT_j[\gu]\\
dT_i[\gv] & dT_j[\gv]
\end{matrix}\right| = (1) = dT_i \y dT_j [\gu,\gv]
\]
(1) = Por las propiedades del producto exterior de 1-formas.

\textbf{Conclusión: } $T^{\ast} (dx_i \y dx_j) = dT_i \y dT_j$.

\subparagraph{Ej 4)} ¿Qué pasa cuando tenemos el producto de 2-formas generadas?

\[\omega = \sum f_idx_i\,;\,\beta=\sum g_jdx_j\]
Vamos con el $\y$.

\begin{gather*}
T^{\ast} (\omega \y \beta) (s) [\gu,\gv] = \sum_{i,j} f_i(T(s))g_j(T(s)) \underbrace{dx_i\y dx_j [DT(s)\gu, DT(s),\gv]}_{\text{Calculado justo arriba}}\\
= \sum_{i,j} (f_i\circ T) ... \\
= \left(\sum (f_i\circ T)dT_i\right)\y\left(\sum(g_j \circ T) dT_j\right) = T^{\ast}\omega \y T^{\ast}\beta
\end{gather*}

\textbf{Conclusión: } $T^{\ast}(\omega \y \beta) = T^{\ast}\omega \y T^{\ast}\beta$. 

Esto es válido para multindices $I$, es decir, para $\omega$ k-forma y $\beta$ s-forma.


\paragraph{Pull-back y diferencial exterior}
una vez visto cómo se comporta el \emph{pull-back} respecto del producto exterior vamos a ver como se comporta con respecto de la diferencial exterior.

\begin{gather*}
d(T^{\ast} \omega) = d\left(\sum_i f_i(T(s)) dx_i [DT(s)\gv]\right) = d\left(\sum (f_i \circ T)(s) dT_i[\gv]\right)\\
= \sum_i d(f_i\circ T)\y dT_i
\end{gather*}
\text{Vamos a ver que significa:  $d(f_i\circ T)$}

\begin{gather*}
d(f_i\circ T) =  \sum_k \dpa{f_i\circ T}{s_k} ds_k \\
\dpa{f_i\circ T}{s_k} = \sum_j \dpa{f_i}{x_j}(T(s))\cdot \dpa{x_j}{s_k}; \text{Donde }x_j = T_j(s)\\
\text{Juntando todo tenemos: }
\sum_{i,j,k} \dpa{f_i}{x_j}(t(s)) \dpa{T_j(s)}{s_k} ds_k \y dT_i = \sum_{i,j} \dpa{f_i}{s_j}(T(s)) dT_j\y dT_i = T^{\ast}(d(\sum f_i dx_i))
 \end{gather*}
 
 \textbf{Conclusión: } $d(T^{\ast}\omega) = T^{\ast}(d\omega)$
 
 
 \paragraph{Ejemplo concreto} ¡¡Por fin!! El cambio a coordenadas polares.
 
 $(\rho,\theta)$.
 
 
 \[T(\rho,\theta) =\left( T_1(\rho,\theta),T_2(\rho,\theta)\right) = (\rho cos\theta,\rho sen\theta)\]
 
 Vamos a calcular los pull-backs:
 
 \[T^{\ast}(dx) = ...\]
 
 \[T^{\ast} (dy) = dT_2 = d(\rho sen\theta) = \dpa{\rho sen\theta}{\rho} d\rho + \dpa{\rho sen\theta}{\theta}d\theta =sen\theta d\rho + \rho cos\theta d\theta\]
 
 \[T^{\ast}(dx\y dy) = ... = \rho d\rho \y d\theta\]
Completar.

\textbf{Interpretación:}

No sé dónde va esto.

Sea $ω$ una k-forma, donde \[ ω = \sum_I f_i \, dx_I \] donde $I$ son k-multiíndices. Entonces el pullback de $ω$ es 

\[ T^\ast ω = \sum_I f_i\circ T \, dT_I \]

Supongamos ahora que quiero calcular la diferencial exterior:

\begin{equation} d(T^\ast ω) = \sum_I d(\underbrace{
	(f_i\circ T)}_{\text{0-forma}}
	\underbrace{\,dT_I}_{\text{k-forma}})\label{eqSuputamadre} 
	\end{equation}

Si nos acordamos de la fórmula de Lebiniz \wtf tenemos que

\begin{gather*} 
d(fω) = df\y ω + fdω \\
d(ω\y β) = dω \y β + (-1)^kω\y dβ
\end{gather*}

Usamos la primera fórmula en \ref{eqSuputamadre}

\[  d(T^\ast ω) = \sum_I d(f_i\circ T) \y dT_i + d(f_I\circ T)\underbrace{d(d(T_i))}_{=0} = \sum_{I,K}\dpa{}{s_k} (f_I\circ T) ds_k\y dT_I \]

Usando la regla de la cadena en la derivada parcial

\[ \dpa{}{s_k} (f_I\circ T) = \sum_j\dpa{f}{x_j}\circ T \dpa{T_j}{s_k} \]

Poniendo de nuevo todo junto

\[ d(T^\ast ω) = \sum_{I, K, j} \dpa{f}{x_j}\circ T \dpa{T_j}{s_k} ds_k\y dT_I = \]

Sacando factor común

\[ = \sum_{I, j} \dpa{f}{x_j}\circ T\underbrace{\sum_K \dpa{T_j}{s_k} ds_k}_{dT_j}\y dT_I = \sum_{I,j} \dpa{f_i}{x_j}\circ T dT_j\y dT_I = T^\ast \left(\sum_{I,j} \dpa{f_i}{x_j}dx_j\y d_{x_I} \right) \]

Vemos que lo de dentro es lo mismo que $dω$ y por lo tanto

\[ d(T^\ast ω) T^\ast(dω)\]

Y hay una última propiedad (esto lo ordenas tú) que dice

\[ (T\circ S)^\ast ω = S^\ast(T^\ast ω) \]

\paragraph{Propiedades fundamentales de la operación}

\begin{enumerate}
\item $T^\ast f = f\circ T$, siendo $f$ una 0-forma.
\item $T^\ast(dω) = d(T^\ast ω)$. En particular $T^\ast (dx_I) = dT_I$.
\item $T^\ast(ω\y β)=(T^\ast ω) \y (T^\ast β)$.
\item $T^\ast(fω) = (f\circ T)(T^\ast ω) = (T^\ast f)(T^\ast ω)$
\item $T^\ast(ω+β)=T^\ast+T^\ast β$.
\end{enumerate}

\begin{example}

Tenemos una aplicación $φ(s,t) = (φ_1(s,t), φ_2(s,t))$. Calculamos su pullback y entonces

\[ φ^\ast(dx) = dφ_1 = \dpa{φ_1}{s}ds + \dpa{φ_1}{t}dt \]

y de la misma forma
\[ φ^\ast(dyx) = dφ_2 = \dpa{φ_2}{s}ds + \dpa{φ_2}{t}dt \]

\begin{gather*}
 φ^\ast(dx\y dy) = dφ_1\y dφ_2 =\left( \dpa{φ_1}{s}ds + \dpa{φ_1}{t}dt \right) \y\left( \dpa{φ_2}{s}ds + \dpa{φ_2}{t}dt \right) = \\
 0 + \dpa{φ_1}{s}\dpa{φ_2}{t}ds\y dt + \dpa{φ_1}{t}\dpa{φ_2}{s} dt\y ds + 0
 \end{gather*}
 
 Los diferenciales están cambiados de orden así que seguimos pagando con un cambio de signo:
 
 \[ \left(\dpa{φ_1}{s}\dpa{φ_2}{t} - \dpa{φ_1}{t}\dpa{φ_2}{s}\right)ds\y dt= \left|\begin{matrix}
 \dpa{φ_1}{s} & \dpa{φ_1}{t} \\
 \dpa{φ_2}{s} & \dpa{φ_2}{t} 
 \end{matrix}\right| =  \det \left(\dpa{φ}{s,t}\right) ds\y dt \]
 \end{example}
 
 \begin{example}
 Tenemos $β$, la 2-dorma asociada a un campo $\vf=(F_1, F_2, F_3)$:
 
 \[ β = F_1dy\y dz + F_2dz\y dx + F_3 dx\y dy \]
 
 Queremos calcular su pullback mediante una aplicación $\appl{Φ}{ℝ^2}{ℝ^3}$. Entonces
 
 \[ Φ^\ast β = g(s,t) ds\y dt \]
 
 ¿Quién es $g$? Calculamos el pullback:
 
 \[ φ^\ast β = F_1\circ Φ\, dΦ_2\y dΦ_3 + F_2\circ Φ\, dΦ_3 \y dΦ-2 + F_3\circ Φ\, dΦ_1\y dΦ_2 \]
 
 Calculamos los distintos diferenciales, que no pienso copiarlos porque no los ha puesto él en la pizarra, y los pinchamos en el morcillo ese. Y operamos. Y yo no voy a operar. Al final sale todo y queda lo siguiente
 
 \[ =\pesc{\vf\circ Φ, \left(\dpa{Φ_1}{s}, \dpa{Φ_2}{s}, \dpa{Φ_3}{s}\right) × \left(\dpa{Φ_1}{t}, \dpa{Φ_2}{t}, \dpa{Φ_3}{t}\right)} ds\y dt \]
 
 Sin embargo, el producto vectorial de esos dos vectores parece el producto vectorial de $T_s×T_x$, el factor que teníamos que poner para integrar un campo en una superficie. {\Huge SORPRESA}.
 \end{example}
 
 \begin{example}
 
 Tenemos una 1-forma asociada a $\vf$:
 
 
 
 \[ ω = \sum_i F_i\,dx_i \]
 
 y una aplicación (curva) $\appl{σ}{ℝ}{ℝ^n}$. Entonces $σ^\ast ω$ es de la forma $g(t)\,dt$. 
 
 Entonces
 
 \begin{gather*} (σ^\ast ω)(t)[λ] = \sum_i F_i(σ(t)) dx_i[Dσ(t)λ] = \sum_i F_i(σ(t)) dx_i[σ_1'(t)λ, \dotsc, σ_N'(t)λ = \\
 = \sum_i F_i(σ(t)) σ_i'(t) dt[λ] = \\
 = \pesc{\vf \circ σ, σ'} dt [λ]
 \end{gather*}
 
 Que, oh, sorpresa de nuevo, es lo que aparece cuando integrábamos un campo sobre una curva. 
 \end{example}
 
 Al final, querremos integrar k-formas en $ℝ^N$ sobre variedades de dimensión $k$. 
 
 \subsection{Integración de formas diferenciales}

Vamos a partir de Ω abierto de $\real^N$. 

Sea $\omega$ n-forma definida en un entorno de Ω, es decir $\omega = f(\gx) \underbrace{\df{x_1,...,x_n}}_{\text{Elemento de volumen}}$

\begin{defn}[Integración\IS n-forma en $\real^N$.]
\[
\int_Ω\omega = \inf f(\gx) dx_1...dx_N
\]
\end{defn}

\obs Supongamos que tenemos una $\appl{\Phi}{\real^K}{\real^N}$, tal que $\Phi(\gor{s}) = \gx$.

Para que lo de la derecha sea una variedad tenemos que $\Phi$ tiene que ser regular, homeomorfismo y rango máximo.

Supongamos $\omega \in \real^N$, con $\omega$ una x-forma.

¿Qué pasaría si queremos integrar $T^{\ast}\omega$?

Si queremos integrar $\pb{\omega}$ en $\real^k, \omega$ tiene que ser una k-forma para poder aplicar la definición.


\begin{example}
Variedad 1-dimensional.

$\appl{\sigma}{\real}{\real^3}$

Sea $\omega = f_1(x,y,z)dx + f_2(x,y,z)dy + f_3(x,y,z)dz$

Tenemos que $\sigma^{\ast}\omega = \pesc{\overrightarrow{F}\circ \sigma,\sigma'}dt$

La integral quedaría:

\[\int_{\sigma(I)} = \int_I  \pesc{\overrightarrow{F}\circ \sigma,\sigma'}dt 
\]

Integrar 1-forma sobre la variedad 1-dimensional es integrar el trabajo del campo $\overrightarrow{F}$ a lo largo de $\sigma(I)$.
\end{example}

\begin{example}
Una variedad de dimensión 2 en $\real^3$.

$\appl{\Phi}{\real^2}{\real^3}$, con $\Phi(s,t) =  (x,y,z)$.

$\beta$ 2-forma. 
\[\beta = G_1(x,y,z) \df{y,z} + G_2(x,y,z) \df{z,x} + G_3(x,y,z) \df{x,y}\]

El pullback (calculado anteriormente es)

\[\Phi^{\ast}\beta = \pesc{\overrightarrow{G}\circ\Phi,\Phi_s\x\Phi_t}\df{s,t}\]

\[\int_{\Phi(D)}ß = \int \int_D \pesc{\overrightarrow{G}\circ\Phi,\Phi_s\x\Phi_t}dsdt\]

La integral sería:


Es decir, integrar una 2-forma sobre $\Phi(D)$ es integrar el \textbf{flujo} del campo $\overrightarrow{G}$ a través de $\Phi(D)$
\end{example}

\paragraph{Caso general}

Sea $M$ una variedad de dimensión k en $\real^N$.

Supongamos que $(D,\Phi)$ una carta local, es decir:
$\appl{\Phi}{D\subset\real^K}{\real^N}, \Phi(D)\subset M; \Phi$ parametrización. ($\Phi(\gor{t}) = \gx$)

Sea \[\omega = \sum_I f_Idx_I; \, \, \, I=\{i_1,i_2,...,i_k\}\]

Por definición:

\[
\int_{\Phi(d) \omega} = \int_D \Phi^{\ast}\omega
\]

El pull-back nos va a dar una k-forma definida en $\real^k$.

\[
\Phi^{\ast}\omega =g(\gor{t})\df{t_1,t_2,...,t_k}
\]

Aplicando esto:
\[
\int_{\Phi(d) \omega} = \int_D g(\gor{t})\df{t_1,t_2,...,t_k}
\]

Vamos a identificar la función $g$ remangándonos y haciendo cuentas:

\[
\Phi^{\ast} \omega = \sum_I f_I\circ\Phi d\Phi_I = 
\]

Vamos a fijarnos en 
$d\Phi_I = \df{\Phi_{i_1},...,\Phi_{i_k}}$, que va a actuar sobre k-vectores, es decir:

\[
d\Phi_I[\gv_1,...,\gv_k] = \df{\Phi_{i_1},...,\Phi_{i_k}} [\gv_1,...,\gv_k] = \det \begin{pmatrix}
d\Phi_{i_1}[\gv_1] &\cdots& d\Phi_{i_1}[\gv_k] \\
\vdots & \ddots & \vdots\\
d\Phi_{i_k}[\gv_1] & \cdots & d\Phi_{i_k}[\gv_k] \\
\end{pmatrix}
\]

Vamos a desarrollar 1 de los elementos de la matriz (escribiendo $\gw$ para generalizar a cualquiera de los vectores sobre los que actúa):
\[
d\Phi_{i_1}[\gw] = \sum_{j=1}^k \left(\dpa{\Phi_{i_1}}{t_j} dt_j\right)[\gw] = \sum_{j=1}^k \dpa{\Phi_{i_1}}{t_j}w_j = \pesc{\grad \Phi_{i_1},\gw}
\]

Aplicando esto:

\[d\Phi_I[\gv_1,...,\gv_k] =  \det \begin{pmatrix}
\pesc{\grad \Phi_{i_1},\gv_1} &\cdots&  \pesc{\grad \Phi_{i_1},\gv_k}\\
\vdots & \ddots & \vdots\\
\pesc{\grad \Phi_{i_k},\gv_1} & \cdots & \pesc{\grad \Phi_{i_k},\gv_k} \\
\end{pmatrix} = \det \left(\begin{pmatrix}
\grad \Phi_{i_1} \rightarrow \\
...\\
\grad \Phi_{i_k} \rightarrow 
\end{pmatrix}
\begin{pmatrix}
\gv_1 & ... & \gv_k\\
\downarrow & ... & \downarrow
\end{pmatrix}\right) =\]
\[ \det\begin{pmatrix}
\grad \Phi_{i_1} \longrightarrow \\
...\\
\grad \Phi_{i_k} \longrightarrow 
\end{pmatrix} \cdot \det 
\begin{pmatrix}
\gv_1 & ... & \gv_k\\
\downarrow & ... & \downarrow
\end{pmatrix} = (1) =
\det\begin{pmatrix}
\grad \Phi_{i_1} \longrightarrow \\
...\\
\grad \Phi_{i_k} \longrightarrow 
\end{pmatrix} \df{t_1,t_2,...,t_k}[\gv_1,\gv_2,...,\gv_k]
\]

(1): Aplicando que $dt_1(\gv)$ es la primera coordenada del vector $\gv$. Un paso intermedio es \[\det \begin{pmatrix}
dt_1(\gv_1) & ... & dt_1(\gv_k)\\
\vdots & \ddots & \vdots\\
dt_k(\gv_1) & ... & dt_k(\gv_k)
\end{pmatrix}\]

\textbf{Conclusión:}
\[
\Phi^{\ast} \omega = \sum_I f_I\circ\Phi d\Phi_I =
\overbrace{\sum_I f_i\circ\Phi 
\det\begin{pmatrix}
\grad \Phi_{i_1} \longrightarrow \\
...\\
\grad \Phi_{i_k} \longrightarrow 
\end{pmatrix}}^{\text{Esta es la g que buscamos}} \df{t_1,...,t_k}
\]

Aplicando a una integral:

\[\int_{\Phi(D)} \omega = \int_D \sum_I f_i\circ\Phi 
\det\begin{pmatrix}
\grad \Phi_{i_1} \longrightarrow \\
...\\
\grad \Phi_{i_k} \longrightarrow 
\end{pmatrix}dt_1dt_2...dt_k\]