% -*- root: ../mnedo.tex -*-
\section{Hoja 1}
\begin{problem}[1]
Considerar el PVI:
\[\left\{ \begin{array}{l}y'=f(t) \ t \in [t_0,T] \\
y(t_0)=0\end{array}
\right.\]

Probar que utilizando el método de Euler:
\[y_N=\sum_{k=0}^{N-1} f(t_k)h\]
\solution

Recordamos que el método de Euler consiste en emplear
\[y_{n+1} = y_n + h f(t_n)\]

Por inducción podemos resolverlo:

\begin{equation*}
	\begin{multlined}[0.8\textwidth]
		\underline{n=0}: \quad y_1=y_0+h(t_0) = h(t_0)\\[1em]
		\shoveleft{\underline{n=1}: \quad y_2 = y_1 + hf(t_1) = hf(t_0) + hf(t_1)}\\
		\shoveleft{\qquad \qquad \quad = h\left[ f(t_0) + f(t_1) \right]}\\
	\end{multlined}
\end{equation*}

La hipótesis de inducción es que: $y_N = \sum_{k=0}^{N-1} f(t_k)h$. Así que solo nos falta demostrar que se cumple en $N+1$:
\[y_{N+1} = y_N + hf(t_N) = \sum_{k=0}^{N-1} f(t_k)h + hf(t_N) = \sum_{k=0}^N f(t_k)h\]

\end{problem}


\begin{problem}[2]
Ver que el método de Euler falla cuando queremos aproximar la solución
\[y(t) = t^{\frac{3}{2}}\]
del PVI
\[\left\{ \begin{array}{l}y'=\frac{3}{2}y^{\frac{1}{3}} \\
y(0)=0\end{array}
\right.\]

Justifica cuál es el problema.

\solution
\doneby{Pedro}

Recordamos que el método de Euler consiste en emplear
\[y_{n+1} = y_n + h f(y_n)\]

Puesto que el dato inicial es 0 y no hay ninguna constante positiva sumando en la $f(t_n,y_n)$, todas las $y_n$ que calculemos tendrán valor 0 con lo que el método no nos llevará a ningún sitio.

Si el método de Euler no nos lleva a ningún sitio, parece lógico pensar que la función debe tener algún problema que la hace salir del conjunto de funciones sobre las que se puede emplear este método.

Así podemos comprobar que la función $f(t_n,y_n)=\frac{3}{2}y^{\frac{1}{3}}$ no es lipschitz en la segunda variable. Vamos a comprobarlo.

Sea $L$ la constante que define la condición de Lipchitz, siendo el intervalo en el que estamos trabajando el intervalo $[0, \infty)$. 

Tomamos en concreto $y_1=0$. En estas condiciones, si la función fuese Lipchitz tendríamos que 
\[\frac{\frac{3}{2}(y_2^{1/3})}{y_2} = \frac{3}{2}\frac{1}{y^{2/3}}\leq L \ \ \ \forall y_2 \in [0,\infty)\]

Llegados a este punto es sencillo ver que la parte de la izquierda tiende a infinito cuando $y_2$ tienda a 0 y por tanto no puede existir la constante $L$ que lo acote. Por tanto la función no es Lipchitz y no podemos aplicar el método de Euler.
\end{problem}

\begin{problem}[3]
Sea el PVI
\[\left\{ \begin{array}{l}y'=1+y^2 \ t \in [0,2] \\
y(0)=0\end{array}
\right.\]

¿Podemos usar el método de Euler para aproximar la solución $y(t)=\tan(t)$?

\solution

\doneby{Pedro}

Para empezar debemos de comprobar si la función que queremos aproximar satisface la ecuación planteada en el PVI.

\[\tan(x)' = \sec(x)^2 = 1 + \tan(x)^2, \ \ \tan(0)=0\]

Queda claro que el PVI planteado tiene como solución la función tangente. Ahora tenemos que ver si el problema planteado puede resolverse por el método de Euler.

Para verlo debemos comprobar si la función $f(t_n,y_n)=1+y^2$ es lipschitz en la segunda variable. Sólo en caso de serlo podríamos aplicar el método de Euler para obtener la solución. Vamos a ello.

\[\forall y_1<y_2 \in [0,2] \ \ \frac{\abs{y_2^2 - y_1^2}}{y_2-y_1}=\frac{(y_2-y_1)(y_2+y_1)}{y_2-y_1} = (y_2+y_1) \leq 4\]

Por tanto, como la función es Lipschitz en la segunda variable, podremos aplicar le método de Euler para resolver el PVI planteado.
\end{problem}


\begin{problem}[4]
Calcular el residuo de los siguientes métodos:

\ppart Regla del trapecio:
\[y_{n+1} = y_n + \frac{h}{2}\left( f(t_{n+1},y_{n+1})+f(t_n,y_n)\right)\]

\ppart Euler modificado:
\[y_{n+1} = y_n +hf\left( t_n+\frac{h}{2}, y_n+\frac{h}{2}f(t_n,y_n)\right)\]

\ppart Leap-frog
\[y_{n+2}=y_n+2hf(t_{n+1},y_{n+1})\]
\solution

\doneby{Pedro}

El residuo no es más que la diferencia entre el valor real de la función en $x_n$ y su valor aproximado a partir del método, es decir:
\[R_n = y(x_{n+1})-y_{n+1}\]

\spart
\[R_n = y(x_{n+1})-y(x_{n+1}) = y(x_{n+1})-y(x_n) - \frac{h}{2}\left( y'(x_{n+1})+y'(x_n)\right)\]

Por Taylor podemos ver que:
\[\left\{\begin{array}{l}
y(x_{n+1}) = y(x_n)+hy'(x_n)+\frac{h^2}{2}y''(x_n)+O(h^3) \\
y'(x_{n+1}) = y'(x_n)+hy''(x_n) +O(h^2)
\end{array}\right.\]

Sustituyendo estos datos en la fórmula del residuo llegamos a:
\[R_n = O(h^3)\]

\spart

En esta ocasión
\[R_n = y(x_{n+1})-y(x_n)-hf\left( t_n+\frac{h}{2}, y_n+\frac{h}{2}y'(x_n)\right)\]

Calculando el desarrollo de Taylor de la $f$ llegamos a:
\[f\left( t_n+\frac{h}{2}, y_n+\frac{h}{2}y'(x_n)\right) = f(x_n,y_n)+\frac{h}{2}f_x(x_n,y_n)+\frac{h}{2}y'(x_n)f_y(x_n,y_n)= \atop y'(x_n)+\frac{h}{2}y''(x_n)\]

Sustituyendo en la fórmula del residuo llegamos a:
\[R_n = O(h^3)\]

\spart

En esta ocasión
\[R_n = y(x_{n+2})-y(x_n)-2hy'(x_{n+1})\]

Desarrollando por Taylor el primer sumando tenemos 
\[\left\{ \begin{array}{l}
y(x_{n+2}) = y(x_n) + 2hy'(x_n)+2h^2y''(x_n)+O(h^3) \\
y'(x_{n+1}) = y'(x_n)+hy''(x_n) + O(h^2)
\end{array}\right.\]

Y sustituyendo en la fórmula del residuo llegamos a:
\[R_n=O(h^3)\]


\end{problem}

\begin{problem}[5]
Dado $α \in [0,1]$ encontrar el orden del método:
\[y_{n+1} = y_n +hf(t_n+(1-α)h, αy_n+(1-α)y_{n+1})\]

\solution

Lo que debemos hacer es calcular el residuo cuya definición, recordemos, era:

\begin{defn}[Residuo]
Cuánto de lejos está la solución de satisfacer en un paso la fórmula de recurrencia
\end{defn}

Según esta definición, nuestro residuo será:
\[R_n = \underbrace{y(t_{t+1})}_{\label{ej1-5_tresTerminos}1} - \left\{ \underbrace{y(t_n)}_{2} + \underbrace{hf(t_n+(1-α)h, αy(t_n)+(1-α)y(t_{n+1}))}_{3} \right\}\]

Para conocer el orden de este residuo nos serviremos de los desarrollos de Taylor:
\[\hyperref[ej1-5_tresTerminos]{1} \quad y(t_{n+1}) = y(t_n)+y'(t_n)h + y''(t_n)\frac{h^2}{2} + O(h^3)\]

La segunda variable para la $f$ que aparece en \hyperref[ej1-5_tresTerminos]{3} se puede desarrollar como:
\[αy(t_n) + (1-α)y(t_{n+1}) = αy(t_n) + (1-α)\left[y(t_n) + y'(t_n)h +  y''(t_n)\frac{h^2}{2} + O(h^3) \right] \]
\[\qquad \qquad \qquad \qquad = y(t_n) + (1-α)\left[ y'(t_n)h + y''(t_n) \frac{h^2}{2} + O(h^3) \right]\]

Por tanto el desarrollo de Taylor de \hyperref[ej1-5_tresTerminos]{3} puede expresarse de la siguiente forma:

\[h\left( f(t_n,y(t_n))+\underbrace{f_x(t_n,y(t_n))\cdot (1-α)h +\underbrace{f_y(t_n,y(t_n))(1-α)h\left( y'(t_n)+y''(t_n)\frac{h}{2}+O(h^3)\right)}_{f_y(t_n,y(t_n))y'(t_n)(1-α)h + O(h^2)}}_{(1-α)h y''(t_n) + O(h^2)}\right) = \]

\[=hy'(t_n)+(1-α)h^2y''(t_n)+O(h^3)\]

De modo que las 3 expresiones las tenemos como:
\begin{equation*}
	\begin{multlined}[.8\textwidth]
		\hyperref[ej1-5_tresTerminos]{1} =  \quad y(t_{n+1}) = y(t_n) + y'(t_n) h + y''(t_n) \frac{h^2}{2} + O(h^3) \\
		\shoveleft{\hyperref[ej1-5_tresTerminos]{2} =  \quad y(t_n)} \\
		\shoveleft{\hyperref[ej1-5_tresTerminos]{2} =  \quad hy'(t_n) + (1-α) h^2 y''(t_n) + O(h^3)}\\
	\end{multlined}
\end{equation*}


Sumando \hyperref[ej1-5_tresTerminos]{1} y \hyperref[ej1-5_tresTerminos]{3}, y restando \hyperref[ej1-5_tresTerminos]{2} obtenemos:
\[R_n = y''(t_n)h^2 \left(\frac{1}{2}-(1-α) \right)+O(h^3)\]


Ahora tenemos dos casos posibles, y sabiendo que el orden de un método es $\frac{R_n}{h}$:
\begin{itemize}
\item α=1/2
\[R_n=O(h^3) \implies \text{ orden } \geq 2\]
\item α$\neq$1/2
\[R_n = y''(t_n)h^2 \left(\frac{1}{2}-(1-α) \right) + O(h^3) \implies \text{ orden } 1\]
\end{itemize}

\end{problem}


\begin{problem}
	\ppart Sea un PVI. Utilizando los polinomios de interpolación de Lagrange obtener el método de Adams-Bashforth de dos pasos
	\[y_{n+2} = y_{n+1} + h \left( \frac{3}{2}f(t_{n+1}, y_{n+1}) + \frac{1}{2}f(t_n,y_n) \right),\]
	
	\ppart y el de tres pasos
	\[y_{n+3} = y_{n+2} + h \left( \frac{23}{12} f(t_{n+2},y_{n+2}) - \frac{4}{3} f(t_{n+1}, y_{n+1}) + \frac{5}{12}f(t_n,y_n) \right)\]
	
	\solution
	\begin{defn}{\textbf{Polinomio de interpolación de Lagrange}}

		Recordemos (de cálculo numérico) que el polinomio de interpolación de Lagrange tenía la forma:
		\[P(x) = f(x_0)l_0(x) + f(x_1)l_1(x) + … + f(x_N)l_N(x)\]
		donde $f$ es la función que queremos aproximar en los $x_i,\ i=0,…,N$ puntos, y
		\[l_i(x) = \frac{(x-x_0) … (x-x_{i-1}) (x-x_{i+1}) … (x-x_N)}{(x_i-x_0) … (x_i-x_{i-1}) (x_i-x_{i+1}) … (x_i-x_N)}\]
	\end{defn}

	\spart
	En el método de Adams Bashforth tenemos que
	\[y(x_{n+2})-y(x_{n+1}) = \int_{x_{n+1}}^{x_{n+2}} f(x,y(x)) dx\]
	y el valor de $f$ entre los puntos $x_{n+1}, x_{n+2}$ se aproximama mediante la recta que pasa por los puntos $(x_{n+1},f(x_{n+1},y_{n+1}), (x_{n+2}, f(x_{n+2},y_{n+2})))$. Para obtener dicha recta usamos el polinomio de interpolação de Lagrange:
	\[f(x,y) = f(x_n,y_n)\frac{x-x_{n+1}}{x_n-x_{n+1}} + f(x_{n+1},y_{n+1}) \frac{x-x_n}{x_{n+1}-x_n}\]

	Si integramos entre $\int_{x_{n+1}}^{x_{n+2}}$
	\[\int_{x_{n+1}}^{x_{n+2}} \left[ f(x_n,y_n)\frac{x_{n+1}-x}{h} + f(x_{n+1},y_{n+1})\frac{x-x_n}{h}) \right]dx =\]
	\[= \left[ f(x_{n+1},y_{n+1}) \frac{(x-x_n)^2}{2h} - f(x_n,y_n)\frac{(x_{n+1}-x)^2}{2h} \right]_{x_{n+1}}^{x_{n+2}}  =\]
	\[= \frac{1}{2h}f(x_{n+1},y_{n+1}) \left[ (x_{n+2}-x_n)^2 - (x_{n+1}-x_n)^2 \right] - \frac{1}{2h} \left[ (x_{n+1} - x_{n+2})^2 - (x_{n+1} - x_{n+1})^2 \right] =\]
	\[= \frac{h}{2} \left( 3f(x_{n+1},y_{n+1}) - f(x_n,y_n) \right)\]


	\spart
	En este caso tendremos que:
	\[y_{n+1} - y_n = \int_{x_n}^{x_{n+1}} f(x,y(x)) dx\]
	Con la particularidad de que ahora la aproximación de $f$ en el intervalo $[x_n,x_{n+1}]$ la realizaremos interpolando la $f$ en los puntos $x_{n-2},x_{n-1},x_n$ con el polinomio de Lagrange $p$.

	Sabemos por tanto que $p$ interpola $f$ en $x_{n-2},x_{n-1},x_n$:

	{\inputtikz{EJRC_interpolar}}

	Para simplificar los cálculos vamos a tomar el cambio de variable $u=\frac{x_{n+1}-x}{h}$ para que así el polinomio interpole $f(u,y(u))$ en los puntos $3,2,1$. ($u(x_{n-2})=3, u(x_{n-1})=2, u(x_n)=1$).

	{\inputtikz{EJRC_interpolar_transformed}}


	Es decir, tras el cambio de variable el polinomio interpolador queda como

	\[\tilde{p}(u) = f(x_n,y_n) \frac{(u-2)(u-3)}{(1-2)(1-3)} + f(x_{n-1},y_{n-1}) \frac{(u-1)(u-3)}{(2-1)(2-3)}+f(x_{n-2},y_{n-2}) \frac{(u-1)(u-2)}{(3-1)(3-2)}\]

	De modo que tras el cambio de variable tendremos:
	\[\int_{x_n}^{x_{n+1}}p(x)dx \underbrace{=}_{t_{n+1}-hu=x} h\int_0^1 p(t_{n+1}-hu) du = h\int_0^1 \tilde{p}(u)du =\]
	\[= h\int_0^1 \left[ f(x_n,y_n) \frac{(u-2)(u-3)}{(1-2)(1-3)} + f(x_{n-1},y_{n-1}) \frac{(u-1)(u-3)}{(2-1)(2-3)}+f(x_{n-2},y_{n-2}) \frac{(u-1)(u-2)}{(3-1)(3-2)} \right] =\]
	\[= h\int_0^1 \left[ f(x_n,y_n)\frac{u^2-5u+6}{2} - f(x_{n-1},y_{n-1})(u^2-4u+3) + f(x_{n-2},y_{n-2})\frac{u^2-3u+2}{2} \right] =\]
	\[=  h \left( \frac{23}{12} f(t_{n+2},y_{n+2}) - \frac{4}{3} f(t_{n+1}, y_{n+1}) + \frac{5}{12}f(t_n,y_n) \right)\]

	Por tanto
	\[y(x_{n+2})-y(x_{n+1}) = \int_{x_{n+1}}^{x_{n+2}} p(x) dx = h \left( \frac{23}{12} f(t_{n+2},y_{n+2}) - \frac{4}{3} f(t_{n+1}, y_{n+1}) + \frac{5}{12}f(t_n,y_n) \right)\]
\end{problem}
