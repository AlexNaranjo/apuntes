\chapter{Cadenas de Markov}

\section{Un modelo para redes}
En este capítulo vamos a ver cómo ordena Google las páginas que resultan de la búsqueda para mostrarlas por orden de prioridad.

Supongamos que tenemos una red de páginas web conectadas por enlaces (Google afirma cubrir unas $3\cdot 10^3$ páginas web). Vamos a ver las páginas como vértices de un grafo y los enlaces como aristas dirigidas(especificando un sentido).

Matemáticamente esto es un grafo dirigido:
\begin{center}
\includegraphics{tex/ejemplo_dibujo.png}
\end{center}
¿Cómo ordenar por relevancia los vértices?¿En qué orden aparecerán las páginas?


Para poder determinar que páginas son más importantes vamos a suponer un paseo aleatorio por los vértices (los internautas navegan al azar siguiendo los enlaces) de forma que una mayor acumulación en ciertos vértices indicará que son más importantes.


Aviso: No funciona literalmente, hay que hacer modificaciones.
DIBUJO
A la larga esto converge...\\
DIBUJOS VARIOS
Como había 360 al principio parece que:


\begin{itemize}
	\item Probabilidad de estar en 1 es $\frac{144}{360} = \frac{2}{5}$
	\item Probabilidad de estar en 2 es $\frac{144}{360} = \frac{2}{5}$
	\item Probabilidad de estar en 3 es $\frac{72}{360} = \frac{1}{5}$
\end{itemize}
	Según esto 1 y 2 son igual de importantes y 3 es la mitad de importante.

	La distribución que pensamos que da el límite es estacionaria (no cambia con el tiempo).

	DIBUJO.

% Empieza clase del 4 de Febrero

Recordamos que en la red anterior cuando el tiempo tiende a infinito parece que la distribución de personas se estabiliza.

Parece además que sea cual sea la distribución inicial llegamos a proporciones similares. En este caso llegamos a la distribución límite $\left(\frac{2}{5},\frac{2}{5},\frac{1}{5}\right)$, que es una distribución estacionaria (no varía con el tiempo).

(DIBUJO DE EVOLUCIÓN POR PASOS TENIENDO EN CUENTA PROBABILIDADES)

\section{Propiedades de los paseos aleatorios}

\textbf{¿Esta simulación con paseos aleatorios siempre sirve para ordenar los vértices (páginas web)?}

Debemos obsevar las siguientes preguntas:

\begin{itemize}
	\item ¿Existe siempre una distribución estacionaria?
	\item Si existe una distribución estacionaria ¿es única?
	\item El procedimeinto, ¿Da lugar siempre a una distribución límite?
	\item Si la distribución límite existe, ¿Es independiente de la distribución inicial?

\end{itemize}

\subsection{Si existe una distribución estacionaria ¿es única?}
\label{P2}

(DIBUJO CON DOS GRAFOS IGUALES AL ANTERIOR CONECTADAS CON UN NODO INTERMEDIO QUE SOLO TIENE LINKS HACIA FUERA DE MANERA QUE QUEDAN INCOMUNICADAS)
% nodo 4 es internet oscura

Como desde un lado de la red no se puede acceder al otro podemos decir que estas dos distribuciones son estacionarias:

$(1, 2, 3, 4, 5, 6, 7)$

$(\frac{2}{5},\frac{2}{5},\frac{1}{5}, 0, 0 , 0, 0)$ es estacionaria.

$(0, 0, 0, 0, \frac{1}{5}, \frac{2}{5}, \frac{2}{5})$ es estacionaria.


\subsection{¿Existe siempre una distribución estacionaria?}

\begin{example}{sencillo}

	(DIBUJO CON TRES NODOS CADA UNO CON UNA ENTRADA Y UNA SALIDA)

	Si pones todos en un nodo oscila:

	$1\; 0\; 0 \rightarrow 0\; 0\; 1 \rightarrow 0\; 1\; 0 \rightarrow 1\; 0\; 0$

	Se puede argumentar que con una distribución inicial uniforme si funciona:

	$\frac{1}{3} \; \frac{1}{3} \; \frac{1}{3} \; \rightarrow \frac{1}{3} \; \frac{1}{3} \; \frac{1}{3} \; $

	Pero esto no es verdad para cualquier grafo: partiendo de la equidistribución no se tiene la convergencia en general.

	(DIBUJO IGUAL QUE EL ANTERIOR PERO AÑADIENDO UN NODO MÁS, QUE SOLO TIENE UNA FLECHA SALIENTE A UNO DE LOS NODOS DEL DIBUJO ANTERIOR)

	$(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4}) \rightarrow (\frac{1}{2},\frac{1}{4},\frac{1}{4}, 0) \rightarrow (\frac{1}{4},\frac{1}{4},\frac{1}{2},0)$ oscila como antes

	\textbf{La respuesta es negativa en general}

\end{example}


\subsection {Si la distribución límite existe, ¿Es independiente de la distribución inicial?}


Basta usar como distribución inicial las distribuciones estacionarias que vimos para la segunda pregunta \ref{P2}.

\begin{obs}

Para el grafo de \ref{P2} se puede probar que $\exists$ límite:

$$(1-t)(\frac{2}{5},\frac{2}{5},\frac{1}{5},0,0,0,0) + t (0,0,0,0,\frac{1}{5},\frac{2}{5},\frac{2}{5}) \;\;\; 0 \leq t \leq 1 $$

son infinitos contraejemplos como los necesarios para la segunda pregunta \ref{P2} y la cuarta.

\end{obs}


\textbf{Spoiler} P1 es verdad y "perturbando" un poco el grafo (de manera muy sencilla) todas las preguntas tienen respuesta afirmativa.



\section{Cadenas de Markov}

\begin{defn}[Cadena de markov]
	Es una sucesión de variables aleatorias $\{X_n\}_{n=0}^{\infty}$ que toman valores en un conjunto numetarble S (\textbf{conjunto de estados}) tal que
	$$Prob(X_{n+1} = V | X_n = U) = Prob(X_{n+1} = V | X_n =U , X_{n-1} = U_{n-1} , ... , X_0 = U_0)$$
	para cualesquiera $n \geq 0$ $U,V,U_0,.... ,U_{n-1} \in S$
\end{defn}


\obs Además supondremos que esta probabilidad no depende de n.


\textbf{Idea intuitiva: } n es el tiempo discretizado, lo que ocurra mañana depende con cierta probabilidad de lo que ocurre hoy sin que importe conocer la historia anterior.

Decir que no depende de n es decir que según pasa el tiempo, las reglas no cambian.

\begin{example}
	$X_n =$ suma de puntuaciones el día $n$ al tirar un dado cada día.

	El conjunto de todos los estados serían todas las puntuaciones posibles . (S = naturales)
\end{example}

\begin{example}[2]
	S = puntuaciones en el tenis.\\
	$X_n =$ puntuación el en punto n\\
	Suponemos que el jugador A tiene prob $p > 1/2$ de ganar cada punto.\\
	Pensando un poco las puntuaciones en el tenis vemos que S solo puede tener 20 elementos.\\
	S= puntuaciones numéricas, deuce, advantages(A o B) , victoria (A o B).\\
	Se puede comprobar que:
	$$Prob(\text{victoria A}) = \frac{p^4 \cdot(1- 16(1-p)^4)}{p^4 - (1-p)^4}$$
	Esto es como curiosidad, ver que con tener sólo un poco más de probabilidad de ganar un punto, la probabilidad de ganar un juego y un set va creciendo.
\end{example}




Si $|S| = \infty$ entonces la cadena de Markov es infinita y se supone $S = \ent^+ (\nat -\{0\})$


Si $|S| < \infty$ entonces la cadena de Markov es finita y se supone $S =\{1,2,...,N\}$

\begin{defn}[Probabilidad de transición]
	del estado i al j
	$$P_{ij} = Prob(X_{n+1} = j| X_n = i) = Prob (X_1 = j| X_0 = i)$$
\end{defn}

Los $P_{ij}$ forman la \textbf{matriz de transición}.


\textbf{Propiedades}
\begin{enumerate}
	\item $\sum_{j \in S} P_{ij} = 1$
	\item $Prob(X_1 = j)= \sum_{i \in S} Prob(X_0 = i)P_{ij}$\\
\end{enumerate}

\begin{proof}
	\begin{enumerate}
		\item $\sum_{j \in S} P_{ij} = \sum_{j\in S} Prob(X_1 = j | X_0 = i) = Prob (X_1 \in S | X_0 = i) = 1$
		\item Utilizando la ley de la probabilidad total

		$$Prob(X_1 = j) = \sum_{i \in S} Prob (X_0 = i) \cdot Prob(X_1 = j| X_0 = i)$$
	\end{enumerate}
\end{proof}

	\begin{defn}[Ley de la probabilidad total]
		Sea  $\{A_1, A_2,...,A_n\}$ una partición de $\Omega$ con $P(A_i)>0 \forall i=1,2,...,n$. Entonces, $\forall B \subset \Omega$ medible (perteneciente a $\algb{M}$):
		\[
		P(B)=\sum_{i=1}^{n}P(B\cap A_i)=\sum_{i=1}^{n}P(B|A_i)P(A_i)
		\]
		(Se obtiene de despejar de la formula de la probabilidad condicionada: $P(A|B)=\frac{P(A \cap B)}{P(B)}$)
	\end{defn}


De las dos propiedades deducimos que:
\begin{itemize}
	\item \textbf{(prop.1)} La matriz de transición $P_{ij} i,j \in S$ tiene elementos $0 \leq P_{ij} \leq 1$ y la suma de los elementos de cada fila es 1.
	\item Escribiendo ($\prod_0$) = ${Prob (X_0 =i)}_{i \in S}$ como vector fila, y ($\prod_n$) = ${Prob (X_n =i)}_{i \in S}$

	Entonces por \textbf{(prop.2)} : ($\prod_0$) $ = (\prod_n)\cdot P$ (P = matriz de transición)
\end{itemize}

De la misma forma $(\prod_2) = (\prod_1) \cdot P$, etc...

Iterando nos queda:
$$(\prod_n) = (\prod_0) \cdot P^n$$

Ahora vemos cómo aplicar esto a las páginas web.
DIBUJO DEL GRAFO DE SIEMPRE

S= páginas web (vértices)\\
$P_{ij}$ = probabilidad de , estando en la página i, llegar a la página j en el instante siguiente.
$$Prob(X_1 = (2)| X_0 = (1)) = 1$$
$$P =\left(\begin{matrix}
  0 & 1 & 0\\
  1/2 & 0 & 1/2\\
  1 & 0 & 0
\end{matrix}\right)$$


Otro ejemplo:
DIBUJO DE OTRO TRUÑO DE ESOS QUE PONE EN LA PIZARRA

$$P = \left( \begin{matrix}
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
1 & 0 & 0 & 0\\
1 & 0 & 0 & 0\\
\end{matrix}\right)$$
Este ejemplo habiamos visto que no funcionaba bien porque no convergia a nada, oscilaba.


Teniendo en cuenta que en la realidad la P sería una matriz de $3\cdot 10^{13} \times 3\cdot 10^{13}$ la forma más fácil de calcular $P^n$ es con la forma canónica de Jordan.


