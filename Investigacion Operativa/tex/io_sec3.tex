\section{Condiciones KTT}


\paragraph{Motivación:} Puede ser que los problemas a los que nos enfrentemos no cumplan las condiciones de convexidad estudiadas en el tema anterior. En ese caso, necesitaremos nuevas herramientas, como las condiciones KTT.
Vamos a intentar relajar las condiciones de convexidad para los problemas que vamos a resolver, encontrando otras condiciones (definidas por Karoush, Kuhn y Tucker) que permiten la identificación de los mínimos de un problema. 

En este tema vamos a estudiar tanto problemas generales como problemas convexos en un dominio del problema abierto que incluye todos los puntos que satisfacen las restricciones.

Consideremos el problema:

\begin{ioprob}
\goal{$\min f(x)$}
\restrictions{$f_i(x)≤0\;i=1,...,m$}{}{}{}{}{}
\end{ioprob}


\begin{defn}[Condiciones\IS KTT]
Sean $u_i ≥0$ y el Lagrangiano:

\[
	L(x) = f(x) + \sum_i u_i f_i(x)
\] 

\obs Estos $u_i$ utilizados los denominaremos \concept{ultiplicadores} por el \href{https://en.wikipedia.org/wiki/Lagrange_multiplier}{teorema de los multiplicadores de Lagrange}.

Se dice que el punto $\vx$ y el vector de multiplicadores $\vu \in ℝ^m$ verifica las condiciones KTT para un problema $(P)$ si

\begin{align*}
KKT(\vx) \dimplies \grad L(\vx) = 0 \dimplies \grad f(\vx) + \sum_i u_i\grad f_i(\vx) &=0\\
f_i(\vx)  &≤ 0 \;\; i=1,...,m\\
u_i&≥0\;\; i=1,...,m\\
u_if_i(\vx) &= 0  \;\; i=1,...,m
\end{align*}
\end{defn}
\paragraph{Notación:} $KKT(\vx)$ significa que para $\vx$ existe un vector de multiplicadores tales que verifican las condiciones KTT. De la misma manera, $KTT(\vx,\vu)$ significa que el punto $\vx$ y el vector de multiplicadores satisfacen las condiciones KKT.

Cualquier mínimo local de un problema $(P)$, que también cumpla las cualificación de las restricciones (que definimos a continuación) tiene que cumplir las condiciones KTT. 
Esto nos puede dar una pista para encontrar mínimos locales en un problema.


\begin{defn}[Cualificación\IS de las restricciones]
Dado un punto fatible $\vx$, sea $I_{\vx} = \{i : f_i(\vx) = 0\}$ el conjunto de restricciones \textbf{activas} en $\vx$.

$\vx$ verifica la cualificación de las restricciones si los vectores $\grad f_i(\vx)$ son linealmente independientes.
\end{defn}

Vamos a ver el resultado importante que relaciona estos conceptos:

\begin{itheorem}
\[
\left.
	\begin{array}{c}
		\vx \text{ mínimo local de } (P)\\
		\vx \text{ verifica la cualificación de las restricciones}
	\end{array}
\right\} \implies KKT(\vx)
\]
\end{itheorem}

\begin{proof}
Si $\vx$ es un mínimo local de $(P)$ entonces no existe ninguna dirección $d∈ℝ^n$ tal que sin salir del conjunto factible mejoremos el valor objetivo de $\vx$ en esa dirección, es decir:

\[
	\pesc{\grad f(\vx),d}< 0 \wedge \pesc{\grad f_i(\vx) < 0} ∀ i \in I
\]

Siendo $I$ el conjunto de las restricciones activas en $\vx$.

Por el teorema Gordan, existen $u_0≥0, u_i≥0, i\in I$ no todos nulos tales que $\pesc{(u_0,\vu),(\grad f, \grad f_i}$

$u_0 >0$ por la cualificación de las restricciones, ya que 
\[
	u_0 = 0 \implies \sum u_i\grad f_i (\vx) = 0 
\]
con lo que habríamos encontrado una combinación lineal y podríamos concluir que $\grad f_i$ son linealmente dependientes y por hipótesis no puede serlo.

Definimos $\gor{u_i} = \frac{u_i}{u_0}$ si $i\in I$y $\gor{u_i} = 0$ si $i\notin I$. De esta manera tenemos:

\[
	\gor{u_i} f_i = 0 \impliedby
	\left\{ 
		\begin{array}{cc} 
			i\in I &\implies f_i(\vx) = 0 \\
			i\notin I &\implies \gor{u_i} = 0
		\end{array}
	\right.
\]

Ahora sólo queda comprobar $KKT(\vx,\gor{\vu})$.

\end{proof}

Con este teorema, clasificamos todos los mínimos que puede tener un problema en 2 clases disjuntas. \textbt{O cumple la cualificación de las restricciones o KKT}, pero no puede no cumplir ninguna (ni las 2 a la vez).

\begin{example}
Determina los puntos que verifican KKT y resuelve el problema:

\begin{ioprob}
\goal{$\min x_1^2+x_2^2 + 2x_3^2$}
\restrictions{$2x_1+3x_2+x_3 ≥ 6 \to -2x_1 - 3x_2 - x_3 + 6 ≤0$}{}{}{}{}{}
\end{ioprob}

Tenemos $\grad f(\vx) = (2x_1,2x_2,4x_3)$, con $f_i = (-2,-3,-1)$

Construimos el "sistema":

\[
\grad f(\vx) + \sum u_i f_i(\vx) \to 
\left\{
	\begin{array}{cc}
		2x_1-2u = 0&\\
		-2x_2 - 3u = 0&\\
		6x_3 - u = 0&\\
		u≥0, 2x_1+3x_2+x_3≥6 &(Factibilidad)\\
		u[-2x_1 - 3x_2 - x_3 + 6] = 0 &(Holgura Complementaria)
	\end{array}\right.
\]

Y ahora resolvemos el sistema\footnote{No hay ningún algoritmo mejor que ir razonando.}.

\begin{equation}
\label{KTT:ejemplo1}
2x_1+3x_2+x_3 > 6 \overset{H.C.}{\to} u=0 \to x_i = 0 \to \neg F
\end{equation}
De \ref{KTT:ejemplo1} obtenemos que $2x_1+3x_2 + x_3 = 6$ y nos hemos quitado la desigualdad.

Ahora tenemos un sistema de 4 incógnitas $(x_1,x_2,x_3,u)$ y 4 ecuaciones. Resolviendo el sistema obtenemos:

\[
	sol. \to (x_1,x_2,x_3,u) = \left( \rfrac{8}{9}, x_1^0,x_2^0,x_3^0\right)
\]

Llamamos $\gor{\vx} = (x_1^0,x_2^0,x_3^0)$. Hemos encontrado un punto que $KKT(\gor{\vx})$.

Por otro lado: como $\grad f_i(\vx) = (-2,-3,1) ∀\vx$, todos los $\grad f_i$ son linealmente independientes para todos los $\vx$, con lo que todos los puntos cumplen la cualificación de las restricciones.

$\gor{\vx}$ es un punto que cumple la cualificación de las restricciones y es KKT, con lo que es el único mínimo que hay. Como sólo hay un mínimo, éste tiene que ser el mínimo global.

\end{example}

\begin{example}

Resolver gráficamente y determinar los puntos que verifican KKY en el siguiente problema:

\begin{ioprob}
\goal{$\max 3x_1+x_2$}
\restrictions{$x_2-(1-x_1)^3≤0$}{$x_1≥0$}{$x_2≥0$}{}{}{}
\end{ioprob}

Lo primero es escribirlo como problema de minimización para poder utilizar lo visto hasta ahora:

\begin{ioprob}
\goal{$\min -3x_1-x_2$}
\restrictions{$x_2-(1-x_1)^3≤0$}{$-x_1≤0$}{$-x_2≤0$}{}{}{}
\end{ioprob}

Para comprobar KKT, calculamos el Lagrangiano:

\[
	L(\vx,\vu) = -3x_1 - x_2 + u_0[x_2-(1-x_1)^3] + u_1(-x_1) + u_2(x_2)
\]

Y construimos el sistema:

\[
	\left\{
	\begin{array}{lc}
		\dpa{L}{x_1} = -3 + 3u_0(1-x_1)^2 - u_1 = 0&(I)\\
		\dpa{L}{x_2} = -1 * u_0 - u_2 = 0 & (II)\\
		\left. 
			\begin{array}{c}
				u_0[x_2-(1-x_1)^3] = 0\\
				u_1(x_i) = 0\\
				u_2(x_2) = 0
			\end{array}
			\right\} &(HC)
	\end{array}
	\right.
\]

Y se resuelve.

\end{example}


\subsection{KTT con igualdad}

Podemos extender la noción de condición KKT a un problema en el que haya restricciones con igualdad, esto es:

\marginpar{\textcolor{yellow}{Completar de .tex del profesor}}



También hay una condición de cualificación de las restricciones y un teorema con el resultado análogo al anterior para problemas con restricciones con igualdad.


\section{Problema dual}

Podemos definir un problema a partir de uno dado que siempre es convexo y tiene otras propiedades interesantes. En ocasiones es más fácil de resolver y en otras aporta información muy claramente que en el problema inicial no están definidas. 

Vamos a comenzar definiendo la función que da lugar al problema dual:

\begin{defn}[Función\IS lagrangiana]
Para un problema general (no necesariamente convexo) con $m$ restricciones con desigualdad y $p$ restricciones con igualdad, definimos:

\[
	L(\vx,\vu,\vv) = f(\vx) + \sum_i^m u_if_i(\vx) + \sum_i^p v_if_i(\vx)
\]
\end{defn}

\paragraph{Interpretación:} Vamos a interpretar las restricciones como penalizaciones. Ahora el conjunto factible será todo $\real^n$, pero los puntos que no cumplan una restricción van a ser "penalizados". Definimos la función objetivo:

\[
	f(\vx) + \sum I_{-}(f_i(\vx)) + \sum I_{0}(f_i(\vx)) \to \left\{ 
		\begin{array}{c}
		I_{-} = \left\{
			\begin{array}{ccc}
				0 & si & x≤0\\
				∞ & si & x> 0\\
			\end{array}\right.\\
		I_{0} = \left\{
			\begin{array}{ccc}
				0 & si & x = 0\\
				∞ & si & x ≠ 0\\
			\end{array}\right.
		\end{array}
		\right.
\]

De esta manera hemos agrandado el conjunto factible y tenemos un problema equivalente, pero sin restricciones. Tomando valores interesantes en vez de $I_{-}$ e $I_{0}$, llegaríamos la función lagrangiana.


\begin{defn}[Función\IS dual]
	\[
		g(\vu,\vv) = \inf_{x\in D} L(\vx,\vu,\vv)
	\]
\end{defn}

Tomando la función dual, tenemos:

\[
	g(\vu,\vv) = \inf_{\vx\in D} L(\vx,\vu,\vv) ≤ L(\vx,\vu\vv) = f(x) + \sum u_if_i(\vx) + \sum v_if_i(\vx) \overset{(1)}{≤} f(\vx)
\]

$(1)$ si $\vx$ es un problema factible.

\begin{prop}
La función dual es una función cóncava (aunque el problema inicial $(PI)$ no sea convexo).
\end{prop}

\begin{proof}
\[
	g(λu_1 + (1-λ)u_2, λu_1 + (1-λ)v_2) = \min \{L(\vx,\vu,\vv)\} = \min \{λL(\vx,u_1,v_1) + (1-λ)L(\vx,u_2,v_2)\} \]
\[≥ λ\underbrace{\min\{L(\vx,u_1,v_1)\}}_{g(u_1,v_1)} + (1-λ) \underbrace{\min\{L(\vx,u_2,v_2)\}}_{g(u_2,v_2)}
\]
\end{proof}

La función dual es una cota inferior del valor óptimo del problema inicial. Podríamos considerar resolver el problema inicial buscando la mejor cota inferior de la función dual. De esta manera, igual llegamos a resolver el mismo problema. 
Los siguientes resultados nos ayudarán a resolver estas cuestiones:

Por si no nos creemos que sea una cota inferior, vamos a verlo formalmente como teorema (aunque no lo demostremos):

\begin{itheorem}
Sea $\bar{p}$ el valor óptimo de un problema de optimización cuya función dual es $g(\vu,\vv)$. \textbf{Entonces:} $∀ \vu≥0,∀v, g(\vu,\vv) = \bar{p}$
\end{itheorem}
\begin{proof}
Aunque no lo vamos a demostrar.
\end{proof}


\begin{defn}[Problema\IS dual]
Sea $g(\vu,\vv)$ la función dual asociada a un problema $(PI)$.

\begin{ioprob}
\goal{$\max g(\vu,\vv)$}
\restrictions{$u≥0$}{}{}{}{}{}
\end{ioprob}
\end{defn}

\begin{itemize}
	\item Llamaremos \concept{problema\IS primal} al problema inicial.
	\item El problema dual es \textbf{siempre convexo}, independientemente de que lo sea o no el problema primal al que corresponde.
	\item Un punto $(\vu,\vv)$ con $\vu≥0$ y $g(u,v) < -∞$ se llama \concept{solución\IS factible dual}.
	\item Llamamos \concept{solución\IS factible dual óptima} al punto $(\vu,\vv)$ que resuelve el problema dual.
	\item El problema dual tiene conjunto factible convexo, función cóncava y es un problema convexo\footnote{No tengo muy claro cómo puede ser todo esto al mismo tiempo}. 
	El problema es que la función dual puede ser muy complicada.
\end{itemize}


\subsection{Problemas duales}

\paragraph{El problema dual de un problema lineal en forma estándar}

...

\paragraph{El dual de un problema lineal en forma canónica}

...

\paragraph{Ejemplos}

...


\begin{example} Escribe el dual de:

...

\begin{ioprob}
\goal{$\min -u_1 - u_2$}
\restrictions{$-u_2≥1$}{$u_2 ≤ 1-$}{$u_1-u_2≥-1$}{$u_1 ≥$}{$u_2≥0$}{}
\end{ioprob}

Aquí no tienen solución ni el factible ni el primal.
\end{example}

\subsubsection{Resumen}

A continuación, una tabla que resume el cálculo de problemas duales a partir de primales.
\begin{table}[hbtp]
\centering
\begin{tabular}{c|c|c}
Primal $\equiv$ (P) & $\begin{array}{c} \min c'x\\Ax = b\\x≥ 0\end{array}$ & $\begin{array}{c} \max c'x\\Ax ≤ b\\x≥ 0\end{array}$\\
\hline
Dual $\equiv$ (D) & $\begin{array}{c} \max b'u\\A'u ≥ c\end{array}$ & $\begin{array}{c} \max b'u\\A^\top u ≤ c\\u≥ 0\end{array}$\\
\end{tabular}
\caption{Resumen de pasar del problema primal al dual.}
\end{table}



\subsection{Dualidad fuerte y débil}


\begin{defn}[Dualidad\IS débil]
Sean $\bar{p},\bar{d}$ sendos valores óptimos del problema primal y su dual.

Entonces:\[\bar{p} ≤ \bar{d}\]
\end{defn}

De aquí podemos sacar 2 conclusiones:

\begin{itemize}
	\item Si el primal no es acotado ($\bar{p} = -∞$), entonces el dual no es factible.
	\item Si el dual no es acotado ($\bar{d} = ∞$), entonces el primal no es factible.
\end{itemize}


\begin{defn}[Dualidad\IS fuerte]
$\bar{p} = \bar{d}$
\end{defn}


\begin{theorem}[Dualidad fuerte para problemas lineales]

Consideremos un problema lineal en forma estándar $(P)$ y el correspondiente problema dual $(D)$. 

Si $(P)$ tiene solución factible óptima finita, también la tiene $(D)$ y los correspondientes valores óptimos son iguales.
\end{theorem}

\begin{proof}
\label{proof:dualidadFuerte}
\[u' \equiv c_B'B^{-1}\]

\[
\begin{array}{c}
u'b = c'_BB^{-1}b
c'x = c'_BB^{-1}n]c_N'0
\end{array}
\]


$u$ es factible para $(D)$ $\dimplies$ 

\[u'A ≤ c' = c'_BB^{-1}\left(B | N \right) ≤ (c'_B,c'_N)\dimplies \underbrace{c_B'B^{-1}N}_{z_j} ≤ c'_N\]

Demostrar que $u$ es factible es lo mismo que demostrar que $z_j ≤ c_j$ en la tabla del simplex. Como $\bar{x}$ es el óptimo, en la última fila de simplex tenemos todos $≤0$, con lo que $z_j ≤ c_j$

\paragraph{Conclusión: } Encontrar un óptimo para el primal es encontrar un factible para el dual.

\end{proof}

\obs
\[
\dpa{\bar{z}}{b_i} = u_i
\]

Es decir, el resultado de incrementar uno de los coeficientes del problema primal, corresponde al valor del multiplicador.

\paragraph{Dualidad fuerte para problemas lineas}
\begin{itemize}
	\item La condición de factibilidad de $\bar{u}$ equivale a la de optimalidad de $\gx$.
	\item Resolver el primal y el dual es equivalente a partir de la relación obtenida en la demostración \ref{proof:dualidadFuerte}:
	\[
		\bar{u}^\top =  c_B^\top B^{-1}
	\]
\end{itemize}

\subsection{Interpretación económica del problema dual}

La solución del problema dual del pastelero es $u = \left(\rfrac{1}{3},0,10\right)$, que son los valores que aparecían en el problema \ref{ejer:pastelero}. Además, vemos también que $\bar{p} = \bar{d} = 775$. Es decir, la dualidad es fuerte. 


En la solución de este problema (\ref{ejer:pastelero}), se preguntaba la modificación del valor objetivo al aumentar en 1 cada una de las cantidades y la solución obtenida se corresponde con la solución del problema dual,
como nos indicaba la observación anterior.


\subsection{Algoritmo simplex-dual}

\paragraph{Motivación:} 
Tenemos un problema de programación lineal que resolvemos con simplex normal. 
Llegamos a una solución óptima que es factible del dual. Ahora, imaginemos que cambiamos $b$, con lo que las restricciones dejan de cumplirse. El estado de la tabla del simplex se mantiene, salvo la columna de la izquierda. 
Este es un punto de partida para este algoritmo. Otro caso ventajoso de este algoritmo se da al tener ¿coeficientes negativos?





\begin{example} Resolver el problema:

...

Lo primero es pasarlo a forma estándar:


\begin{ioprob}
\goal{$\min{3x_1 + 2x_2}$}
\restrictions{$3x_1-x_2+x_3 = -3$}{...}{...}{...}{...}{...}
\end{ioprob}


En este caso, no podemos empezar con el algoritmo del simplex, porque hay $b_i< 0$. Pero tendríamos una solución óptima si fuera factible. Al ser óptima en el primal, es factible en el dual y podemos aplicar el algoritmo del simplex-dual.
Vamos a ver la evolución de las tablas.


\paragraph{Vamos a verlo gráficamente paso a paso}

\begin{figure}[hbtp]
\centering
\begin{tikzpicture}[scale=1.5]
\draw[thick,->] (0,0) -- (3.5,0);
\draw[thick,->] (0,0) -- (0,3.5);
\draw[thick,-] (3,0) -- (0,3);
\draw[thick,-] (1,0) -- (0,3);
\draw[thick,-] (1.5,0) -- (0,2);
\filldraw[fill=blue, opacity = 0.4] (3/5,6/5) -- (1.5,0) -- (3,0) -- (0,3) -- cycle;
\node [label={below:$(1)$},nodepoint, inner sep=2pt,color=red] at (0,0) {};
\node [label={left:$(2)$},nodepoint, inner sep=2pt,color=blue] at (0,2) {};
\node [label={below left:$(3)$},nodepoint, inner sep=2pt,color=green] at (3/5,6/5) {};
\end{tikzpicture}
\caption{Evolución del algoritmo del simplex-dual.}
\end{figure}


\end{example}