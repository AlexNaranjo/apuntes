\documentclass[palatino, bibnumbers]{apuntes}

\title{Geometría y Topología}
\author{Jose Antonio García del Saz}
\date{16/17 C2}

% Paquetes adicionales
\usepackage{enumitem}
\usepackage{kpfonts}
\usepackage{tikztools}
\usepackage{fancysprefs}
\usepackage{tikz-3dplot}
\usepackage{physics}
\usepackage{xfrac}
\usepackage{wrapfig}
\usepackage{fastbuild}
%\usepackage{lipsum}
\usepackage{tikz-cd}
\usetikzlibrary{calc,patterns,angles,quotes}
\usetikzlibrary{arrows}
\usetikzlibrary{patterns}
\usetikzlibrary{intersections}
\usetikzlibrary{calc}
\usetikzlibrary{fadings}

\tikzset{
	snake/.style={
		rounded corners,
		to path={
			-- ([xshift=1em]\tikztostart.east)
			-- ([xshift=1em]\tikztostart.south east)
			-- ([xshift=-1em]\tikztotarget.north west)
			-- ([xshift=-1em]\tikztotarget.west)
			-- (\tikztotarget)
		}
	},
	snake up/.style={
		rounded corners,
		to path={
			-- ([xshift=-1em]\tikztostart.west)
			-- ([xshift=-1em]\tikztostart.north west)
			-- ([xshift=1em]\tikztotarget.south east)
			-- ([xshift=1em]\tikztotarget.east)
			-- (\tikztotarget)
		}
	}
}

\setlist{itemsep=1pt, topsep=5pt}
\bibliographystyle{alpha}
% --------------------

%\precompileTikz

\newcommand{\Id}{\mop{Id}}
\newcommand{\cln}{\colon\!}

\setcounter{tocdepth}{3}

\begin{document}
\pagestyle{plain}
\newcommand\tab[1][1cm]{\hspace*{#1}}
% http://tex.stackexchange.com/a/14243
\relpenalty=9999
\binoppenalty=9999
%\newcommand\restr[2]{\ensuremath{\left.#1\right|_{#2}}}
\begin{abstract}
Estos son los apuntes del curso de Geometría y Topología, del profesor Fernando Chamizo.
\end{abstract}

\maketitle

\tableofcontents
\newpage
% Contenido.

\chapter{Álgebra Tensorial}

\section{Tensores en  $ℝ^{n}$}
\subsection{Definiciones y ejemplos}
Estudiar los tensores en $ℝ^n$ es en realidad estudiar el Álgebra Lineal pero en varias variables. En primer curso (Álgebra I) estudiamos las aplicaciones, las cuales eran de la forma:
\begin{align*}
	\appl{π}{ℝ^{n}&}{ℝ^{m}} \\
	\overline{x} &\longmapsto[\overline{y}=A\cdot \overline{x}]
\end{align*}

\begin{defn}[Aplicación\IS lineal] Sea $f$ una aplicación entre dos espacios vectoriales $V$, $W$ sobre el mismo cuerpo $K$. Decimos que $f$ es una \textbf{aplicación lineal} si se cumplen las siguientes propiedades ($λ\in K$):
	\begin{enumerate}
		\item $f(λ\overline{x})=λ\cdot f(\overline{x})$ .
		\item $f(\overline{x_1}+\overline{x_2})=f(\overline{x_1})+f(\overline{x_2})$
	\end{enumerate}
\end{defn}

\begin{defn}[Aplicación\IS bilineal] Sea 
	\begin{align*}
	\appl{f}{ℝ^{n}×ℝ^{n}&}{ℝ} \\
	\overline{x},\overline{y} &\longmapsto{f(\overline{x},\overline{y})}
	\end{align*}
una aplicación, decimos que es \textbf{bilineal} si es una aplicación lineal en cada una de las dos variables, es decir:
\begin{enumerate}
	\item $f(λ\overline{x},\overline{y})=λ\cdot f(\overline{x},\overline{y})$; $f(\overline{x_1}+\overline{x_2},\overline{y})=f(\overline{x_1},\overline{y})+f(\overline{x_2},\overline{y})$
	\item $f(\overline{x},λ\overline{y})=λ\cdot f(\overline{x},\overline{y})$; $f(\overline{x},\overline{y_1}+\overline{y_2})=f(\overline{x},\overline{y_1})+f(\overline{x},\overline{y_2})$
\end{enumerate}
\end{defn}
\textbf{Observación:} todas las aplicaciones bilineales entre dos espacios se pueden escribir de la siguiente manera:
$$f(\overline{x},\overline{y})=\overline{x}^{T}A\overline{y}$$ con A una matriz n×n.
\newpage
\begin{defn}[Aplicación\IS multilineal] Decimos que una aplicación es \textbf{multilineal} si es lineal en cada una de sus variables. 
\end{defn}

\begin{defn}[Tensor\IS n veces covariante] Es cualquier aplicación multilineal
	$\appl{T}{\varprod_{i=1}^n V}{ℝ}$, siendo V un espacio vectorial de dimensión finita sobre $ℝ$ (que como sabemos de otros cursos son isomorfos a $ℝ^{n}$).
\end{defn}

\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_1\cdot y_3}
	\end{align*}
es obvio que T es multilineal, luego T es un tensor 2 veces covariante en $ℝ^{3}$.
\end{example}
\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_1\cdot x_3}
	\end{align*}
	se ve rápidamente que \underline{no} es una aplicación lineal respecto de la variable $\overline{x}$.
\end{example}
\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix},\begin{pmatrix}z_1\\z_2\\z_3\end{pmatrix}\right) &\longmapsto{\begin{vmatrix}
			x_1 & y_1 &  z_1 \\ 
			x_2 & y_2 & z_2 \\ 
			x_3 & y_3 & z_3 \\ 
		\end{vmatrix}}
	\end{align*}
	la propiedad de linealidad del producto por un escalar es obvia por las propiedades de los determinantes. La propiedad de linealidad que conserva la adición se demuestra fácilmante desarrollando el determinante por adjuntos en la primera columna. Luego T es un tensor 3 veces covariante.
\end{example}
\newpage
En Álgebra Lineal estudiamos no sólo las aplicaciones $\appl{T}{ℝ^{n}}{ℝ}$ , sino también las de la forma $\appl{T}{ℝ^{n}}{ℝ^{m}}$. Ahora bien, estás últimas pueden convertirse al primer tipo mediante un elemento del \textbf{espacio dual}.

\begin{defn}[Espacio\IS dual] Sea V un espacio vectorial entonces se define el espacio dual y se denota con $V^{*}$ de la siguiente manera: \[ V^{*} = \{ \appl{f}{V}{ℝ} \tq \text{f es lineal} \}\]
\end{defn}

Con la definición anterior, un truco para pasar de unas aplicaciones a otras es que consideramos un elemento del espacio dual ($\phi\inℝ^{m}$) y uno del espacio vectorial original ($\overline{x}\inℝ^{n}$) y entonces tenemos una aplicación $$\hat{f}(\phi,\overline{x})=\phi(f(\overline{x}))\inℝ$$

De la misma manera, en lugar de considerar "tensores vectoriales" (esta expresión no es correcta, pero se da para ilustrar), los cuales serían aplicaciones multilineales $\appl{T}{\varprod_{1}^s V}{\varprod_{1}^r V}$, es más conveniente pensar en que el tensor va a depender también de los elementos del espacio dual. Luego vamos a considerar tensores de la forma $$\appl{T}{\underbrace{V^{*}×\cdots×V^{*}}_{\text{r veces}}×\underbrace{V×\cdots×V}_{\text{s veces}}}{ℝ}$$ que sean multilineales.

\begin{defn}[Tensor\IS r veces contravariante y s veces covariante] Es cualquier aplicación multilineal de la forma:
	$$\appl{T}{\underbrace{V^{*}×\cdots×V^{*}}_{\text{r veces}}×\underbrace{V×\cdots×V}_{\text{s veces}}}{ℝ}$$ siendo V un espacio vectorial de dimensión finita sobre $ℝ$ (isomorfo a $ℝ^{n}$) y $V^{*}$ su espacio dual. Diremos análogamente que T es un tensor de tipo (r,s).
\end{defn}

Como ya sabemos, si V es un espacio vectorial y tenemos una base de V (llamémosla $\base = \{ \overline{v_1},...,\overline{v_n} \}$), entonces existe una base natural de $V^{*}$
llamada \textbf{base dual} (denotada por $\base^{*}=\{\tilde{\phi}^{1},\cdots ,\tilde{\phi}^{n}\}$) y que está determinada por la propiedad: $$\tilde{\phi}^{i}(\overline{v_j})=\delta_j^{i} = \begin{cases} 0 & i ≠ j \\ 1 & i = j \end{cases}$$
\newpage
\begin{example} Daremos un ejemplo casi absurdo para ilustrar. Dar la base dual es muy fácil cuando tenemos una base ortonormal, por ejemplo la base canónica de $ℝ^{2}$:
$$\base = \{\overline{e_1},\overline{e_2}\}=\left\{\begin{pmatrix}1\\0\end{pmatrix},\begin{pmatrix}0\\1\end{pmatrix}\right\}$$En este caso obtenemos la base dual solamente girando los elementos de la base canónica, obteniendo: $$\base^{*} =\{\tilde{\phi^{1}},\tilde{\phi^{2}}\}=\left\{\begin{pmatrix}1&0\end{pmatrix},\begin{pmatrix}0&1\end{pmatrix}\right\}$$
\end{example}
\begin{example} Imaginemos que estamos en $ℝ^{2}$ pero en esta ocasión tenemos una cualquiera de sus bases $\base=\{\overline{v_1},\overline{v_2}\}$. Ahora consideramos la matriz $A=\begin{pmatrix}v_{11}&v_{21}\\v_{12}&v_{22}\\ \end{pmatrix}$, y entonces tenemos que $\begin{cases}\overline{v_1}=A\cdot \overline{e_1} \\\overline{v_2}=A\cdot \overline{e_2}\end{cases}$. Construímos entonces la base dual $\base^{*}=\{ \tilde{\phi^{1}},\tilde{\phi^{2}}\}$ de esta manera con la matriz de cambio de base: $\begin{cases} \tilde{\phi^{1}}(\overline{x})=\begin{pmatrix}0&1\end{pmatrix}\cdot A^{-1}\cdot \overline{x} \\\tilde{\phi^{2}}(\overline{x})=\begin{pmatrix}1&0\end{pmatrix}\cdot A^{-1}\cdot \overline{x}\end{cases}$
\end{example}
\begin{example} Si f es un \textit{endomorfismo}, digamos $\appl{f}{ℝ^{n}}{ℝ^{n}}$, se corresponde de manera unívoca con un tensor de tipo (1,1):
	\begin{align*}
	\appl{T}{(ℝ^{n})^{*}×ℝ^{n}&}{ℝ} \\
	T(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}(f(\overline{x}))}
	\end{align*}
\end{example}
\begin{example} Cualquier vector de un espacio vectorial ($\overline{v}\in V$) se puede hacer corresponder con un tensor (1,0)  que se alimenta de elementos del dual y devuelve reales definido como:
	\begin{align*}
	\appl{T_{\overline{v}}}{V^{*}&}{ℝ} \\
	T_{\overline{v}}(\tilde{\phi}) &\longmapsto{\tilde{\phi}(\overline{v})}
	\end{align*}
\end{example}

Vamos a introducir notación para las definiciones y resultados venideros, y hay que hacerla nuestra ya que es el infierno de casi todos los estudiantes al abrir un libro de cálculo tensorial. De aquí en adelante (aunque se venga haciendo desde el inicio) se usarán \textbf{subíndices} para numerar vectores ($\overline{v_1},\overline{v_2},...,\overline{v_n}$) y \textbf{superíndices} para numerar elementos del espacio dual, aunque también sean vectores ($\tilde{\phi^{1}},\tilde{\phi^{2}},...,\tilde{\phi^{n}}$) .
\newpage
\begin{defn}[Componentes\IS de un tensor] Sea un tensor $T$ de tipo (r,s) y sean $\base=\{\overline{v_1},...,\overline{v_n}\}$, $\base^{*}=\{\tilde{\phi^{1}},...,\tilde{\phi^{n}}\}$ las bases de $V$ y $V^{*}$ respectivamente, se definen las componentes de $T$ en la base $\base$ como la siguiente colección de números:
	$$T_{j_1\space j_2\space \cdots \space j_s}^{i_1\space i_2\space \cdots \space i_r}=T(\tilde{\phi^{i_1}},\tilde{\phi^{i_2}},...,\tilde{\phi^{i_r}},\overline{v}_{j_1},\overline{v}_{j_2},...,\overline{v}_{j_s})$$
\end{defn}
\begin{example} Calcular las componentes del tensor:
	\begin{align*}
	\appl{D}{ℝ^{2}×ℝ^{2}&}{ℝ} \\
	D\left(\begin{pmatrix}x_1\\x_2\end{pmatrix},\begin{pmatrix}y_1\\y_2\end{pmatrix}\right) &\longmapsto{\begin{vmatrix}
		x_1 & y_1 \\ 
		x_2 & y_2 \\ 
		\end{vmatrix}}
	\end{align*}
	Lo primero que hacemos es coger una base (cogemos la canónica porque será lo más usual este curso). Como es un tensor (0,2), no habrá superíndices en las componentes, sólo subindices. Las componentes son: $$D_{j_1\space j_2}=\begin{cases}
		D_{1\space1}=D(\overline{e_1},\overline{e_1})=\begin{vmatrix}1&1 \\ 0&0 \\ \end{vmatrix}=0\\
		D_{1\space2}=D(\overline{e_1},\overline{e_2})=1\\
		D_{2\space1}=-1\\
		D_{2\space2}=0\\
	\end{cases}$$
\end{example}
\subsection{Convenio de Einstein}
Se usa para ahorrar en escritura cuando se habla del álgebra tensorial. En resumen consiste en que cuando se repite un índice arriba y abajo entonces hay que suponer que sumamos en él.
\begin{example} En primer curso, la combinación lineal se escribía como: $λ_1\cdot \overline{v_1}+\cdots +λ_n\cdot \overline{v_n}$. Si usamos el convenio esto se escribiría simplemente como $λ^{i}\cdot \overline{v}_i$
\end{example}
\begin{example} Sea una aplicación lineal $f(\overline{x})=A\cdot \overline{x}$, se corresponde unívocamente con un tensor (1,1):
	\begin{align*}
		\appl{T}{(ℝ^{n})^{*}×ℝ^{n}&}{ℝ} \\
		T(\tilde{\phi},\overline{v}) &\longmapsto{\tilde{\phi}(\overline{v})}
	\end{align*}
Las componentes (en la base canónica) son las $a_j^{i}$, donde $i$ son las filas y $j$ las columnas.
$$f(\overline{x})=a_j^{i}\cdot x^j;\overline{x}=x^j\cdot \overline{e_j}$$
Las componentes $T_j^{i}\equiv T(\tilde{\phi}^{i},\overline{e_j})=\begin{pmatrix}0&\cdots & 1 & \cdots &0\end{pmatrix}\cdot A\cdot \begin{pmatrix}
0 \\ \cdots \\ 1 \\ \cdots\\0\end{pmatrix}=a_j^{i}$
\end{example}
\newpage
\begin{example} Un tensor (1,3) muy importante es el llamado tensor de Riemann $\appl{T}{R=V^{*}×V×V×V}{ℝ}$. En relatividad $dim V = 4$ y tiene $4\cdot 4\cdot 4\cdot 4=256$ componentes y, para aplicarlo a un elemento del dual, digamos con componentes $(a_1,a_2,a_3,a_4)$, y a tres vectores, con coordenadas$(b_1,b_2,b_3,b_4), (c_1,c_2,c_3,c_4), (d_1,d_2,d_3,d_4)$, debemos escribir:
$$\sum_{i=1}^{4}\sum_{j=1}^{4}\sum_{k=1}^{4}\sum_{l=1}^{4}R_{j\space k\space l}^{i}a_i\space b^{j}\space c^{k}\space d^{l}$$
Esta expresión tiene demasiados sumatorios, si la reescribimos con el criterio de Einstein queda $R_{j\space k\space l}^{i}a_i\space b^{j}\space c^{k}\space d^{l}$\newline
\end{example}
\begin{defn}[Producto\IS tensorial] Sea T un tensor de tipo (r,s) y sea S otro tensor de tipo (u,v), de define su producto tensorial $T\otimes S$ como un nuevo tensor de tipo (r+u,s+v): $$T\otimes S(\tilde{\phi^{1}},\cdots ,\tilde{\phi^{r+u}})=T(\tilde{\phi^{1}},\cdots ,\tilde{\phi^{r}},\overline{v}_1,\cdots,\overline{v}_s)\cdot S(\tilde{\phi^{r+1}},\cdots ,\tilde{\phi^{r+u}},\overline{v}_{s+1},\cdots,\overline{v}_{s+v})$$
\end{defn}
\begin{example}Tomaremos estos dos tensores de tipo (0,1) en $ℝ^{2}$: $$T(\overline{x})=2\cdot x^{1}+x^{2}; S(\overline{x})=5\cdot x^{1}$$ y hallaremos ahora las componentes de $T\otimes S$, que será por definición un nuevo tensor de tipo (0,2), de la forma $\appl{T\otimes S}{ℝ^{2}×ℝ^{2}}{ℝ}$, y le llamaremos P a partir de ahora. Entonces tenemos que: $$\begin{cases}
	P_{1\space1}=P(\overline{e}_1,\overline{e}_1)=10\\
	P_{1\space2}=0\\
	P_{2\space1}=P(\overline{e}_2,\overline{e}_1)=5\\
	P_{2\space2}=0\\
	\end{cases}$$
	
\end{example}
\begin{example}En física e ingeniería se consideran muchos tensores importantes. Por ejemplo, el \textbf{tensor de inercia} es un tensor de tipo (0,2) que mide (entre otras cosas) lo difícil que es girar un sólido rígido respecto a un eje dado (en términos físicos es difícil si necesito un gran \textbf{trabajo} para girarlo).\\
	$$
	\begin{tikzpicture}
	\draw (-1,0) arc (180:360:1cm and 0.5cm);
	\draw[dashed] (-1,0) arc (180:0:1cm and 0.5cm);
	\draw (0,0) circle (1cm);
	\shade[ball color=blue!10!white,opacity=0.20] (0,0) circle (1cm);
	\draw[thick,->] (0,-1.5,0) -- (0,1.5,0) node[above]{$eje$};
	\end{tikzpicture}
\tab
	\begin{tikzpicture}
	\draw (-1,0) arc (180:360:1cm and 0.5cm);
	\draw[dashed] (-1,0) arc (180:0:1cm and 0.5cm);
	
	\draw (0,0) circle (1cm);
	\shade[ball color=blue!10!white,opacity=0.20] (0,0) circle (1cm);
	\draw[thick,->] (-0.9,-1.5,0) -- (-0.9,1.5,0) node[above]{$eje$};
	\end{tikzpicture}
	$$
Por ejemplo, en la figura, suponiendo que es una esfera que pesa toneladas, la intuición nos dice sin hacer cálculos que costará menos rotar la esfera respecto al primer eje que rotarla respecto al segundo (y estamos en lo cierto).
\end{example}
\begin{example}Los tensores también aparecen en el \textbf{entrelazamiento cuántico}, dentro del campo de la mecánica cuántica.
Una partícula se corresponde con un vector, que como sabemos se corresponde con un tensor (1,0). Pues si tenemos dos partículas $\overline{v}$ y $\overline{w}$, entonces el sistema formado por ambas partículas es  $\overline{v}\otimes\overline{w}$.
\end{example}
\section{Repaso (intuitivo) de Geometría Diferencial}
Empezaremos con el objeto matemático al que llamamos \textbf{variedad}. Como idea, una variedad es un objeto geométrico que se puede parametrizar por abiertos de $ℝ^{n}$, pero el gran salto con respecto de la geometría de la asignatura de GCS, es que la variedad no está inmersa en $ℝ^{n}$, sino que está ahí (como el universo), sin preocuparnos lo que sea que la rodea.\newline
\indent La idea de variedad diferenciable n-dimensional es, por tanto, la de un objeto geométrico compuesto por parches que son similares a abiertos de $ℝ^{n}$. Partimos de un espacio topológico M al que exigimos que tenga la propiedad de Hausdorff y una base numerable (segundo axioma de numerabilidad). La primera propiedad es natural si queremos poder tratar separadamente los puntos, y las segunda va también en este sentido, porque permite asegurar la existencia de particiones de la unidad, que son totalmente necesarias para hacer el an análisis local típico de la geometría diferencial.
Una carta nos dice la manera de allanar un parche de M en $ℝ^{n}$ (es la inversa de la parametrización en ese abierto de $ℝ^{n}$).
$$\includegraphics{img/GT17_Variedad_carta}$$
El número de parámetros que la parametrización requiere es llamado en geometría \textbf{dimensión} de la variedad (mientras en mecánica lo llamaríamos \textbf{grados de libertad}). Si llamamos $\phi$ a la inversa de la parametrización (la carta), entonces tendremos (mirar figura superior) algo como $\phi(x^{1},\cdots,x^{n})$, que nos lleva a $ℝ^{n}$ y donde $x^{i}$ son lo que llamamos \textbf{funciones coordenadas}. Vamos a formalizarlo rápidamente para no empezar a divagar.

\begin{defn}[Carta\IS n-dimensional] Una carta n-dimensional de M es un par $(\mathcal{U},\phi)$ donde $\mathcal{U}$ es un abierto
de M y $\phi$ es una función $\appl{\phi}{\mathcal{U}}{ℝ^{n}}$ que es homeomorfismo sobre su imagen.
\end{defn}

Como un punto puede estar tapado por varios parches, diferentes abiertos de cartas, debemos asegurarnos de que el análisis no se estropea bajando por una $\phi$ o por otra. Una de las cosas que se suelen pedir en Geometría Diferencial es que si existe otra parametrización $\psi$, entonces tanto $\psi\circ\phi$ como $\phi\circ\psi$ han de ser de clase $C^{\infty}$ (En el abierto intersección de $ℝ^{n}$), y en ese caso se dice que las cartas son \textbf{compatibles} 

\begin{defn}[Derivada parcial i-ésima en una variedad] Se dice que una función $\appl{f}{M}{ℝ}$ es $C^{\infty}$ si para cada carta $(\mathcal{U},\phi)$ la función $\appl{f\circ \phi^{-1}}{\phi(\mathcal{U})}{ℝ}$ lo es, y se define para cada $p \in \mathcal{U}$ la derivada parcial i-ésima en la variedad como $$\restr{\pdv{f}{x^{i}}}{p}=D_i(f\circ \phi^{-1})(\phi(p))$$ donde $D_i$ denota la derivada parcial usual respecto de la variable i-ésima.
\end{defn}

No daremos la definición rigurosa, pero sí diremos que a las funciones $C^{\infty}$ entre dos variedades $M$ y $N$ que tienen inversa $C^{\infty}$ se llaman \textbf{difeomorfismos}
\newpage
Un problema técnicamente más complejo es la definición del \textbf{espacio tangente}, que en el caso de subvariedades de $ℝ^{n}$ es muy fácil. No es una mera adaptación porque allí los vectores tangentes eran “pelos” orientados que se salían de la subvariedad, mientras que ahora concebimos las variedades como una entidad única, sin referencia a un posible “exterior”. Hay varias maneras de superar este obstáculo. Aquí mencionaremos las definiciones matemáticas que corresponden a ver los vectores tangentes como velocidades de curvas y como derivadas direccionales. La segunda es más abstracta, se hace introduciendo implícitamente el concepto de derivación.

\begin{defn}[Espacio\IS tangente de una variedad] Se llama espacio tangente de una variedad M en un punto p al conjunto cociente $T_p(M)=K_p(M) /\sim$ donde $K_p(M)=\{ $Funciones $\appl{c}{(-\epsilon,\epsilon)}{M}$ con $c(0)=p \}$ y $\sim$ identifica las funciones curvas tales que $(\phi\circ c_1)'(0)=(\phi\circ c_2)'(0)$ con $(\mathcal{U},\phi)$ una carta. Se llama \textbf{vector tangente} de M en p a cualquiera de sus elementos.
\end{defn}

\begin{defn}[Vector\IS tangente en una variedad] Se llama vector tangente de $M$ en $p$ a cualquier operador $ℝ$-lineal $\appl{v}{E_p(M)}{ℝ}$ que satisface $v(fg)=v(f)g(p)+f(p)v(g)$ para todo $f,g \in E_p(M)$, donde $E_p(M)$ es el anillo de funciones $M\longmapsto ℝ$ definidas en un entorno suficientemente pequeño de p. Se llama espacio tangente de $M$ en un punto $p$ al conjunto formado por todos los vectores tangentes.
\end{defn}

A partir de las curvas que corresponden a los ejes coordenados (una vez que bajamos a $ℝ^{n}$ por la carta) se obtienen unos vectores tangentes que denotaremos con el extraño nombre $\restr{\pdv{}{x^{i}}}{p}$. Para ser rigurosos, si $\{\overline{e}_1,\overline{e}_2,\cdots,\overline{e}_n\}$ es la base canónica, fijada una carta $(\mathcal{U},\phi=(x^1,\cdots,x^n))$ con la primera definición se tiene $$\restr{\pdv{}{x^{i}}}{p}=[c_i]\tab con \tab c_i(t)=\phi^{-1}(\phi(p)+t\overline{e}_i),\tab i=1,2,...,n $$

Denominar a estos vectores con el mismo símbolo que el de las derivadas parciales no es casual, pues con la segunda definición no son más que las derivadas parciales i-ésimas en la varidad, es decir 
\begin{equation}
\appl{\restr{\pdv{}{x^{i}}}{p}}{f}{\restr{\pdv{f}{x^{k}}}{p}}
\end{equation}
Por razones obvias se les suele denotar con la notación abreviada $\restr{\partial_i}{p}$, o incluso $\partial_i$ si el punto no se indica.
\begin{prop} El espacio tangente $T_p(M)$ tiene una estructura natural de espacio vectorial cuya dimensión es la de la variedad diferenciable M.
\end{prop}
\begin{prop} Para cada punto p de una variedad diferenciable n-dimensional $M$, el conjunto $\{\restr{\partial_1}{p},\restr{\partial_2}{p},\cdots,\restr{\partial_n}{p}\}$ es una base de $T_p(M)$.
\end{prop}
Hasta aquí , si aún no nos hemos quitado la vida con la notación, podemos proceder.
\newpage
Con $\appl{f}{M}{N}$ podemos pasar curvas en curvas lo cual induce una aplicación $T_p(M)\longmapsto T_{f(p)}(N)$. Aunque ésta es la idea intuitiva, es más sintético proceder tomando en cuenta la segunda definición de espacio tangente.

\begin{defn}[Aplicación\IS tangente] Sea $\appl{f}{M}{N}$. Se llama aplicación tangente de f en p y se denota con $\restr{\dv{f}}{p}$, a la aplicación lineal $T_p(M)\longmapsto T_{f(p)}(N)$ que aplica un elemento de $T_p(M)$ (considerado con la segunda definición), digamos $v(\cdot)$ en $v(\cdot\circ f)$
\end{defn}
\begin{prop} Sea $\appl{f}{M}{N}$ y sean $(\mathcal{U}(p),\phi)$ y $(\mathcal{V}(f(p)),\psi)$ cartas de M y N respectivamente en los puntos indicados. La matriz de la aplicación tangente $\restr{df}{p}$ en las bases $\{\restr{\pdv{}{x^1}}{p},\cdots,\restr{\pdv{}{x^m}}{p}\}$ y $\{\restr{\pdv{}{y^1}}{f(p)},\cdots,\restr{\pdv{}{y^n}}{f(p)}\}$ correspondientes a estas cartas es la matriz jacobiana de $\psi\circ f\circ\phi^{-1}$ en $\phi(p)$.
\end{prop}

Dada una carta $(\mathcal{U},\phi=(x^1,\cdots,x^n))$ de M tiene sentido considerar las aplicaciones tangentes de las funciones coordenadas $\restr{dx^{i}}{p}$ como funciones de $M$ en $ℝ$ con la estructura de variedad obvia. Usando las definiciones de vector tangente se puede probar que $$\restr{dx^{i}}{p}(\restr{\pdv{}{x^j}}{p})=\delta_j^i$$ o dicho de otra forma $$\{\restr{dx^1}{p},\restr{dx^2}{p},\cdots,\restr{dx^n}{p}\}\tab \text{es la base dual de} \tab\{\restr{\pdv{}{x^1}}{p},\restr{\pdv{}{x^2}}{p},\cdots,\restr{\pdv{}{x^n}}{p}\}$$

\begin{defn}[Espacio\IS cotangente] Dada una carta $(\mathcal{U},\phi=(x^1,\cdots,x^n))$ de $M$, al espacio vectorial sobre $ℝ$ generado por $\{\restr{dx^1}{p},\restr{dx^2}{p},\cdots,\restr{dx^n}{p}\}$ se denomina espacio cotangente de M en p y se denota con $T_p^{*}(M)$, por ser el dual de $T_p(M)$.
\end{defn}

\begin{defn}[Uno forma] Los elementos de $T_p^{*}(M)$ se llaman uno formas (o covectores).
\end{defn}

Como cabía esperar, en lo sucesivo descargaremos la notación para las aplicaciones tangentes y las bases introducidas de $T_p(M)$ y $T_p^{*}(M)$ omitiendo el punto cuando no sea relevante. Por ejemplo, escribiremos $dx^1$ en lugar de $\restr{dx^1}{p}$.

Una vez más insistimos en que todos los espacios vectoriales sobre $ℝ$ son lo mismo, y una vez fijadas las bases las operaciones se realizan coordenada a coordenada como nos enseñaron en primero cuando casi todo era con vectores de $ℝ^{n}$. Los elementos del dual no albergan nada nuevo y siguen funcionando como se indicó en la sección anterior (y en el curso de primero) por mucho que pongamos $d$ y $\partial$ por todos los lados. En un ejemplo: \\ $$(2dx^1+3dx^2)(2\pdv{}{x^1}-\pdv{}{x^2})=1 \tab\text{porque}\tab \begin{pmatrix}2&3\end{pmatrix}\begin{pmatrix}2\\-1\end{pmatrix}=1$$
\newpage
\section{Tensores en el espacio tangente}
Ya hemos visto tensores en $ℝ^{n}$, veamos que pasa cuando consideramos los tensores en las variedades en general. Podemos considerar tensores cuyo espacio vectorial subyacente sea el espacio tangente de la variedad en cada punto, y cuyo dual es el cotangente: $$V=T_p(M)\tab V^*=(T_p(M))^*$$
Será conveniente permitir variar el punto y tener entonces un \textbf{campo de tensores} (un tensor definido en cada punto de la variedad) y queremos que sea diferenciable (en algún sentido).\\ 
Para hacer la teoría más sintética, es conveniente introducir el \textbf{fibrado}, tanto tangente como cotangente: $$TM=\bigcup\limits_{p\in M} T_p(M)\tab T^*M=\bigcup\limits_{p\in M} (T_p(M))^* $$ con cierta estructura de variedad. En física a esto se le llama \textbf{espacio de fases} (partículas elementales).

\begin{defn}[Tensor\IS en una variedad] Sea $M$ una variedad. Un tensor (en rigor, campo tensorial) $C^{\infty}$ de tipo $(r,s)$ en $M$ es una aplicación que a cada punto $p$ le asigna un tensor de tipo $(r,s)$ con $V=T_p(M)$ y $V^*=(T_p(M))^*$ y tal que en cada carta las componentes sean funciones $C^{\infty}$.
\end{defn}

\begin{defn}[Métrica] Una métrica en una variedad es un tensor de tipo (0,2) en dicha variedad tal que si en una carta $(g_{i\space j})$ es la matriz de componentes, entonces esta matriz es simétrica y no singular.
\end{defn}

\begin{example}En $ℝ^{2}$ con la carta identidad tenemos $G=dx\otimes dx+dy\otimes dy$. Tomemos $\overline{v}=a^i\pdv{}{x^i}$ y $\overline{w}=b^i\pdv{}{x^i}$, ambos en $ℝ^{2}$, y entonces con la métrica G: $$G(\overline{v},\overline{w})=dx(\overline{v})\cdot dx(\overline{w})+dy(\overline{v})\cdot dy(\overline{w})=a^1+b^1\cdot a^2+b^2$$ que es el producto escalar usual.
\end{example}
\begin{example}\textbf{(Métrica de Poincaré)}\indent En $ℝ×ℝ^+$ se define la métrica:\space$G=y^{-2}(dx\otimes dx+dy\otimes dy)$. Sea $\overline{v}=3\restr{\pdv{}{x}}{p}+\restr{4\pdv{}{y}}{p}$; para $p=(0,1)$; entonces $G(\overline{v},\overline{v})=3^2+4^2=25$. Y si $\overline{w}=3\restr{\pdv{}{x}}{q}+\restr{4\pdv{}{y}}{q}$; para $q=(0,5)$; entonces $G(\overline{w},\overline{w})=1$.
\end{example}
\begin{example}\textbf{(Métrica alrededor de un agujero negro)}\indent Se define como $$G=-\left(1-\frac{r_0}{r}\right)dt\otimes dt+\left(1-\frac{r_0}{r}\right)^{-1}dr\otimes dr$$ donde r es la distancia al centro, t es el tiempo y $r_0$ una constante.
\end{example}
\newpage
\begin{example}\textbf{(Componentes de la métrica usual en $ℝ^2$ )}\indent Tenemos la métrica usual del producto escalar con componentes: $$\begin{cases}
	g_{1\space1}=1 \tab g_{1\space2}=0\\
	g_{2\space1}=0 \tab g_{2\space2}=1\\
	\end{cases}$$
	En general, una métrica es de la forma $G=g_{i\space j}dx^i\otimes dx^j$. En la matriz de componentes de la métrica usual nos encontramos con la identidad (simétrica y no singular).
\end{example}

\begin{example}\textbf{(Componentes de la métrica de Poincaré )}\indent Se tienen las componentes:$$G=(g_{i\space j})=\begin{pmatrix}y^{-2}&0\\0&y^{-2}\\ \end{pmatrix}$$ Lo mas importante de los tensores en variedades es saber como se comportan sus componentes por cambios de carta.
\end{example}

Si tenemos un tensor T en una variedad M para cierta carta, el tensor no depende de la carta pero las componentes si: $$\tilde{T}^{i_1,\cdots,i_r}_{j1,\cdots,j_s}=\pdv{y^{i_1}}{x^{k_1}}\cdots\pdv{y^{i_r}}{x^{k_r}}\pdv{x^{l_1}}{y}\cdots\pdv{x^{l_s}}{y^{j_s}}\cdot T^{k_1,\cdots,k_r}_{l_1,\cdots,l_s},\tab\text{para }\psi=(y^1,\cdots,y^n)$$
Esto se deduce por la regla de la cadena de la sigiente manera: $$\pdv{y^j}=\pdv{x^i}{y^j}\pdv{x^i};\tab dy^j=\pdv{y_j}{x^i}dx^i;$$
Por definición tendriamos que $\tilde{T}^{i_1\cdots i_r}_{j_1,\cdots,j_s}=T(dy^{i_1},\cdots,dy^{i_r},\pdv{y^{j_1}},\cdots,\pdv{y^{j_s}})$.
Si recordamos la definición de métrica como tensor $(0,2)$ en una variedad cuya matriz de componentes es simétrica y no singular nos preguntamos si podemos pasar los tensores de una variedad $M$ a tensores en una variedad $N$ por medio de una aplicación. Y la respuesta es que no es tan trivial como parece. 

\begin{defn}[Pull-back] Sea un tensor $T$ de tipo $(0,s)$ en la variedad N, se llama pull-back (o en español menos popularmente imagen recíproca) al tensor de tipo $(0,s)$ en $M$ definido por la siguiente expresión: $$f^*T(\overline{v}_1,\cdots,\overline{v}_s)=T(df(\overline{v}_1),\cdots,df(\overline{v}_s))$$
\end{defn}

El pull-back será muy interesante cuando estudiemos las formas diferenciables. Para los tensores $(r,s)$ no está bien definida por no saber como tratar con los elementos del dual, y para los de tipo $(r,0)$ hay otra cosa definida que se llama push-forward.
\newpage
\begin{defn}[Métrica\IS inducida] Sea $i$ una inclusión, y sea $T=G$ una métrica, se dice que $i^*G$ es la métrica inducida.
\end{defn}

\begin{example} Sean 
	\begin{tikzcd}
	\mathbb{S}^1 \arrow[r] \arrow[d, "\phi=ang."] & ℝ^2 \arrow[d, "\psi=id"] \\
		\theta & (x,y)
	\end{tikzcd} 
y la métrica usual en $ℝ^2$: $G=dx\otimes dx+dy\otimes dy$\\
En lugar de seguir la fórmula de la definición de pull-back recordamos que la aplicación tangente usa las derivadas parciales (el jacobiano). Tenemos pues:\\
$$\begin{cases}
x=cos (\theta)\\
y=sen(\theta)\\
\end{cases}\mapsto
\begin{cases}
dx=-sen (\theta)\\
dy=cos(\theta)\\
\end{cases}$$
Cabe decir que la llave izquierda no es un cambio de carta, es la inclusión $\psi\circ i\circ \phi^{-1}$. Concluyendo, tenemos la métrica inducida por la usual en $\mathbb{S}^1$:
$$i^*G=(-sen(\theta))^2d\theta\otimes d\theta + (cos^2(\theta))d\theta\otimes d\theta=d\theta\otimes d\theta$$ 
\end{example}
\begin{example}\textbf{(Típico de GCS: Superficie inmersa en $ℝ^3$ )}\\ 
	\begin{wrapfigure}{r}{0.5\textwidth}
		\begin{center}
			\includegraphics[width=0.40\textwidth]{img/GT17_parametric_surface}
		\end{center}
		\caption{Superficie inmersa en $ℝ^3$ }
	\end{wrapfigure}
Llamamos (u,v) a los parámetros de la superficie, que en la foto aparecen como $(x,y)$:\\
$\begin{cases}
x=f^1(u,v)\\
y=f^2(u,v)\\
z=f^3(u,v) \\
\end{cases}$
$\begin{cases}
dx=\pdv{f^1}{u}du+\pdv{f^1}{v}dv\\
dy=\pdv{f^2}{u}du+\pdv{f^2}{v}dv\\
dz=\pdv{f^3}{u}du+\pdv{f^3}{v}dv \\
\end{cases}$
\\La métrica inducida por la usual (que para confundirnos aún más recibe también el nombre de usual) es la suguiente:\\ \\
$i^*(dx\otimes dx+dy\otimes dy+dz\otimes dz)=$$$(\pdv{f^1}{u}du+\pdv{f^1}{v}dv)\otimes(\pdv{f^1}{u}du+\pdv{f^1}{v}dv)\cdots=$$\\$\left(\norm{\pdv{f}{u}}\right)^2du\otimes du+\cdots$
\end{example}

Como se ha visto en los ejemplos, en la práctica es mucho más cómodo aplicar las siguientes fórmulas que la ley general de transformación de tensores:
$\begin{cases}
\pdv{y^j}=\pdv{x^i}{y^j}\pdv{x^i}\\
dy^j=\pdv{y_j}{x^i}dx^i\\
\end{cases}$
\newpage
\begin{example}Vamos a cambiar la métrica usual de $ℝ^2$ a polares (y como venimos haciendo, pasamos de la fórmula del pull-back). Tenemos la métrica $G=dx\otimes dx+dy\otimes dy$ y el cambio de carta $\begin{cases}
	x=r\cdot cos (\theta)\\
	y=r\cdot sen(\theta)\\
	\end{cases}\mapsto
	\begin{cases}
	dx=cos(\theta)dr-sen(\theta)d\theta\\
	dy=sen(\theta)dr+cos(\theta)d\theta\\
	\end{cases}$\\
	Si sustituímos en la métrica usual tenemos: $$cos^2(\theta)dr\otimes dr+r^2sen^2(\theta)d\theta\otimes d\theta+sen^2(\theta)dr\otimes dr+r^2cos^2(\theta)d\theta\otimes d\theta=dr\otimes dr+r^2d\theta\otimes d\theta$$
\end{example}
\chapter{Geometría Riemanniana}
\section{Cálculo de variaciones y mecánica}
El cálculo de variaciones se dedica a hallar máximos y mínimos de \textbf{funcionales} (entendiendo esta palabra como aplicación que va de un espacio de funciones a $ℝ$). Lo más común es el ejercicio en el que hay que minimizar una integral (como hallar el "tobogán" más rapido entre dos puntos dados), aunque hay otros como intentar hallar el área máxima que podemos encerrar con una cuerda de longitud 1 (Demostrar que la solución es una circunferencia no es trivial sin el cálculo de variaciones). 
\begin{obs}Durante este capítulo, se usara la notación $\dot{f}\equiv\dv{f}{t}$
\end{obs}
\begin{example}\textbf{(Problema de la Braquistócrona I)}\\
\begin{wrapfigure}{r}{0.5\textwidth}
		\begin{center}
			\includegraphics[width=0.5\textwidth]{img/GT17_Brachistochrone}
		\end{center}
		\caption{Curva Braquistócrona}
\end{wrapfigure}
Una curva braquistócrona, o curva del descenso más rápido, es la curva entre dos puntos que es recorrida en menor tiempo (el "tobogán" del que hablábamos antes), por un cuerpo que comienza en el punto inicial con velocidad cero, y que debe desplazarse a lo largo de la curva hasta llegar al segundo punto, bajo acción de una fuerza de gravedad constante y suponiendo que no existe fricción.\\ \\ \indent Supongamos que dicha curva es la gráfica de una función $y=f(x)$ en $ℝ^2$ y entonces el problema consiste en minimizar el tiempo que se tarda en ir de $A$ a $B$. Dicho tiempo (llamémosle $T$) se corresponde con la integral: $$\int_{0}^{1}\sqrt{\frac{1+(\dot{f}(x))^2}{2g\cdot f(x)}}dx;\tab\text{donde g es la constante gravitacional.}$$ 
\end{example}

A continuación se enuncia la proposición básica del cálculo de variaciones.
\newpage
\begin{prop} Dados $a,b\inℝ$; $\overline{c},\overline{d}\in ℝ^n$ y un conjunto de funciones $$\mathcal{C}=\{F=(q^1,\cdots,q^n)\space:\space F(a)=\overline{c},\space F(b)=\overline{d}\}$$ Supongamos además que tenemos la integral $$\int_{a}^{b}L dt;\tab\text{con }L=L(t,F(t),\dot{F}(t))$$ y que esta alcanza un máximo o un mínimo en $\mathcal{C}$, entonces dicha F es solución de la versión discreta (la que se usa en mecánica clásica) de \textbf{Euler-Lagrange}:
\begin{equation}
\label{eq:Euler-Lagrange}
\dv{t}\left(\pdv{L}{\dot{q^i}}\right)=\pdv{L}{q^i};\tab i=1,\cdots,n
\end{equation}
\end{prop}

\begin{proof}Sea $f(\epsilon)=\int_{a}^{b}L(t,F_0(t)+\epsilon\alpha t,\dot{F}_0(t)+\epsilon\dot{\alpha}(t))dt$; siendo $F_0$ la función para la que se alcanza el extremo y siendo $\appl{\alpha}{[a,b]}{ℝ^n}$ arbitraria con $\alpha(a)=\alpha(b)=0$; $\appl{f}{I}{ℝ}$ alcanza un extremo en $\epsilon=0$, por tanto:
	$$\dot{f}(0)=0\longrightarrow0=\int_{a}^{b}\left(\pdv{L}{q^i}\alpha^i+\pdv{L}{\dot{q}^i} \dot{\alpha}^i \right)dt=\int_{a}^{b}\left(\pdv{L}{q^i}-\dv{t}\left(\pdv{L}{\dot{q}^i}\right)\dot{\alpha}^i \right)dt$$
	que implica las ecuaciones de Euler-Lagange.
\end{proof}

\begin{example}$$I=\int_{1}^{2}(1+t^2(\dot{q}(t))^2)dt;\tab q(1)=2, q(2)=3$$
	Hay que encontrar la $q=q(t)$ que minimiza I. ¿Cuál es? Pues atendiendo a la proposición llamamos $L$ al integrando y tenemos siguiendo la fórmula: $$L=1+t^2\dot{q}^2\longrightarrow\begin{cases}
	\pdv{L}{\dot{q}}=2t^2\dot{q};\\
	\pdv{L}{q}=0;
	\end{cases}\longrightarrow\dv{t}(2t^2\dot{q})=0;$$
	Luego nos queda la EDO $4t\dot{q}+2t^2\ddot{q}=0$ y solo hay que resolverla. Tenemos que $t^2\dot{q}=cte\rightarrow \dot{q}(t)=\frac{cte}{t^2}$. Luego ya podemos integrar para hallar la función deseada: $$q(t)=K_1+\frac{K_2}{t}\xrightarrow{q(1)=2, q(2)=3}q(t)=4-\frac{2}{t}$$
Con esta q tenemos que I=3. Por ejemplo, si hubieramos cogido $q(t)=t+1$, entonces tendríamos $I=\frac{10}{3}\textgreater3$.\\
\end{example}
Volvamos ahora al ejemplo de la Braquistócrona.
\begin{example}\textbf{(Problema de la Braquistócrona II)}\\
Teníamos que:
$$\int_{0}^{1}\sqrt{\frac{1+(\dot{f}(x))^2}{2g\cdot f(x)}}dx;\tab f(0)=1,f(1)=0$$ 
\newpage
Luego tenemos que nuestro integrando, al que venimos llamando $L$, es:
$$L=\sqrt{\frac{1+(\dot{q}(x))^2}{2g\cdot q(x)}}\longrightarrow\begin{cases}\pdv{L}{\dot{q}}=\frac{1}{\sqrt{2gq}}\frac{\dot{q}}{\sqrt{1+\dot{q}^2}}\\
\pdv{L}{q}=\sqrt{\frac{1+(\dot{q}(x))^2}{2g}}\cdot\frac{-1}{2}\cdot q^{\frac{-3}{2}}
\end{cases}$$
Y si ahora usamos las ecuaciones de Euler-Lagrange nos sale una EDO bastante complicada. Para ayudar damos una proposición nueva
\end{example}
\begin{prop}\textbf{(Ley de conservación de la energía)} Supongamos que $L$ no depende explícitamente de $t$. Por tanto, $L(t,q,\dot{q})=L(q,\dot{q})$ y entonces a lo largo de cualquier solución de las ecuaciones de Euler-Lagrange se cumple que:
\begin{equation}
(q')^i\pdv{L}{(q')^i}-L=cte
\end{equation}
\end{prop}
\begin{proof}
	$\dv{t}\left(\dot{q}^i\pdv{L}{\dot{q}^i}-L\right)=\ddot{q}^i\pdv{L}{\dot{q}^i}$Por terminar...
\end{proof}
HASTA AQUÍ EL PRIMER EXAMEN PARCIAL\\
¿Por qué pueden interesarnos estos resultados del cálculo de variaciones en geometría de variedades? Imaginemos que tenemos el problema anterior, en el que intentabamos minimizar $\int_{1}^{2}(1+t^2(\dot{q}(t))^2)dt$, donde $L=1+t^2\dot{q}^2$ y el mínimo era 3.
Ahora, si cambiamos de nombre la función incógnita $q$, el mínimo debería seguir siendo el mismo. Entonces yo podría considerar (por ejemplo, yo,porque quiero) llamar a la $q=h^2$  (suponiendo que esto funciona bien: como $q$ es positiva se puede escribir como un cuadrado...) y el mínimo debería ser el mismo y alcanzarse para la misma función. El nuevo $\tilde{L}=1+t^2(2h\dot{h})^2$ y el mínimo debe salir el mismo salvo el cambio de nombre. Si antes $q(t)=4-\frac{2}{t}$ ahora $h(t)=\sqrt{4-\frac{2}{t}}$. Esto es sorprendente porque si cambio las coordenadas en las ecuaciones de Euler-Lagrange el problema parece compicarse, pero funciona perfectamente:
$$\dv{t}\left(\pdv{L}{\dot{q}}\right)=\pdv{L}{q};\tab\dv{t}\left(\pdv{\tilde{L}}{\dot{h}}\right)=\pdv{\tilde{L}}{h}$$
Luego es lícito hacer este cambio 
$$L\longmapsto\tilde{L}$$
$$q\longmapsto h$$
 De alguna manera, que las ecuaciones de Euler-Lagrange sean invariantes por cambios de coordenadas es atractivo, porque quiere decir que en los problemas de Geometría puedo cambiar la carta (las coordenadas) y haciendo el cambio de variable pertinente todo funcionará de lujo.

Esto tiene una aplicación en mecánica (s.XVIII y S.XIX) que es fantástica. En estos siglos surgió la idea de dejar de aplicar $\overline{F}=m\cdot\overline{a}$ en cada punto por resolver un problema de cálculo de variaciones: 
\newpage
\begin{prop}\textbf{(Principio de mínima acción o de acción estacionaria)}\\
	En mecánica se usa este langrangiano siempre $L=E_c-E_p$ que es la diferencia entre energía cinética (energía que aportan las partículas, que es igual a $E_c=\frac{1}{2}\sum_{i=1}m_i\norm{\dv{\overline{x}_i}{t}}^2$) y energía potencial (la energía que las partículas toman del campo donde se encuentren, como el gravitatorio donde vale $E_p=\sum_{i=1}m_igh_i$) y existe el \textbf{principio de mínima acción}, que dice que los sistemas mecánicos evolucionan entre dos tiempos de modo que $\int_{t1}^{t2}Ldt$ es mínima (aunque en rigor es estacionaria).
\end{prop}
\begin{example}
	\begin{wrapfigure}{r}{0.5\textwidth}
		\begin{center}
			\begin{tikzpicture}
			\pgfmathsetmacro{\Gvec}{1.5}
			\pgfmathsetmacro{\myAngle}{30}
			% calculate lengths of vector components
			\pgfmathsetmacro{\Gcos}{\Gvec*cos(\myAngle)}
			\pgfmathsetmacro{\Gsin}{\Gvec*sin(\myAngle)}
			
			\coordinate (centro) at (0,0);
			\draw[dashed,gray,-] (centro) -- ++ (0,-3.5) node (mary) [black,below]{$ $};
			\draw[thick] (centro) -- ++(270+\myAngle:3) coordinate (bob);
			\pic [draw, ->, "$\theta$", angle eccentricity=1.5] {angle = mary--centro--bob};
			\draw [blue,-stealth] (bob) -- ($(bob)!\Gcos cm!(centro)$);
			\draw [-stealth] (bob) -- ($(bob)!-\Gcos cm!(centro)$)
			coordinate (gcos)
			node[midway,above right] {$l\cos\theta$};
			\draw [-stealth] (bob) -- ($(bob)!\Gsin cm!90:(centro)$)
			coordinate (gsin)
			node[midway,above left] {$l\sin\theta$};
			\draw [-stealth] (bob) -- ++(0,-\Gvec)
			coordinate (g)
			node[near end,left] {$g$};
			\pic [draw, ->, "$\theta$", angle eccentricity=1.5] {angle = g--bob--gcos};
			\filldraw [fill=black!40,draw=black] (bob) circle[radius=0.1];
			\end{tikzpicture}
		\end{center}
		\caption{Péndulo en $ℝ^n$}
	\end{wrapfigure}
	
	Supongamos que queremos ver el movimiento de un péndulo. En lugar de imaginar fuerzas y tensiones ficticias, veámoslo matemáticamente. El punto extremo del péndulo tiene coordenadas $(x,y)$ y entonces $L=\frac{1}{2}m(\dot{x}^2+\dot{y}^2)-mgy$. Si nos fijamos, $(x,y)$ no son buenas coordenadas para este problema. Cojamos mejor la coordenada $\theta=$ángulo. Entonces$$ \begin{cases}
		x=l\cdot sen(\theta)\\
		y=-l\cdot cos(\theta)\\
	\end{cases}\longrightarrow \begin{cases}
	dx=l\cdot cos(\theta)d\theta\\
	dy=-l\cdot cos(\theta)d\theta\\
	\end{cases}$$
	y entonces $L=\frac{1}{2}m\cdot l^2\dot{\theta}^2+mgl\cdot cos(\theta)$. \\Ahora aplicando \refeq{eq:Euler-Lagrange} tenemos:
	$$\dv{t}\left(\pdv{L}{\dot{\theta}}\right)=\pdv{L}{\theta}\longrightarrow\dv{t}\left(ml^2\dot{\theta}\right)=-mgl\cdot sen(\theta)\longrightarrow\ddot{\theta}=-\frac{g}{l}sen(\theta)$$
	que es la ecuación del péndulo de toda la vida.
\end{example}
\\
\begin{obs}
	Este resultado de invarianza ante cambios de coordenadas  nos llevará como veremos a calcular geodésicas en variedades muy rápidamente si lo vemos como un problema del cálculo de variaciones minimizando las métricas en dicha variedad.
	\end{obs}
%% Apéndices (ejercicios, exámenes)
\appendix

\chapter{Ejercicios}
\input{tex/GeoTopo17_Ejs.tex}
\bibliography{../Apuntes}
\printindex
\end{document}
