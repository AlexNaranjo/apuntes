\documentclass[palatino, bibnumbers]{apuntes}

\title{Geometría y Topología}
\author{Jose Antonio García del Saz}
\date{16/17 C2}

% Paquetes adicionales
\usepackage{enumitem}
\usepackage{kpfonts}
\usepackage{tikztools}
\usepackage{fancysprefs}
\usepackage{tikz-3dplot}
\usepackage{xfrac}
\usepackage{wrapfig}
\usepackage{fastbuild}
\usepackage{tikz-cd}

\usetikzlibrary{arrows}
\usetikzlibrary{patterns}
\usetikzlibrary{intersections}
\usetikzlibrary{calc}
\usetikzlibrary{fadings}

\tikzset{
	snake/.style={
		rounded corners,
		to path={
			-- ([xshift=1em]\tikztostart.east)
			-- ([xshift=1em]\tikztostart.south east)
			-- ([xshift=-1em]\tikztotarget.north west)
			-- ([xshift=-1em]\tikztotarget.west)
			-- (\tikztotarget)
		}
	},
	snake up/.style={
		rounded corners,
		to path={
			-- ([xshift=-1em]\tikztostart.west)
			-- ([xshift=-1em]\tikztostart.north west)
			-- ([xshift=1em]\tikztotarget.south east)
			-- ([xshift=1em]\tikztotarget.east)
			-- (\tikztotarget)
		}
	}
}

\setlist{itemsep=1pt, topsep=5pt}
\bibliographystyle{alpha}
% --------------------

%\precompileTikz

\newcommand{\Id}{\mop{Id}}
\newcommand{\cln}{\colon\!}

\setcounter{tocdepth}{3}

\begin{document}
\pagestyle{plain}

% http://tex.stackexchange.com/a/14243
\relpenalty=9999
\binoppenalty=9999

\begin{abstract}
Estos son los apuntes del curso de Geometría y Topología, del profesor Fernando Chamizo.
\end{abstract}

\maketitle

\tableofcontents
\newpage
% Contenido.

\chapter{Álgebra Tensorial}

\section{Tensores en  $ℝ^{n}$}

Estudiar los tensores en $ℝ^n$ es en realidad estudiar el Álgebra Lineal pero en varias variables. En primer curso (Álgebra I) estudiamos las aplicaciones, las cuales eran de la forma:
\begin{align*}
	\appl{π}{ℝ^{n}&}{ℝ^{m}} \\
	\overline{x} &\longmapsto[\overline{y}=A\cdot \overline{x}]
\end{align*}

\begin{defn}[Aplicación\IS Lineal] Sea $f$ una aplicación entre dos espacios vectoriales $V$, $W$ sobre el mismo cuerpo $K$. Decimos que $f$ es una \textbf{aplicación lineal} si se cumplen las siguientes propiedades ($λ\in K$):
	\begin{enumerate}
		\item $f(λ\overline{x})=λ\cdot f(\overline{x})$ .
		\item $f(\overline{x_1}+\overline{x_2})=f(\overline{x_1})+f(\overline{x_2})$
	\end{enumerate}
\end{defn}

\begin{defn}[Aplicación\IS Bilineal] Sea 
	\begin{align*}
	\appl{f}{ℝ^{n}×ℝ^{n}&}{ℝ} \\
	\overline{x},\overline{y} &\longmapsto{f(\overline{x},\overline{y})}
	\end{align*}
una aplicación, decimos que es \textbf{bilineal} si es una aplicación lineal en cada una de las dos variables, es decir:
\begin{enumerate}
	\item $f(λ\overline{x},\overline{y})=λ\cdot f(\overline{x},\overline{y})$; $f(\overline{x_1}+\overline{x_2},\overline{y})=f(\overline{x_1},\overline{y})+f(\overline{x_2},\overline{y})$
	\item $f(\overline{x},λ\overline{y})=λ\cdot f(\overline{x},\overline{y})$; $f(\overline{x},\overline{y_1}+\overline{y_2})=f(\overline{x},\overline{y_1})+f(\overline{x},\overline{y_2})$
\end{enumerate}
\end{defn}
\textbf{Observación:} todas las aplicaciones bilineales entre dos espacios se pueden escribir de la siguiente manera:
$$f(\overline{x},\overline{y})=\overline{x}^{T}A\overline{y}$$ con A una matriz n×n.
\newpage
\begin{defn}[Aplicación\IS Multilineal] Decimos que una aplicación es \textbf{multilineal} si es lineal en cada una de sus variables. 
\end{defn}

\begin{defn}[Tensor\IS n veces covariante] Es cualquier aplicación multilineal
	$\appl{T}{\varprod_{i=1}^n V}{ℝ}$, siendo V un espacio vectorial de dimensión finita sobre $ℝ$ (que como sabemos de otros cursos son isomorfos a $ℝ^{n}$).
\end{defn}

\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_1\cdot y_3}
	\end{align*}
es obvio que T es multilineal, luego T es un tensor 2 veces covariante en $ℝ^{3}$.
\end{example}
\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_1\cdot x_3}
	\end{align*}
	se ve rápidamente que \underline{no} es una aplicación lineal respecto de la variable $\overline{x}$.
\end{example}
\begin{example} Sea
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix},\begin{pmatrix}z_1\\z_2\\z_3\end{pmatrix}\right) &\longmapsto{\begin{vmatrix}
			x_1 & y_1 &  z_1 \\ 
			x_2 & y_2 & z_2 \\ 
			x_3 & y_3 & z_3 \\ 
		\end{vmatrix}}
	\end{align*}
	la propiedad de linealidad del producto por un escalar es obvia por las propiedades de los determinantes. La propiedad de linealidad que conserva la adición se demuestra fácilmante desarrollando el determinante por adjuntos en la primera columna. Luego T es un tensor 3 veces covariante.
\end{example}
\newpage
En Álgebra Lineal estudiamos no sólo las aplicaciones $\appl{T}{ℝ^{n}}{ℝ}$ , sino también las de la forma $\appl{T}{ℝ^{n}}{ℝ^{m}}$. Ahora bien, estás últimas pueden convertirse al primer tipo mediante un elemento del \textbf{espacio dual}.

\begin{defn}[Espacio\IS dual] Sea V un espacio vectorial entonces se define el espacio dual y se denota con $V^{*}$ de la siguiente manera: \[ V^{*} = \{ \appl{f}{V}{ℝ} \tq \text{f es lineal} \}\]
\end{defn}

Con la definición anterior, un truco para pasar de unas aplicaciones a otras es que consideramos un elemento del espacio dual ($\phi\inℝ^{m}$) y uno del espacio vectorial original ($\overline{x}\inℝ^{n}$) y entonces tenemos una aplicación $$\hat{f}(\phi,\overline{x})=\phi(f(\overline{x}))\inℝ$$

De la misma manera, en lugar de considerar "tensores vectoriales" (esta expresión no es correcta, pero se da para ilustrar), los cuales serían aplicaciones multilineales $\appl{T}{\varprod_{1}^s V}{\varprod_{1}^r V}$, es más conveniente pensar en que el tensor va a depender también de los elementos del espacio dual. Luego vamos a considerar tensores de la forma $$\appl{T}{\underbrace{V^{*}×\cdots×V^{*}}_{\text{r veces}}×\underbrace{V×\cdots×V}_{\text{s veces}}}{ℝ}$$ que sean multilineales.

\begin{defn}[Tensor\IS r veces contravariante y s veces covariante] Es cualquier aplicación multilineal de la forma:
	$$\appl{T}{\underbrace{V^{*}×\cdots×V^{*}}_{\text{r veces}}×\underbrace{V×\cdots×V}_{\text{s veces}}}{ℝ}$$ siendo V un espacio vectorial de dimensión finita sobre $ℝ$ (isomorfo a $ℝ^{n}$) y $V^{*}$ su espacio dual. Diremos análogamente que T es un tensor de tipo (r,s).
\end{defn}

Como ya sabemos, si V es un espacio vectorial y tenemos una base de V (llamémosla $\base = \{ \overline{v_1},...,\overline{v_n} \}$), entonces existe una base natural de $V^{*}$
llamada \textbf{base dual} (denotada por $\base^{*}=\{\tilde{\phi}^{1},\cdots ,\tilde{\phi}^{n}\}$) y que está determinada por la propiedad: $$\tilde{\phi}^{i}(\overline{v_j})=\delta_j^{i} = \begin{cases} 0 & i ≠ j \\ 1 & i ≠ j \end{cases}$$
\newpage
\begin{example} Daremos un ejemplo casi absurdo para ilustrar. Dar la base dual es muy fácil cuando tenemos una base ortonormal, por ejemplo la base canónica de $ℝ^{2}$:
$$\base = \{\overline{e_1},\overline{e_2}\}=\left\{\begin{pmatrix}1\\0\end{pmatrix},\begin{pmatrix}0\\1\end{pmatrix}\right\}$$En este caso obtenemos la base dual solamente girando los elementos de la base canónica, obteniendo: $$\base^{*} =\{\tilde{\phi^{1}},\tilde{\phi^{2}}\}=\left\{\begin{pmatrix}1&0\end{pmatrix},\begin{pmatrix}0&1\end{pmatrix}\right\}$$
\end{example}
\begin{example} Imaginemos que estamos en $ℝ^{2}$ pero en esta ocasión tenemos una cualquiera de sus bases $\base=\{\overline{v_1},\overline{v_2}\}$. Ahora consideramos la matriz $A=\begin{pmatrix}v_{11}&v_{21}\\v_{12}&v_{22}\\ \end{pmatrix}$, y entonces tenemos que $\begin{cases}\overline{v_1}=A\cdot \overline{e_1} \\\overline{v_2}=A\cdot \overline{e_2}\end{cases}$. Construímos entonces la base dual $\base^{*}=\{ \tilde{\phi^{1}},\tilde{\phi^{2}}\}$ de esta manera con la matriz de cambio de base: $\begin{cases} \tilde{\phi^{1}}(\overline{x})=\begin{pmatrix}0&1\end{pmatrix}\cdot A^{-1}\cdot \overline{x} \\\tilde{\phi^{2}}(\overline{x})=\begin{pmatrix}1&0\end{pmatrix}\cdot A^{-1}\cdot \overline{x}\end{cases}$
\end{example}
\begin{example} Si f es un \textit{endomorfismo}, digamos $\appl{f}{ℝ^{n}}{ℝ^{n}}$, se corresponde de manera unívoca con un tensor de tipo (1,1):
	\begin{align*}
	\appl{T}{(ℝ^{n})^{*}×ℝ^{n}&}{ℝ} \\
	T(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}(f(\overline{x}))}
	\end{align*}
\end{example}
\begin{example} Cualquier vector de un espacio vectorial ($\overline{v}\in V$) se puede hacer corresponder con un tensor (1,0)  que se alimenta de elementos del dual y devuelve reales definido como:
	\begin{align*}
	\appl{T_{\overline{v}}}{V^{*}&}{ℝ} \\
	T_{\overline{v}}(\tilde{\phi}) &\longmapsto{\tilde{\phi}(\overline{v})}
	\end{align*}
\end{example}

Vamos a introducir notación para las definiciones y resultados venideros, y hay que hacerla nuestra ya que es el infierno de casi todos los estudiantes al abrir un libro de cálculo tensorial. De aquí en adelante (aunque se venga haciendo desde el inicio) se usarán \textbf{subíndices} para numerar vectores ($\overline{v_1},\overline{v_2},...,\overline{v_n}$) y \textbf{superíndices} para numerar elementos del espacio dual, aunque también sean vectores ($\tilde{\phi^{1}},\tilde{\phi^{2}},...,\tilde{\phi^{n}}$) .
\newpage
\begin{defn}[Componentes\IS de un tensor] Sea un tensor $T$ de tipo (r,s) y sean $\base=\{\overline{v_1},...,\overline{v_n}\}$, $\base^{*}=\{\tilde{\phi^{1}},...,\tilde{\phi^{n}}\}$ las bases de $V$ y $V^{*}$ respectivamente, se definen las componentes de $T$ en la base $\base$ como la siguiente colección de números:
	$$T_{j_1\space j_2\space \cdots \space j_s}^{i_1\space i_2\space \cdots \space i_r}=T(\tilde{\phi^{i_1}},\tilde{\phi^{i_2}},...,\tilde{\phi^{i_r}},\overline{v}_{j_1},\overline{v}_{j_2},...,\overline{v}_{j_s})$$
\end{defn}
\begin{example} Calcular las componentes del tensor:
	\begin{align*}
	\appl{D}{ℝ^{2}×ℝ^{2}&}{ℝ} \\
	D\left(\begin{pmatrix}x_1\\x_2\end{pmatrix},\begin{pmatrix}y_1\\y_2\end{pmatrix}\right) &\longmapsto{\begin{vmatrix}
		x_1 & y_1 \\ 
		x_2 & y_2 \\ 
		\end{vmatrix}}
	\end{align*}
	Lo primero que hacemos es coger una base (cogemos la canónica porque será lo más usual este curso). Como es un tensor (0,2), no habrá superíndices en las componentes, sólo subindices. Las componentes son: $$D_{j_1\space j_2}=\begin{cases}
		D_{1\space1}=D(\overline{e_1},\overline{e_1})=\begin{vmatrix}1&1 \\ 0&0 \\ \end{vmatrix}=0\\
		D_{1\space2}=D(\overline{e_1},\overline{e_2})=1\\
		D_{2\space1}=-1\\
		D_{2\space2}=0\\
	\end{cases}$$
\end{example}
%% Apéndices (ejercicios, exámenes)
\appendix


\chapter{Ejercicios}
\input{tex/GeoTopo17_Ejs.tex}


\bibliography{../Apuntes}{}
\printindex
\end{document}
