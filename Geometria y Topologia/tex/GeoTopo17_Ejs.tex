% -*- root: ../GeoTopo17.tex -*-
\section{Hoja 1}
\begin{problem}[1]Responde brevemente a las siguientes preguntas:
	\ppart Si $T=T(\overline{x},\overline{y})$ y $S=S(\overline{x},\overline{y})$ son tensores, ¿lo es $T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$?¿y $T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$?
	\ppart ¿Es $T(\overline{x},\overline{y})=\overline{x}+\overline{y}$ una aplicación bilineal?
	\ppart ¿Cuántas componentes tiene un tensor (r,s) con $V=ℝ^{m}$?
	\ppart ¿Es un tensor la aplicación que dados dos vectores de $ℝ^{3}$ les asigna la primera coordenada de su producto vectorial?
	\ppart ¿Es un tensor la aplicación que a cada par de vectores de $ℝ^{2}$ con la base canónica les asigna el área del paralelogramo que determinan?
	
	\solution
	\doneby{Jose}\\
	\spart Tenemos $$\appl{T}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\appl{S}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\text{ambos multilineales}$$\indent Es fácil observar que $T\cdot S(\overline{x},\overline{y})=T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$ no es multilineal , ya que $$T\cdot S(\alpha\cdot\overline{x},\overline{y})=\alpha^2\cdot T\cdot S(\overline{x},\overline{y})$$ \indent luego no es tensor.\newline
	\indent Si ahora nos fijamos en $T+S(\overline{x},\overline{y})=T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$ es inmediato comprobar que es \indent un tensor 2 veces covariante:
	$$T+S(\alpha\cdot\overline{x},\overline{y})=T(\alpha\overline{x},\overline{y})+S(\alpha\overline{x},\overline{y})=\alpha\cdot(T+S(\overline{x},\overline{y}))$$
	$$T+S(\overline{x}_1+\overline{x}_2,\overline{y})=T(\overline{x}_1,\overline{y})+S(\overline{x}_1,\overline{y})+T(\overline{x}_2,\overline{y})+S(\overline{x}_2,\overline{y})=(T+S(\overline{x}_1,\overline{y}))+(T+S(\overline{x}_2,\overline{y}))$$
	\spart \indent Inmediato comprobar que no es bilineal multiplicando una variable por un escalar: $$T(\alpha\overline{x},\overline{y})=\alpha\overline{x}+\overline{y}\neq\alpha(\overline{x}+\overline{y})$$
	\newpage
	\spart $$\appl{T}{\underbrace{(ℝ^{m})^{*}×\cdots×(ℝ^{m})^{*}}_{\text{r veces}}×\underbrace{ℝ^{m}×\cdots×ℝ^{m}}_{\text{s veces}}}{ℝ}$$ \indent luego habrá $m^{r+s}$ componentes.
	
	\spart  Hay dos formas, una es considerar:
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_2\cdot y_3-x_3\cdot y_2}
	\end{align*}
 	y comprobar que efectivamente se cumplen las condiciones de multilinealidad. \\
 	La segunda es considerar:
 	\begin{align*}
 		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
 		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{(\overline{x}×\overline{y})\cdot\overline{e}_1=\begin{vmatrix}
 				1 & 0 &  0 \\ 
 				x_1 & x_2 & x_3 \\ 
 				y_1 & y_2 & y_3 \\ 
 		\end{vmatrix}}
 	\end{align*}
	y como vimos que el determinante es multilineal, pues ya está demostrado porque es un determinante.
	
	\spart 
		\begin{align*}
		\appl{T}{ℝ^{2}×ℝ^{2}&}{ℝ} \\
		T(\overline{x},\overline{y}) &\longmapsto{A=\text{área}}
	\end{align*}
\indent El área siempre es $\geq 0$, luego si multiplico por $\lambda=-1$ tenemos $T(\lambda\overline{x},\overline{y})\neq\lambda T(\overline{x},\overline{y})$
	
\end{problem}

\begin{problem}[3] Halla cuántas componentes nulas y cuántas componentes no nulas tiene el tensor determinante en $ℝ^{n}$. Estudia cuántas son positivas.
	
	\solution Sea el tensor n veces covariante en $ℝ^{n}$ y la base canónica $\base = \{ \overline{e}_1,...,\overline{e}_n \}$ de $ℝ^{n}$:
	
\begin{align*}
	\appl{D}{\underbrace{(ℝ^{n})×\cdots×(ℝ^{n})}_{\text{n veces}}&}{ℝ} \\
	D(\overline{x}_1,\cdots,\overline{x}_n) &\longmapsto{\begin{vmatrix}
							\overline{x}_1 & \cdots &  \overline{x}_n \\ 
						\end{vmatrix}}
\end{align*}
		El tensor tienen $n^n$ componentes:
		$$D_{1\space1\cdots1}=\begin{vmatrix}
		1 & 1 &\cdots & 1 \\ 
		0& 0 &\cdots & 0 \\ 
		\vdots & \vdots &\ddots & \vdots \\ 
		0& 0 &\cdots & 0 \\ 
		\end{vmatrix}$$
	En cuanto el determinante contenga a dos $\overline{e}_i$ que tengan la misma $i$ ya da 0 (por ser determinante de elementos linealmente dependientes). Luego para que no sea nulo ha de tener todas los índices distintos. Esto nos dice que el número de componentes no nulas son las permutaciones de $n$ elementos ($n!$), y las nulas serían entonces $n^n - n!$.\\
	Ahora, de las que no son nulas vamos a ver cuales son positivas. Probando descubrimos que con esta base hay dos valores posibles del determinante que son $1$ y $-1$. Las componentes positivas son aquellas que valen $1$ y esto ocurre cuando hay un número par de $\overline{e}_i$ cambiadas de posición (recordemos que todas las $i$ son ahora distintas porque estamos en el caso no nulo). \\
	La conclusión es que la cantidad de las que valen $1$ es la cantidad de permutaciones pares de n elementos, que es $\frac{n!}{2}$.
\end{problem}
\begin{problem}[4] \ppart Si multiplicamos tensorialmente unos cuantos elementos de $\mathcal{B}$ y otros de $\mathcal{B}^*$, halla cuántas componentes no nulas tiene el tensor resultante. Explica por qué todo tensor se puede escribir como combinación lineal de estos productos tensoriales y \ppart hazlo para el tensor que corresponde a la rotación de ángulo $\frac{\pi}{2}$ escogiendo $\mathcal{B}=\{\overline{e}_1+\overline{e}_2,\overline{e}_2\}$ siendo los $\overline{e}_i$ los vectores canónicos habituales.
	
	\solution \spart Sean $\mathcal{B}=\{\overline{e}_1,\cdots\overline{e}_n\}$ y $\mathcal{B}^*=\{\tilde{\phi}^1,\cdots\tilde{\phi}^n\}$ donde los $\overline{e}_i$ son tensores de tipo (1,0) y los $\tilde{\phi}^i$ son tensores de tipo (0,1). Tenemos que $$\overline{e}_i(\tilde{\phi^{j}})=\tilde{\phi}^j(\overline{e}_i)=\delta^i_j=\begin{cases}0\tab i\neq j\\1\tab i=j
	\end{cases}$$
	$$\overline{e}_{i_1}\otimes\cdots\otimes\overline{e}_{i_m}\otimes\tilde{\phi^{j_1}}\otimes\cdots\otimes\tilde{\phi^{j_k}}(\tilde{\phi^{s_1}},\cdots,\tilde{\phi^{s_m}},\overline{e}_{r_1},\cdots,\overline{e}_{r_k})=\begin{cases}1\tab \text{si los }\delta^i_j\text{ valen todos 1}\\0\tab \text{en otro caso}
	\end{cases}$$
	$$T(\tilde{x}^1,\cdots,\tilde{x}^m,\overline{y}_1,\cdots,\overline{y}_k)=T(x^1_{i_1}\phi^{i_1},\cdots,x^m_{i_m}\phi^{i_m},\overline{y}_1^{j_1}\overline{e}_{j_1},\cdots,\overline{y}_k^{j_k}\overline{e}_{j_k})=x^i_{i_1}\cdots x^m_{i_m}y_1^{j_1}\cdots y_k^{j_k};$$
	$$T^{i_1\cdots i_m}_{j_1\cdots j_k}=x^1_{h_1}\delta^{h_1}_{i_1}\cdots x^m_{h_m}\delta^{h_m}_{i_m}y_1^{h_1}\delta^{j_1}_{h_1}\cdots y_k^{h_k}\delta^{j_k}_{h_k};$$
	\spart parte 2
\end{problem}
\begin{problem}[7] El "tensor de Minkowski" $\appl{M}{ℝ^2×ℝ^2}{ℝ}$ tiene componentes $-M_{1\space 1}=M_{2\space 2}=1;\space M_{1\space 2}=M_{2\space 1}=0$ en la base canónica. Encuentra un cambio de base no trivial (que no consista en cambios de signo) que deje invariantes todas las componentes.
	\solution Sabemos por el ejercicio 2 que todo tensor dos veces covariante puede escribirse como: $$T(\overline{x},\overline{y})=\overline{x}^TA\overline{y}$$ Ahora hallamos la matriz $A$ que se corresponde con este tensor.$$\begin{cases}T_{1\space 1}=\overline{e}_1^TA\overline{e}_1=\begin{pmatrix}1&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}1\\0\end{pmatrix}
	=a=-1\\T_{2\space 2}=\overline{e}_2^TA\overline{e}_2=\begin{pmatrix}c&d\end{pmatrix}\begin{pmatrix}0\\1\end{pmatrix}=d=1;\\b=c=0;\end{cases}$$
	Buscamos ahora $\tilde{\alpha}=\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}$, $\tilde{\mu}=\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix}$ tales que $\mathcal{B}=\{\tilde{\alpha},\tilde{\mu}\}$ es una base y se conservan las $M_{i\space j}$, luego tenemos el sistema:
	$$\begin{cases}M(\tilde{\alpha},\tilde{\alpha})=\begin{pmatrix}\alpha_1&\alpha_2\end{pmatrix}\begin{pmatrix}-1&0\\0&1\end{pmatrix}\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}=-1\longrightarrow-\alpha_1^2+\alpha_2^2=-1\\
	M(\tilde{\mu},\tilde{\mu})=1\longrightarrow-\mu_1^2+\mu_2^2=1\\
	M(\tilde{\alpha},\tilde{\mu})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	M(\tilde{\mu},\tilde{\alpha})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	\end{cases}$$
	y ya solo hay que coger una solución (no hay una única), como por ejemplo $\mathcal{B}=\{\begin{pmatrix}2\\\sqrt{3}\end{pmatrix},\begin{pmatrix}\sqrt{3}\\2\end{pmatrix}\}$.
\end{problem}
\begin{problem}[9] El espín de un electrón es una especie de imán asociado a él y se representa con un vector unitario $a\overline{e}_1+b\overline{e}_2\in\mathbb{C}^2$ donde $\abs{a}^2$ y $\abs{b}^2$ indican las probabilidades de que al hacer un experimento notemos el polo norte arriba o abajo, respectivamente. Para dos electrones se representa como un tensor $(2,0)$ complejo $a^{i\space j}\overline{e}_i\otimes\overline{e}_j$ donde $\abs{a^{i\space j}}^2$ son las probabilidades de cada medición (por ejemplo $\abs{a^{1\space 2}}^2$ es arriba-abajo). Si $a^{i\space j}\overline{e}_i\otimes\overline{e}_j=\overline{v}\otimes\overline{w}$ los electrones son de alguna manera independientes y se dice que no están entrelazados. Prueba que esto ocurre si y sólo si $det(a^{i\space j})\neq0$. Nota: Para tres electrones el tensor es tipo $(3,0)$ y no existe una caracterización sencilla.
	
	\solution El espín es un vector $\overline{v}=a_1\overline{e}_1+a_2\overline{e}_2$ para $a_1,a_2\in\mathbb{C}$. Queremos demostrar:$$Independencia\iff det(a^{i\space j})\neq0$$
	$(\rightarrow)$ Cuando $T$ es un tensor de tipo $(0,2)$ es igual a $\overline{v}\otimes\overline{w}$ para dos $\overline{v}=b^i\overline{e}_i,\overline{w}=c^i\overline{e}_i$ de tipo $(1,0)$. Entonces tenemos $\overline{v}\otimes\overline{w}=b^ic^i\overline{e}_i\otimes\overline{e}_j$
	$$\begin{vmatrix}
	b^1c^1&b^1c^2\\
	b^2c^1&b^2c^2
	\end{vmatrix}=b^1b^2c^1c^2\cdot\begin{vmatrix}
	1&1\\
	1&1
	\end{vmatrix}=0\qed$$
	$(\leftarrow)$ Partimos de las hipótesis $T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j;\tab\begin{vmatrix}
	a^{1\space1}&a^{1\space2}\\
	a^{2\space1}&a^{2\space2}
	\end{vmatrix};\tab\sum_{i,j=1}^{(2,2)}\abs{a^{i\space j}}^2=1$, luego $\begin{cases}
	a^{1\space 2}=\lambda a^{1\space 1};\\
	a^{2\space 2}=\lambda a^{2\space 1};\\
	\lambda=\frac{a^{1\space 2}}{a^{1\space 1}}
	\end{cases}$ Ahora vamos a escribir el tensor como un producto tensorial:
	$$T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j=a^{1\space 1}\overline{e}_1\otimes(\overline{e}_1+\lambda\overline{e}_2)+a^{2\space 1}(\overline{e}_1+\lambda\overline{e}_2)=(\underbrace{a^{1\space 1}\overline{e}_1+a^{2\space 1}\overline{e}_2}_{\overline{v}})\otimes(\underbrace{\overline{e}_1+\lambda\overline{e}_2}_{\overline{w}})\qed$$ Queda para el lector comprobar que al normalizar $\overline{v}$, se normaliza automáticamente $\overline{w}$, aunque no se pide.
\end{problem}

