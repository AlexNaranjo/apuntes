\documentclass{apuntes}[nochap]
\usepackage[colorlinks,urlcolor=blue]{hyperref}
\usepackage{xifthen}

\newcounter{problem}
\newcounter{solution}
\renewcommand{\theenumi}{\alph{enumi}}

\newcommand\Problem[1][]{%
  \color{blue}
  \stepcounter{problem}%
  \ifthenelse{\isempty{#1}}{\textbf{Problema \theproblem.}}{\textbf{Problema #1.}}

  \setcounter{solution}{0}%
}

\newcommand\TheSolution{%
  \color{black}
  \textbf{Solución:}\\%
}

\newcommand\ASolution{%
  \stepcounter{solution}%
  \textbf{Solución \thesolution:}\\%
}


\setlength{\arrayrulewidth}{1mm}
\setlength{\tabcolsep}{18pt}
\renewcommand{\arraystretch}{1.5}


\author{Pedro Valero & Victor de Juan}
\title{Sistemas Informáticos II}
\parindent 0in
\parskip 1em
\makeindex
\begin{document}

\maketitle
\newpage
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROBLEMA 1

\chapter{Middleware}
\section{Teoría}
Para este tema es importante tener claros varios conceptos que vamos a ir definiendo y explicando poco a poco.

\begin{defn}[Middleware]
Conjunto de aplicaciones encargadas de enlazar los componentes de un sistema distribuido.
\end{defn}

Este conjunto de aplicaciones está dividido en el protocolo específico del servicio con el que estamos trabajando (ODBC, HTTP, SMTP...), el protocolo de transporte (TCP/IP) y una capa intermedia llamada \concept{Network Operating System (NOS)}.

\begin{defn}[Network Operating System]
Es una extensión del sistema operativo que proporciona transparencia al cliente, para que éste realice las llamadas como si fueran locales.

\end{defn}
Algunas de las maneras de proporcionar transparencia del NOS son


\section{Problemas Tema 1}
\chapter{Colas}
\section{Teoría}
\section{Problemas Tema 2}
\input{tex/Colas.tex}


\chapter{Aspectos operacionales de los sistemas distribuidos: Disponibilidad}
\section{Teoría}
\subsection{Introducción}
A lo largo de este tema vamos a estudiar la teoría de la disponibilidad de los sistemas distribuídos así como algunas arquitecturas que permiten obtener un incremento de la misma.

Para empezar debemos definir qué es la disponibilidad.

\begin{defn}[Disponibilidad]
La disponibilidad de un sistema es la probabilidad de que un sistema se encuentre operativo en un instante de tiempo determinado.
\end{defn}

Hay dos motivos por los que un sistema puede no estar disponible:
\begin{enumerate}
\item[1] \textbf{Paradas no planificadas}

Este tipo de paradas tiene lugar por fallos en los equipos o en los programas que implementan los servicios.

Requieren tratamiento estadístico, pues no habrá dos iguales: Teoría de la Fiabilidad de componentes y sistemas. Los sistemas que las minimizan se llaman de \textbf{Alta Disponibilidad} \textit{(High Availability, HA)}

\newpage

Algunas de las causas más frecuentes por las que se producen este tipo de paradas son:

\begin{itemize}
\item Extensión del tiempo destinado aoperaciones planificadas.
\item Error humano.
\item Fallo en aplicación.
\item Fallo del sistema operativo.
\item Fallo hardware.
\item Errores de configuración del software.
\end{itemize}

\item[2] \textbf{Paradas planificadas}

Son requeridas por la aplicación para su correcto funcionamiento: Rearranques programados, copias de seguridad, cambios de configuración...

Por ser previsibles permiten un tratamiento sistemático. Los sistemas que las minimizan se denominan de \textbf{Operación Continua} \textit{(Continuous Operation, CO)}

Algunas de las causas más frecuentes por las que se producen este tipo de paradas son:

\begin{itemize}
\item Copias de seguridad.
\item Reemplazar o actualizar hardware.
\item Reemplazar o actualizar aplicaciones.
\item Actualizar sistema operativo.
\item Instalación de parches
\end{itemize}
\end{enumerate}

Evidentemente, un sistema ideal sería de Alta Disponibilidad y de Operación Continua. No obstante, a mayor disponibilidad del sistema mayor es el coste del mismo y su mantenimiento. Por tanto, es necesario valorar el nivel de disponibilidad requerido para un funcionamiento aceptable e invertir lo necesario para conseguirlo sin tratar de superarlo.

\subsection{Definiciones relacionadas con la disponibilidad}

Antes de seguir estudiando el tema de la disponibilidad, vamos a ver una serie de definiciones de términos que aparecerán a lo largo de los apuntes y que es necesario precisar.

\begin{defn}[Fiabilidad (Reliability)]
Probabilidad de que un componente o sistema continúe funcionando en un determinado instante en el tiempo.
\end{defn}

\newpage
\begin{defn}[Elasticidad o Resiliencia (Resiliency)]
Capacidad de un sistema para adaptarse a
condiciones externas imprevistas (fallos, aumento de carga...) para continuar cumpliendo sus parámetros de calidad.
\end{defn}

\begin{defn}[Mantenibilidad (Serviceability)]
Es la probabilidad de realizar una reparación satisfactoria en un tiempo determinado.
\end{defn}

\begin{defn}[Sistemas tolerantes a fallos (Fault-Tolerant Systems)]
Sistemas que contienen
componentes hardware dobles de modo que el fallo de uno de ellos no suspende su
operación.
\end{defn}

\begin{defn}[Clusters de alta disponibilidad (High Availability Clusters)]
Conjunto de nodos de servicio que comparten conexiones externas (red, discos...) y están gestionados por un software especial que permite proporcionar servicio sin interrupciones ante el fallo de alguno de sus componentes.
\end{defn}

\begin{defn}[Clusters de alto rendimiento (High Performance Clusters)]
Conjunto de nodos de servicio que comparten una misma carga de trabajo.
\end{defn}

\begin{defn}[Recuperación ante desastres (Disaster Recovery)]
Capacidad de una instalación de
recuperar la operatividad tras un evento de gran magnitud, bien de tipo local (edificio), urbano (ciudad) o regional (área extendida con infraestructuras comunes).
\end{defn}

\subsection{Teoría de la disponibilidad}
\subsubsection{Disponibilidad}
La disponibilidad, $A$, de un sistema se estima a partir de la medida del tiempo que ha estado operativo, $T_{op}$, en un intervalo de tiempo, $T_{tot}$, suficientemente grande.
\[A= \frac{T_{op}}{T_{tot}}\]

Pero esta medida no da una idea global de la disponibilidad del sistema, pues un mismo valor puede obtenerse de la misma forma.

Por ejemplo, no es lo mismo que un sistema esté disponible 99 horas de cada 100 que 99 segundos de cada 100. Incluso si dos datos se han obtenido dividiendo los datos en las mismas unidades y estamos, por ejemplo, en 99 horas de cada 100 de actividad, puede ser que el sistema haya fallado una única vez en esas 99 horas y tardase una hora en recuperarse o que el sistema falle cada media hora tardando poco en recuperarse.

Por ello se utilizan otras medidas para estudiar la disponibilidad del sistema.

\begin{defn}[Tiempo medio\IS entre fallos]

En inglés \textbf{Mean Time Between Failures, MTBF}, es valor esperado del tiempo que transcurre entre dos fallos consecutivos de un equipo.
\end{defn}

\begin{defn}[Tiempo medio\IS hasta el fallo]

En inglés \textbf{Mean Time To Failure, MTTF}, es el valor esperado del tiempo de vida de un equipo o sistema, medida de su Fiabilidad (Reliability).
\end{defn}

\begin{defn}[Tiempo medio\IS de reparación/recuperación]

En inglés \textbf{Mean Time To Repair/Restore, MTTR}, es el valor esperado del tiempo que se tarda en sustituir un equipo averiado o recuperar un fallo de software, medida de su Mantenibilidad (Serviceability)
\end{defn}

A partir de estos valores se calcula la disponibilidad según la fórmula:

\[A=\frac{MTTF}{MTBF}=\frac{MTTF}{MTTF+MTTR}\]

Para pasar de la primera a la segunda fórmula se emplea la relación lógica $MTBF=MTTF+MTTR$, es decir, el tiempo que transcurre entre dos fallos es la suma del tiempo que tardo en recuperarse el sistema tras un fallo más el tiempo que tarda en volver a fallar.

\subsubsection{Fiabilidad}

La fiabilidad de un componente o sistema en el tiempo es la probabilidad de que el sistema continúe funcionando en un instante de tiempo. Si denominamos $T$ al tiempo de vida del componente, su fiabilidad viene dada por la expresión:
\[R(t)=\mathbb{P}\{T > t \}\]

La vida del componente, $T$, es una variable aleatoria, cuya función de distribución es
\[F_T(t)=\mathbb{P}\{T \leq t \}\]

Evidentemente ambas variables probabilidades deben sumar siempre 1, $R(t)+F_T(t)=1$ y derivando obtenemos que sus funciones de densidad son iguales pero de signo contrario.

Una vez hemos definido estas variables podemos definir el tiempo medio hasta fallo como la esperanza de vida de un componente:
\[MTTF = E[T]=\int_{-\infty}^{\infty}fF'_T(t)dt\]

Ahora, sabiendo algo de probabilidad, podemos calcular la probabilidad de que un sistema falle antes de un instante, $x$, sabiendo que funcionaba en un instante $t<x$.
\[F_T(x | T > t ) = \mathbb{P}\{T \leq x | T> t\}=\frac{\mathbb{P}\{(T \leq x) \cap (T > t)\}}{\mathbb{P}\{T > t\}}=\frac{\mathbb{P}\{t < T \leq x\}}{\mathbb{P}\{T > t\}}=\]
\[=\frac{F_T(x)-F_T(t)}{1-F_T(t)}\]

y derivando con respecto a $x$ se obtiene
\[f_T(x | T > t)=\frac{f_T(x)}{1-F_T(x)}\]

A partir de esta última expresión se define la \concept{función de tasa de fallo} al evaluarla en $x=t$.
\[r(t)=f_T(t | T > t)=\frac{-R'(t)}{R(t)}\]

y se interpreta como la probabilidad de que un componente que funciona falle en el instante siguiente:
\[\mathbb{P}\{t<T\leq t + dt | T > t\}=f_T(t | T > t)dt=r(t)dt\]

Si la tasa de fallos tiene un valor constante, integrando la función $r(t)$ entre $0$ y $t$ y despejando $R(t)$ llegamos a:
\[R(t)=e^{-λt} \implies F_T(t) = 1-e^{-λt}\]

con lo que acabamos de obtener que el tiempo de vida es una distribución exponencial y su valor esperado será el MTTF=1/λ

\newpage
\subsubsection{Distribución de los fallos}

La función de tasa de fallos en un equipo tiene la forma que se muestra en la figura:
\begin{center}
\includegraphics[width=0.7\linewidth]{img/tasa_fallos.png}
\end{center}

Durante la zona de infancia la tasa de fallos es alta debido al montaje de componentes defectuosos. Esta tasa de fallos se reduce con el tiempo hasta alcanzar una etapa de madurez que se correspondería con la época en que tenemos tasa de fallos constante. Por último el envejecimiento del equipo aumenta la tasa de fallos.

Todos los cálculos se realizan penando en la zona de madurez del equipo, trabajando con $r(t)=cte$

Por otro lado tenemos también los fallos en programas que pueden dividirse en dos tipos según su tratamiento
\begin{enumerate}
\item[1] Programas que no son reparados cuando se encuentra el fallo sino que es necesario esperar a que se publique una nueva versión del mismo. Es la situación habitual en producción y con programas cerrados.

El modelo de tasa de fallos constante es válido durante el uso de una misma versión. Al cambiarla es necesario recalcular todos los datos.

\item[2] Programas cuyos defectos se corrigen conforme se encuentran. Suele tratarse de programas de producción propia o ciclos de pruebas en la producción de programas. El principal problema es que la solución de un defecto puede y suele introducir otros nuevos.

En este caso el modelo de tasa de fallos constante no es válido ya que en este caso tendremos una tasa de fallos que decrece con el tiempo (según se van arreglando los desperfectos). Su forma depende del modelo elegido para el ritmo de descubrimiento de fallos.

\subsubsection{Mantenibilidad}
Es la probabilidad de realizar una reparación satisfactoria en un tiempo determinado. Mide la rapidez y facilidad con que un sistema se vuelve a poner operativo tras un fallo.
\[M(t)=\mathbb{P}\{T'> t\} \text{ con T' el tiempo de reparación}\]

Este tiempo incluye el tiempo necesario para descubrir el fallo, encontrar la causa, conseguir las piezas necesarias, la instalación de las mismas, arrancar el sistema de nuevo, etc. Es decir, incluye todo el tiempo gastado desde que \textbf{se produce} el fallo (aún si no se detecta) hasta que se resuelve el problema.

\[MTTR=E[T']\]

\subsubsection{Componentes en serie vs Componentes en paralelo}

Si tenemos un sistema compuesto por componentes en serie, un fallo en cualquiera de ellos implica un fallo global. La conexión en serie puede no ser física pero si lógica, una componente depende del resultado del trabajo de otra.

Suponiendo que el fallo en cada componente es independiende del resto, tenemos:
\[A= \prod_{i=1}^{n}A_i; \ \ \; R(t)=\prod_{i=1}^{n}R_i(t); \  \ \; r(t)=\sum_{i=1}^{n}r_i(t)\footnote{No veo clara esta fórmula}\]

Si tenemos un sistema compuesto por componentes en paralelo y estas componentes son redundantes para su funcionamiento, un fallo en una de ellas no implicará un fallo en el sistema.

Suponiendo que el fallo en cada componente es independiente nos queda:
\[A= 1-\prod_{i=1}^{n}(1-A_i)\footnote{Estará disponible cuando al menos una componente esté disponible}; \ \ \; F_T(t)=\prod_{i=1}^{n}F_{T_i}(t); \  \ \; R(t)= 1-\prod_{i=1}^{n}(1-R_i(t))\]

\begin{center}
\includegraphics[width=\linewidth]{img/disponibilidad.png}
\end{center}

\end{enumerate}

\subsection{Mejoras de la disponibilidad}

Recordemos la ecuación inicial que dimos para la disponibilidad:
\[A=\frac{MTTF}{MTTF+MTTR}=\frac{1}{1+MTTR/MTTF}\]

simplemente viendo esta fracción podemos ver que la disponibilidad de un sistema puede mejorarse (aumentar) de dos formas:
\begin{itemize}
\item Aumentando $MTTF$ mejorando la calidad de los equipos, introduciendo redundancias o eliminando \textbf{Puntos Simples de Fallo}

\item Reduciendo $MTTR$ en cualquiera de las siguientes fases:
\begin{itemize}
\item Tiempo de \textbf{latencia} (desde que se da el fallo hasta que se descubre que algo falla)

\item Tiempo para aislarla (desde que se descubre hasta que se encuentra el motivo)

\item Tiempo para corregirla

\item Tiempo para verificar que todo funciona bien
\end{itemize}
\end{itemize}

\subsubsection{Arquitecturas que incrementan la disponibilidad}

La disponibilidad de una cadena de procesamiento es siempre menor que la menor de las disponibilidades de sus componentes. Denominamos \concept{Single Point Of Failure, SPOF} a los puntos más criticos del sistema, aquellos que al fallar implican la caída del servicio.

Como es evidente, la forma en que más podemos incrementar el $MTTF$ de cada componente es mediante la creación de un \textbf{cluster} (elementos redundantes) en cada parte de la cadena de procesamiento. Esta solución, además, elimina los SPOF al añadir redundancias incluso a esos componentes más críticos.

Conseguir que varios sistemas realicen en paralelo una misma función no es sencillo y la solución empleada depende de factores como el tipo de elemento al que se le quiere dar redundancia y las necesidades de disponibilidad del sistema completo.

En cualquier caso, siempre es necesario considerar dos procesos a la hora de implementar un sistema: el cómo actuar cuando se produce un fallo para poder mantener el servicio, \concept{Fail-over}, y cómo actuar para recuperar la situación normal una vez se resuelve el fallo \concept{Fail-back}.

\newpage
Existen diferentes tipos de redundancia:
\begin{enumerate}
\item[1] \textbf{Según el estado de cada elemento del cluster}

Pueden estar todos los elementos activos (AA), uno activo y el resto preparados para activarse casi instantáneamente (AS) o uno activo y el resto detenidos pudiendo activarse en un cierto periodo de tiempo (AP)

\item[2] \textbf{Según el reparto de carga entre los elementos del cluster}

Puede ser dinámico (D), en cuyo caso no habrá que preocuparse en caso de fallo de un componente; o estático (E), donde un fallo implica reconfigurar el reparto de carga

\item[3] \textbf{Según el tratamiento de las conexiones activas}

Las sesiones activas pueden continuar (C) tras un fallo o ser interrumpidas (I).
\end{enumerate}

\subsection{Redundancia en los sistemas de comunicaciones}
Los sistemas de comunicaciones son uno de los puntos críticos de todo sistema distribuido.

Vamos a distinguir la redundancia en las redesd de área local (LAN) y en redes de área extendida (WAN) considerando en ambos casos los estándares de facto actuales: redes LAN basads en Ethernet y TCP/IP como medio de transporte.

Las características de los equipos que actualmente se emplean para implementar una LAN hacen que estas redes se puedan construir atendiendo a tres modelos distintos:
\begin{itemize}
\item \textbf{Nivel 2 compartido} Múltiples servidores se conectan a un mismo segmento de LAN implementado en un \textit{Hub}. Es el menos utilizado por ser el menos eficiente y flexible.

El hub es un dispositivo que tiene la función de interconectar las computadoras de una red local. Su funcionamiento es más simple comparado con el Switch y el router:
El hub recibe datos procedentes de una computadora, los transmite a los demás. En el momento en que esto ocurre, ninguna otra conmutadora puede enviar una señal. Su liberación surge después que la señal anterior haya sido completamente distribuida.


\item \textbf{Nivel 2 conmutado} Cada enlace es un segmento de LAN. Todos los componentes se interconectan mediante \textit{switches}, que actúan como puentes multipuerta.

Suele emplearse en el \textbf{nivel de acceso}, por ejemplo, en las conexiones de los ordenadores de las granjas de servidores.

\item \textbf{Nivel 3} Cada enlace es un segmento de red que une un elemento con un \textit{router}. El \textit{router} se implementa también en los propios \textit{switches} mediante módulos especiales.

Suele emplearse en el \textbf{nivel de agregación} interconectando diverso niveles de acceso, servidores especiales y redes externas.
\end{itemize}

Estos modelos suelen coexistir dentro de un Centro de Proceso de Datos (CPD)
\begin{center}
\includegraphics[width=\linewidth]{img/niveles.png}
\end{center}

La instalación de redundancias en el nivel 3 implica el uso de un protocolo de encadenamiento dinámico (OSPF, BGP), igual que en el caso de redes de área extendida (WAN).

A nivel 2, implica la aparición de bucles en los posibles caminos entre dos nodos de la red lo que lo hace incompatible con el protocolo \textit{Transparent Bridging} empleado en Ethernet. Este problema se resuelve con el \textit{Spanning Tree Protocol}, que se mejoró con el \textit{Rapid Spanning Tree Protocol}. Para optimizar el uso de VLANs se deben crear múltiples \textit{spanning trees}, solución proporcionada por \textit{Multiple Spanning Tree}.

En definitiva, si en la red de comunicación tenemos redundancias en un determinado nivel, es necesario emplear un protocolo que permita encontrar el mejor camino de un elemento a otro aún con las redundancias.

\subsubsection{Rapid Spanning Tree Protocol, RSTP}

Al aplicar este protocolo tenemos cada switch asociado a un identificador que nos da su prioridad. El de mayor prioridad (menor identificador, ID1) se denomina switch raíz. El siguiente en prioridad se le denomina switch raíz alternativo (ID2).

Para cada puerto hay que determinar de que tipo es:
\begin{itemize}
\item Raíz. Da el mejor camino al switch raíz

\item Designado. Proporciona a cada segmento de red conectado al switch el mejor camino al switch raíz. Es decir, que para algún nodo, su mejor camino hasta el nodo raíz implicar coger justo este enlace.

\item Alternativo. Otros.
\end{itemize}

Periódicamente, cada switch genera una \textit{Bridge Protocol Data Unit, BDPU} y la envía a todos los switches de la red.

\textcolor{red}{Mirar el ejemplo de moodle subido por la profesora. Explica bastante bien el protocolo}

\subsubsection{Detección de fallos en RSTP}
Puede producirse un fallo en un enlace conectado a un RP o DP, que se detecta directamente por los switches que forman el enlace; o puede darse un fallo en un switch. Si hay tres turnos seguidos en los que no se recibe BDPU de un switch, se le da por muerto.

Tras el fallo, todos los switches reconfiguran el spanning tree, mediante intercambios locales de los switches afectados por el cambio y el resultado se propaga al resto de la red.

\obs Hay otra versión de este mecanismo es el \textit{spanning tree normal}, en el que únicamente el root bridge transmite BPDU. Sólo se detecta un problema tras 20 segundos (vida máxima) y tras esto recalculamos el spanning tree completo.

\subsubsection{Redundancia en la conexión de servidores a nivel 2}
La redundancia básica en la conexión de un ordenador a una LAN se consigue mediante el uso de dos o más adaptadores de red.

Los puertos de estos adaptadores (un puerto por adaptador) tendrán la misma MAC, pero sólo uno de los adaptadores estará disponible. Si cae, el sistema activará otro. No afecta a los protocolos de niveles superiores.

\begin{defn}[EtherChannels]
Consiste en la agrupación de enlaces Ethernet donde todos los puertos poseen la misma MAC como si fuesen sólo 1 (y así lo ven desde arriba) y están activos simultáneamente.

Da mayor rapidez en la resolución de fallos y mejora el ancho de banda pero su implementación es costosa. Se requiere que ambos extremos de la conexión tengan soporte de \textbf{EtherChannels}. Los componentes the un \txtbf{EtherChannel} no se pueden disgregar para conectar varios dispositivos distintos. A todos los efectos, es un único enlace.

\end{defn}

\subsubsection{Redundancia de las WAN}
Las redes WAN permiten establecer la interconexión entre elementos distantes de sistemas distribuídos. Se basan en el protocolo TCP/IP y se distinguen dos tipos de componenetes: enlaces y unidades de encadenamiento (routers).

La alta disponibilidad de las WAN se consigue teniendo muchos routers y enlaces para que siempre haya caminos alternativos. La gestión del tráfico a través de las diferentes rutas se lleva a cabo con los protocolos de encadenamiento dinámico que estudiamos en Redes: OSPB y BGP.

\begin{defn}[OSPF]
Protocolo de encadenamiento dinámico eficaz y ampliamente utilizado en redes IP. Se basa en el conocimiento de toda la red y el empleo de Dijkstra para localizar el camino más corto. Se organiza la red en áreas dentro de las cuales los routers encaminan los paquetes. Para cambiar de área se emplean los Area Border Gateways (routers fronterizos)

El mensaje OSPF Hello se emplea para conocer la topología de la red con lo que cada router conoce a sus vecinos. Y con el mensaje Link State se informa del estado de los enlaces.
\end{defn}

Se puede producir un fallo en OSPF por la caída de un enlace, que se deteca de forma inmediata, por la caída de un router, que se detecta gracias al protocolo OSPF Hello, que sirve de \textit{keep-alive}. El mensaje Hello se intercambia cada 10 segundos. Si tras cuatro rondas no se han recibido Hello's de un router, se le da por muerto.

Si en un caso concreto se requiere una configuración estática (estaciones de trabajo, por ejemplo) el router por defecto que se asigna a estos dispositivos se convierte en un SPOF (Single Point Of Failure). Para evitarlo se emplea un cluster de routers controlado con el protocolo \textit{Virtual Router Redundancy Protocolo, VRRP}

\begin{defn}[VRRP]
Protocolo de \textit{clustering} para routers empleado para proporcionar redundancia en routers en los casos en que representan un punto único de fallo en rutas de la red. El router se sustituye por un \textit{virtual router} formado por un router activo y otro en \textit{stand-by}.

El router de mayor prioridad será el activo y asume como propias una dirección IP y una MAC que habrán sido asignadas al router virtual. Si cae el router se activa otro.
\end{defn}

El router activo envía mensajes Hello en \textit{multicast} cada x segundos. Si transcurre un tiempo predefinido sin recibir mensajes Hello se da al router por muerto y se activa el siguiente en prioridad. Este tiempo de espera predefinido es menor cuanto menor sea la prioridad. Así cuando esté un router activo que no sea el inicial, tendrá más probabilidades de que se le de por muerto, por lo que el router principal tendrá más probabilidades de volver.

En el \textbf{fail-back} hay dos opciones:
\begin{itemize}
\item Si la configuración activa preempt, el router de mayor prioridad asume el tráfico. Supone una breve interrupción del servicio mientras se produce el cambio.
\item Si la configuración desactiva preempt, se deja el router actual como activo hasta un posible fallo, quedando el reincorporado como router de backup.
\end{itemize}

\begin{defn}[Balanceador de carga]
Un balanceador de carga es un dispositivo capaz de distribuir peticiones entre un grupo de servidores para su proceso. Tiene como objeto aumentar la capacidad de proceso y la disponibilidad del servicio.

Previamente se realizaba este proceso en redes IP a través del DNS, resolviendo el mismo nombre por distintas IP pero esto no garantizaba que el servidor estuviera activo y los cambios del DNS son lentos al propagarse por la red.

Frente a un switch que sólo maneja información de nivel 2 y un router que sólo maneja información a nivel 3, el \textbf{Load Balancer, LB} también utiliza información de los niveles de transporte y aplicación para realizar el encadenamiento. Como mínimo debe garantizar que en TCP todos los paquetes de la misma conexión van al mismo servidor.
\end{defn}

Para emplear un LB, se asigna una dirección IP virtual (VIP), puerto y protocolo para el servicio a prestar; se asocian al LB los servidores que prestan el servicio y se definen unos mecanismo de distribución de carga y entrega de paquetes.

Cuando llega una petición, el LB decide que servidor debe atenderla y se la reenvía. El servidor procesará la petición y devolverá una respuesta que será reenviada al cliente. Este último paso, según la configuración de entrega de paquetes, puede eliminarse siendo el servidor quien directamente responde al cliente. (Direct Server Return vs Destination NAT)

El mecanismo de distribución de carga puede ser cualquiera: Round Robin, alterno, menor número de conexiones, ponderado, mejor tiempo de respuesta, por origen de la petición, etc.

En cualquier caso es necesario considerar condiciones límite para realizar la entrega:
\begin{itemize}
\item Máximo número de conexiones permitido
\item Umral de tiempo de respuesta
\item \textbf{Gracefull Shutdown}. No mandar más mensajes a un servidor que quiere desconectarse
\item \textbf{Tiempo de gracia}. Tiempo que se deja a un servidor desde que está activo hasta que se le envía tráfico, para permitir su estabilización adecuada.
\end{itemize}

Si todos los paquetes de respuestas pasaban por el LB, se puede detectar un fallo si un servidor deja de responder, se puede monitorizar en \textit{handshake} de TCP o los códigos de retorno de HTTP. Si no es así, se emplean pruebas de nivel 3 con ICMP echo/replay; a nivel 4, con apertura/cierre de conexiones TCP; o pruebas de nivel 7, tratar de conectar con la aplicación. Estos acciones las realizaría el LB para comprobar que el servidor esté activo.

El LB debe ser capaz de hacer que un cliente se conecte siempre a un mismo servidor para que se mantenga la sesión, que no está implementada de modo estándar en TCP/IP. Existen diferentes formas de hacerlo:
\begin{itemize}
\item Aplicando un algoritmo de balanceo por origen. Tiene el problema de que si varios clientes están tras una NAT son indistinguibles en este sentido.
\item Por concurrencia de conexiones. Una nueva petición de un cliente se envía al mismo servidor que mantiene la actual
\item Cookies o identificadors SSL que guarden información de la sesión. Requiere analizar el paquete e impide que el balanceo se haga por paquete. Es necesario partir la conexión TCP en el LB
\end{itemize}

\subsubsection{Redundancia en los sistemas de almacenamiento de la información}



\printindex
\end{document}