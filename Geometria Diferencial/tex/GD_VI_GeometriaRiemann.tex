% -*- root: ../GeometriaDiferencial.tex -*-
\chapter{Introducción a la geometría riemanniana}

\hfill \textit{Prometo que yo he hecho lo mejor que he podido con esto.}

Tomaremos $X$ una variedad compacta y una métrica Riemanniana en $X$ dada por el producto escalar $\pesc{}_p$ en $\tgs_p X$. La condición es que dados $D, D'$ campos en $X$, la aplicación \begin{align*}
p & \longmapsto \pesc{D_p, D_p'}_p \\
x & \longmapsto ℝ
\end{align*} es infinitamente diferenciable en $X$.

% Autonota: Creo que lo que este hombre está tratando de explicarnos es cómo la métrica riemanniana permite replicar las nociones que ya teníamos de ℝ^n.

En una variedad riemanniana\footnote{Variedad compacta con métrica riemanniana.} algo.

En geometría de primero hacíamos cosas como medir la longitud de una curva $\appl{γ}{I}{X}$ dada por \[ \mop{long} γ ≝ \int_I \md{γ'(t)} \dif t \]

Dado que esta longitud no dependía de la parametrización, es una propiedad intrínseca de la imagen. Por alguna razón, se tiene que la distancia entre dos puntos es \[ \dst(x, x') ≝ \inf_{γ\, curva} \mop{long} γ \], que es una distancia que nos da la misma topología que teníamos antes\footnote{La topología de la variedad es la topología de subespacio inducida por el espacio ambiente.}. Esto será lo que nos dé una distancia riemanniana.

Para demostrar que es una distancia lo más difícil es ver que si la distancia es cero entonces los dos puntos son el mismo.

La métrica riemanniana también nos da una noción de ángulo. No sé cómo lo hace pero lo hace, parece ser.

Otra cosa que querríamos hacer es definir una isometría.

\begin{defn}[Isometría] Dadas dos variedades $X, X'$ y un difeomorfismo $\appl{Φ}{X}{X'}$, se dice que Φ es isometría si y sólo si para todo $p∈X$ y para todo par $D_p, D_p'$ de vectores tangentes se tiene que \[ \pesc{D_p, D_p'} = \pesc{Φ_{*,p}(D), Φ_{*,p}(D')} \]
\end{defn}

Dos variedades diferenciales isomorfas son la misma, aunque no tienen por qué tener la misma métrica riemanniana. En cambio, dos variedades isométricas sí que tienen la misma geometría riemanniana.

Las isometrías de una variedad forman un grupo y, en fin.

% TODO: Esto es una proposición.

Un último comentario: si hay particiones de la unidad para una variedad diferenciable compacta $X$ entonces hay una métrica. Tenemos la partición $(U_i, ρ_i)$. En cada abierto $U_i$ la métrica se puede definir como \[ \pesc{\dpa{}{x_j}, \dpa{}{x_k}}_i = δ_ij \], tomando esas parciales como los elementos de la base del tangente. Así, podemos combinarlo todo y decir que, dados dos vectores $D,D'$, su producto escalar es\footnote{No estoy muy seguro de esto porque lo ha puesto sin $D,D'$, pero a mí me gustan las ecuaciones sin vacíos.} \[ \pesc{D, D'} = \sum_i ρ_i \pesc{D, D'}_i \]

La cuestión es que puede haber muchas.

\section{Ecuaciones de estructura}

Nosequé de un libro del hijo de Cartan que se llama formas diferenciales y que está bien explicado.

La idea es construir ciertas formas diferenciales que son más o menos canónicaas y, usando esas formas diferenciales y las operaciones estándar construir nuevas formas y se ve que así aparecen muchas formas y llega un momento en el que no pueden ser indepentientes, hay tantas que tiene que haber relaciones entre ellas. Las relaciones entre las formas vendrán dadas por coeficientes que darán invariantes de la variedad, como curvatura o algo.

La idea va a ser coger formas, y aplicarles operaciones hasta que aparezcan estas relaciones porque no queda otra.

Lo primero que hacemos es definir una transformación afín $T$, que es un nosequé y un vector. Por notación, llamaremos \[ e_i ≝ T((0,\dotsc, 0, 1, 0, \dotsc, 0))\] donde el $1$ está en la posición $i$-ésima, y además \[ M ≝ T((0,\dotsc, 0))\], con $\det(e_1, \dotsc, e_n)$. Con esto diremos que tenemos una referencia afín dada por $(M, e_1, \dotsc, e_n)$. El conjunto de todas las referencias afines será $\mathcal{R} ⊆ R^n \underbrace{× \dotsb ×}_{n+1} ℝ^n ⊂ ℝ^{(n+1)n}$. Es un abierto por alguna razón.

Un nosequé móvil es un $S ⊂ \mathcal{R}$ es una referencia parametrizada de los puntos de $S$.En particular, uno puede parametrizar las referencias por el mismo punto que estamos... No sé ni cómo escribirlo.

De aquí viene el nombre: el método de la referencia móvil consiste en usar referencias móviles\footnote{Capitán obvio al rescate.} que varían de punto a punto.

Podemos considerar funciones $\mathcal{R}\longmapsto ℝ^n$, donde las funciones serán $M, e_1, \dotsc, e_n$, que a cada elemento de $\mathcal{R}$ le manda un elemento de la referencia. Por ejemplo, \begin{align*}
\appl{M}{\mathcal{R}&}{ℝ^n} \\
(M, e_1, \dotsc, e_n) &\longmapsto M
\end{align*}

Aquí por alguna razón se puede derivar $M$ con la diferencial exterior. Para funciones a valores vectoriales derivar dos veces da cero porque se hace componente a componenente \[ \dif(\dif M) = 0\]

Entonces ahora empieza a aparece ya estas uno-formas y dos-formas que son las que van a dar lugar a las ecuaciones de estructura. Yo considero $\dif M$, que se obtiene derivando las componentes de $M$. Y esto, va a ocurrir digamos en una referencia $r$ y se va a aplicar a un vector tangente $ξ ∈ ℝ^{n+1}$, luego \[ (\dif M)_r\, ξ = \sum_i ω_{i,r} (ξ) (e_i)_r\] porque estamos escribiendo un vector en la base y un vector son coordenadas por coeficientes numéricos, los $ω_{i,r}(ξ)$. Al final no se van a escribir casi nunca, no hace falta, y esto al final se va a escribir como  \[ \dif M = \sum_i ω_i e_i \] y sobreentendemos los puntos y los vectores.

Los coeficientes actúan sobre vectores tangentes y dan números, luego los $ω_i$ son 1-formas en $\mathcal{R}$. Los mismos cálculos se hacen para las otras funciones $e_j$, y tenemos que \( \dif e_j = \sum_k υ_{j,k} e_k \label{eqDerivadaE} \), donde los $ν_{j,k}$ son igualmente $1$-formas.

Así, tenemos $n^2 + n$ 1-formas que nos vienen de gratis. Son 1-formas normales. Lo que hacemos es derivarlas\footnote{Espíritu Guijarro: no sé qué hacer, luego derivo.} y ver qué pasa.

Lo que sabemos es que $\dif(\dif M) = 0$ y que $\dif(\dif e_i) = 0$. Por otro lado, tenemos que $\dif M = \sum ω_i e_i$. Ahora tenemos que volver a derivar, así que calculamos: \[ \dif(ω_i e_i) = \dif ω_i e_i - ω_i \y \dif e_i \]

Ahora, la derivada de $\dif e_i$ la tenemos en \eqref{eqDerivadaE}, luego sustituimos y nos queda que eso es igual a \[ \dif ω_i e_i - ω_i \y \left(\sum_k ν_{i,k} e_k\right) \]. Sumando todas estas cosas nos queda que \( 0 = \dif(\dif M) = \sum_i \dif ω_i e_i - \sum_i ω_i \y \sum_k ν_{i,k} e_k \label{eqRiemann2} \)

¿Qué quiero hacer con esto? Ya hemos escrito como algo que tiene formas diferenciales por los elementos de la base, luego vamos a usar que los $e_k$ son independientes, por lo que nos quedaría lo siguiente \[ 0 = \sum_k \left(\dif ω_k -\sum_i ω_i \y ν_{i,k} \right) e_k \], de donde se concluye ya que los $e_k$ son base que \[ \dif ω_k = \sum_i ω_i \y ω_k \]

Lo que se ve es que cuando se deriva, los coeficientes de $M$ que es lalalalalala traslación en la referencia en la que estamos, se obtienen unas $ω_i$ que al volverlas a derivar salen cosas que siguen siendo dependientes de la $ω_i$. Ahora, el mismo cálculo se puede hacer para las otras $e_i$ y lo que queda es que \[ \dif ν_{i,j} = \sum_k ν_{i,k} \y ν_{k,j} \] haciendo el mismo cálculo.

A estas ecuaciones se le llama las ecuaciones de estructura. A lass $ν_{i,j}$ se les llama la forma de conexión.

Queda una cosa más, que es que usando las referencias afines se puede hacer geometría afín, pero normalmente querremos hacer geometría euclídea (Riemanniana). Luego lo que habrá que suponer es que la referencia sea ortonormal, luego querremos obligar a que $\pesc{e_i, e_k} = δ_{ij}$.

Las referencias ortonormales $\mathcal{O} ⊂^i \mathcal{R}$ no es un abierto pero es una subvariedad de $\mathcal{R}$. En este conjunto se pueden definir $\gor{ω}_i = i^* ω_i$ y $\gor{ν}_ij = i^* ν_{ij}$ usando el cambio de variable $i$ de la inmersión (creo), y van a definir las mismas ecuaciones de estructura. Y entonces es lo mismo hacer la derivada y luego la imagen y nosequé cosas. Cuando estamos en geometría riemanniana les quitamos la barra porque es un abuso razonable.

La cuestión es que además de estas ecuaciones de estructura hay otra ecuación más que viene de aquí (no sé qué es aquí) ya que $\dif (e_i · e_j) = 0$ por ser base ortonormal, pero por Leibiniz \[ \dif (e_i · e_j) = \dif e_i e_j + e_i \dif e_j \] y sustituyendo nos va a quedar que $ν_{ij} = -ν_{ji}$. Entonces en el caso de referencias ortonormales se añade otra ecuación a las ecuaciones de estructura. Esto sguiere que con estas ν se va a poder hacer una matriz antisimétrica de 1-formas que se le llama Ω, matriz de conexión.

Con esto lo único que se ha hecho es la base digamos en $ℝ^n$ de la geometría que se va a hacer. La base viene luego de considerar variedades de $ℝ^n$. Lo que veremos el próximo día es qué ocurre cuando en $ℝ^n$ hay una subvariedad. De hecho, consideraremos el caso de $n=3$ con una subvariedad como superficie.
