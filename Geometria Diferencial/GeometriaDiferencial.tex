\documentclass[nochap]{apuntes}

\title{Geometría Diferencial}
\author{Guillermo Julián Moreno}
\date{14/15 C2}

% Paquetes adicionales

% --------------------

\begin{document}
\pagestyle{plain}
\maketitle

\tableofcontents
\newpage

\section{Formas diferenciales en abiertos de $ℝ^n$}

\subsection{Introducción y motivación}

Vamos a hacer un pequeño repaso de formas diferenciales. A lo largo de esta sección vamos a considerar la función $\appl{f}{U⊆ℝ^n}{ℝ}$, con $f∈C^∞(U)$.

Las formas diferenciales parten del concepto de derivadas y la búsqueda de ``tangentes'' a un punto. En esta línea, recordamos lo que es la matriz diferencial de una función, que por así decirlo nos da la tasa de variación de una función cuando nos movemos a lo largo de un vector.

\begin{defn}[Diferencial\IS de una función] Dada $\appl{f}{U⊆ℝ^n}{ℝ}$, con $f∈C^∞(U)$ y $x_0 ∈ U$, entonces el diferencial en un punto es $\Dif f(x_0) = f'(x_0) = (\Dif f)_{x_0}$, que se considera como una aplicación lineal
\begin{align*}
\appl{\Dif f}{ℝ^n&}{ℝ} \\
(λ_1, \dotsc, λ_n)^T &\longmapsto \sum \dpa{f}{x_i} (x_0) λ_i
\end{align*}
\label{defDiferencialD}
\end{defn}

Hay que tener en cuenta que el espacio de partida de $\Dif f$ $ℝ^n$ no es el mismo espacio de partida de $f$. Diremos que el $ℝ^n$ de $\Dif f$ es el espacio tangente de $f$ en $x_0$ (denotado por $Π_{x_0} U = ℝ^n$).

Por ser una aplicación lineal de $ℝ^n$ en $ℝ$, el diferencial está en el espacio dual de $ℝ^n$ o, más concretamente, del espacio tangente de $U$: \[ \Dif f(x_0) ∈ \left(Π_{x_0} U\right)^* ≝ Π_{x_0}^* U\] donde $Π_{x_0}^* U$ será el espacio cotangente.

El espacio tangente se identifica con su dual no de forma única: depende de la elección de la base. Es decir, son isomorfos pero no son canónicamente isomorfos, ya que hay muchos isomorfismos y no hay uno privilegiado.

Como el diferencial está en el espacio dual, sus elementos serán llamados \concept[Covector]{covectores}. Esto nos permitirá evitar líos de notación al considerar vectores en el espacio y por otro lado vectores en el espacio tangente.

Por otra parte, queremos introducir otra notación, la de las formas diferenciales, a partir de la diferencial exterior.

\begin{defn}[Diferencial\IS exterior] Dada $\appl{f}{U⊆ℝ^n}{ℝ}$, con $f∈C^∞(U)$ y $x_0 ∈ U$, entonces la diferencial en un punto es \[ (\dif f)_{x_0} = \sum \dpa{f}{x_i} (\dif x_i)_{x_0} \]. En general, la diferencial será \[ \dif f = \sum \dpa{f}{x_i} \dif x_i \] \label{defDifrenciald}
\end{defn}

En realidad, la única diferencia entre esta definición y la dada en \ref{defDiferencialD} es que cambiamos los $λ_i$ por $\dif x_i$. En ambos casos tenemos  Por definición, la diferencial es una 1-forma en el abierto $U$. Sabemos ya que una 1-forma es una expresión \[ ω = f_1 \dif x_1 + \dotsb + f_n \dif x_n \] con $f_i ∈ C^∞(U)$.

Cada $(\dif x_i)_{x_0}$ es un covector de $Π^*_{x_0}$, y de hecho $\set{(\dif x_i)_{x_0}}$ es una base del espacio de covectores.

\paragraph{Deducción de las reglas de cálculo} Vamos a considerar ahora una diferencial \[ \dif h = \dpa{h}{x_1} \dif x_1 + \dotsb + \dpa{h}{x_n} \dif x_n \] y una 1-forma \[ ω = f_1 \dif x_1 + \dotsb + f_n \dif x_n \]

Dado ω, nos preguntamos si existe una función $h$ tal que $\dif h = ω$. Es una propiedad muy deseable, porque nos da de alguna manera unas ciertas garantías de ``operación cerrada'' en formas diferenciales.

Esto es lo mismo que plantearse la resolución del sistema de ecuaciones diferenciales dado por \[ \dpa{h}{x_i} = f_i\quad i=1,2,\dotsc,n \]

Esta cuestión está resuelta por el teorema de Poincaré, que veremos más adelante durante el curso.

A primera vista, parece difícil que haya solución. Si uno elije las $f_i$ de forma aleatoria, tendremos demasiadas ecuaciones y pocas incógnitas. Luego debemos esperar condiciones de integrabilidad: las $f_i$ deben cumplir ciertas posibilidades para que la solución $h$ exista. Habitualmente estas condiciones son necesarias pero no siempre suficientes, y una vez que las encontremos suponemos que se cumplen (si no no hay solución) y veremos si bajo esas condiciones el problema tiene solución.

Dado que queremos que exista $h$, vamos a suponer que efectivamente existe $h$. Entonces va a ocurrir que $\dpa{h}{x_i} = f_i$, y si volvemos a derivar tendremos que $\frac{∂h}{∂x_j∂x_i} = \dpa{f_i}{x_j}$. Si derivamos en orden contrario, como el Teorema de Schwarz nos dice que las derivadas cruzadas son iguales, tendremos que tener \[ \dpa{f_i}{x_j} = \dpa{f_j}{x_i} \]

Hay una manera natural de poner toda esta información. Nosotros tenemos la matriz Hessiana de derivadas parciales segundas dada por \[ H = \left(\frac{∂h}{∂x_j∂x_i}\right)_{ij}\], que es simétrica por el Teorema de Schwarz.

Por otra parte, a partir de la forma diferencial $ω = f_1 \dif x_i + \dotsb + f_n \dif x_n$ podemos obtener la matriz $H_1$ dada por \[ H_1 = \del{\dpa{f_i}{x_j}}_{ij} \].

Habíamos visto que la diferencia entre la matriz diferencial y la diferencial exterior era simplemente de notación, luego parece lógico que $H = H_1$. Luego la condición de integrabilidad es que $H_1$ sea simétrica.

A partir de aquí podemos definir más formalmente la diferencial de una 1-forma

\begin{defn}[Diferencial\IS de una 1-forma] Dada una 1-forma ω, tenemos que \[ \dif ω ≝ H_1^Γ = \frac{H_1 - H^T_1}{2} \] donde $H_1^Γ$ es la parte antisimétrica de la matriz $H_1$.
\end{defn}

Esto nos lleva a poder dar una condición concreta para que exista la función $h$ que comentábamos antes. Como queremos que $H_1$ sea simétrica, la parte antisimétrica deberá ser 0. Podemos enunciar entonces el siguiente lema:

\begin{lemma} Si existe $h$ tal que $\dif h = ω$, entonces $\dif ω = 0$. \end{lemma}

Vamos a ver cómo aplicar todo ese tocho de antes para calcular la diferencial de una 1-forma $ω$ dada por \[ ω = f_1 \dif x_1 + f_2 \dif x_2 \] definida en un abierto $U ⊆ ℝ^2$. En este caso, su matriz $H_1$ será \[ H_1 = \begin{pmatrix} \dpa{f_1}{x_1} & \dpa{f_1}{x_2} \\ \dpa{f_2}{x_1} & \dpa{f_2}{x_2} \end{pmatrix} \], así que su parte antisimétrica será

\[ H_1^Γ = \begin{pmatrix} 0 & \displaystyle\frac{\dpa{f_1}{x_2} - \dpa{f_2}{x_1}}{2} \\ \displaystyle\frac{\dpa{f_2}{x_1}- \dpa{f_1}{x_2}}{2} \end{pmatrix} \]

Y como ese 2 molesta multiplicamos por dos y nos lo quitamos de en medio.

Como al diferenciar estamos derivando y la derivada es lineal, deberíamos esperar que \[ \dif ω = \dif (f_1\dif x_1) + \dif (f_2 \dif x_2)\], luego tenemos que ver cuánto vale $\dif(f_1\dif x_1)$.

Dado que la derivada tiene que seguir cumpliendo la regla de Leibniz, tenemos que tener \[ \dif(f_1\dif x_1) = \dif f_1 \dif x_1 + f_1 \dif \dif x_1 \]

Aquí ya empiezan a pasar cosas importantes de este cálculo de diferenciales. Principalmente que $ \dif \dif x_1 = 0$, ya que la matriz $H$ tiene que ser simétrica.

Ahora tenemos que calcular $ \dif f_1 \dif x_1 $, que será \[ \dif f_1 \dif x_1  = \left(\dpa{f_1}{x_1} \dif x_1 + \dpa{f_1}{x_2} \dif x_2\right)\dif x_1 = \dpa{f_1}{x_1}\dif x_1 \dif x_1 + \dpa{f_1}{x_2} \dif x_2 \dif x_1 \], luego sumando nos queda que

\[ \dif ω = \dpa{f_1}{x_1}\dif x_1 \dif x_1 + \dpa{f_1}{x_2} \dif x_2 \dif x_1  + \dpa{f_2}{x_1} \dif x_1 \dif x_2 + \dpa{f_2}{x_2} \dif x_2 \dif x_2 \]

Comparamos esto con la matriz antisimétrica dada por  \[ 2H_1^Γ = \begin{pmatrix} 0 & \dpa{f_1}{x_2} - \dpa{f_2}{x_1} \\ \dpa{f_2}{x_1}- \dpa{f_1}{x_2} \end{pmatrix} \] vemos que los términos $\dpa{f_1}{x_1}$ y $\dpa{f_2}{x_2}$ no aparecen, luego tiene que ser \[ \dpa{f_1}{x_1} \dif x_1 \dif x_1 = \dpa{f_2}{x_2} \dif x_2 \dif x_2 = 0 \], y por otra parte que el producto de diferenciales tiene que ser anticonmutativo, esto es, que $\dif x_1 \dif x_2 = - \dif x_2 \dif x_1$. Dado que este producto (producto exterior) es distinto al habitual, lo denotaremos como $\dif x_1 \y \dif x_2$.

Es decir, hemos extraído las dos reglas siguientes para el producto de diferenciales o \concept[Producto\IS exterior]{producto exterior}: \begin{align*}
\df{x_i, x_j} &= - \df{x_j, x_i} \\
\df{x_i, x_i} &= 0
\end{align*}

Vamos a extendernos un poco en el significado de la expresión $\df{x_i, x_j}$, y por tanto en el de la forma diferencial. En el fondo, no estamos más que definiendo unos objetos (las formas) y aplicando ciertas reglas razonables para calcular ciertas operaciones

\paragraph{¿Es $\dif ω = 0$ condición suficiente?} Tenemos que esto ($\dif ω = 0$) es una condición necesaria para que exista un $h$ tal que $\dif h = ω$. Ahora bien, ¿es condición suficiente?

Para demostrarlo, lo que vamos a hacer es construir esa función $h$. Es trivial ver que \[ h(x) = \int_γ \dif h \] para un cierto camino $\appl{γ}{I}{U}$. En este caso, aplicando la regla de Barrow

\[ \int_γ \dif h = \int_I \dif(h ○ γ) = h(γ(b)) - h(γ(a)) = h(x) - h(x_0)\] donde $x_0$ es el punto de inicio de $γ$. Es decir, que $h$ está definido salvo constante. Habría que ver, eso sí, que la definición que hemos construido no depende de la elección del camino $γ$ y que además, se cumple efectivamente que $\dif h = ω$.

Vamos a demostrar que la definición no depende del camino. Tomemos $γ_1, γ_2$ dos caminos distintos que empiezan y acaban en el mismo punto. Consideremos entonces $Γ = γ_1 * γ_2^-$, y sea $D$ la región encerrada por Γ.

Por un lado, tenemos que como $\dif ω = 0$, entonces $0 = \int_D \dif ω$. Por otra parte, por el teorema de Stokes, \[ \int_D \dif ω = \int_Γ ω = \int_{γ_1} ω - \int_{γ_2} ω \implies \int_{γ_1} ω = \int_{γ_2} ω\] luego la integral no depende del camino

Lo único que necesitamos para aplicar Stokes es que $U$ sea simplemente conexo, es decir, que no haya agujeros y que siempre podamos deformar un camino a otro, de tal forma que el borde de $D$ sea Γ.

En el fondo, esto es un reflejo de lo que haíamos visto en cursos anteriores de cálculo con campos de vectores conservativos: cuando eran conservativos ($\grad V = 0$) la integral sobre caminos cerrados era cero y además existía una función potencial.

\subsubsection{Resumen: reglas del cálculo de formas diferenciales}



\subsection{Estudio formal de las formas diferenciales}

\subsubsection{Espacio tangente y cotangente}

Suponemos un abierto $U ⊆ ℝ^n$ y un punto $x_0 ∈ U$.

\begin{defn}[Espacio\IS tangente] Se define el espacio tangente de $U$ en un punto como $Π_{x_0} U$ como un espacio vectorial sobre $ℝ$ de dimensión $n$. Los elementos $D^\vv_{x_0} ∈ Π_{x_0} U $ son las derivadas direccionales (en la dirección $\vv$) locales (en el punto $x_0$), que operan las funciones y dan números.
\end{defn}

Lo primero que nos damos

\section{Variedades diferenciables}

\subsection{Ejemplos de variedades diferenciables}

\section{Campos vectoriales y formas diferenciales: Teoremas de Frobenius y Poincaré}

\section{Integración en variedades: teorema de Stokes}

\section{Geometría de superficies. Curvatura de Gauss-Bonnet}

\section{Introducción a la geometría riemanniana}

%% Apéndices (ejercicios, exámenes)
\appendix

\chapter{Ejercicios}
\input{tex/GeometriaDiferencial_Ejs.tex}
\printindex
\end{document}
