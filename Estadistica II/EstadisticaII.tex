\documentclass[nochap]{apuntes}

\usepackage{hyperref}

\usepackage{tikztools}
\usepackage{fastbuild}
\usepackage{tikz-3dplot}

\usepackage{tikz}
\usepackage{graphicx}
\usepackage{latexsym, amsfonts, amsmath, amssymb, amscd, epsfig,amsthm}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage[nottoc]{tocbibind}
\usepackage{fancysprefs}

\usepackage{listings}
\lstset{
    language=R,
    basicstyle=\ttfamily
}

\usepackage{caption}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}



\input xy
\xyoption{all} %%!!
\usetikzlibrary{calc, intersections}
\author{Víctor de Juan}
\date{2014/2015 2º cuatrimestre}

\renewcommand*{\arraystretch}{1.5}
\title{Estadística II}
\precompileTikz

\begin{document}


\pagestyle{plain}
\maketitle

\tableofcontents
\newpage

\input{tex/EstII_sec1.tex}
\input{tex/EstII_sec2.tex}
\input{tex/EstII_sec3.tex}



\appendix
\chapter{Ejercicios}
\input{tex/EstII_ejercicios.tex}
\chapter{Recordando}

\section{Estimador de máxima verosimilitud}
\label{sec:estimadorMaximaVerosimilitud}
En lo que sigue vamos a suponer que $\{X_n\}$ es una muestra formada por v.a.i.i.d. cuya distribución tiene una función de densidad o de masa $f(.;\theta_0)$ perteneciente a una familia de funciones $\{f(.;\theta) \tq \theta \in \Theta\}$. $\theta_0$ nos indica el valor real, y $\theta$ es un parámetro genérico.

Intuitivamente, lo que pensamos con este método es que la función de masa mide lo verosímil que es que salga un cierto parámetro. 

\begin{defn}[Función\IS de verosimilitud] También llamada \textit{likelihood function}. Dada una muestra fija $\{x_n\}$, se define como

\[ L_n(\theta;x_1,\dotsc,x_n) = L_n(\theta) = \prod_{i=1}^n f(x_i;\theta) \]
\end{defn}

\begin{defn}[Estimador\IS de máxima verosimilitud]\label{defEMV} También llamado EMV o MLE (\textit{maximum likelihood estimator}) es el argumento que maximiza la función de verosimilitud:

\[ \hat{\theta}_n = \hat{\theta}_n(x,\dotsc,x_n) = \argmax_{\theta\in\Theta} L_n(\theta;x_1,\dotsc,x_n) \]

cuando ese máximo está bien definido.
\end{defn}

Para evitar usar derivadas en un producto potencialmente muy largo, podemos maximizar el logaritmo de la verosimilitud, que es creciente y está bien definido porque la densidad es siempre mayor que cero, y los casos en los que sea cero no los estudiamos porque no ocurren (ocurren con probabilidad 0).




\end{document}
