% -*- root: ../VariableReal.tex -*-
Habitualmente, uno llamaría a esto resumen pero así mola más. La idea es dar un esquema de cada una de las partes del curso, motivando y enlazando a los teoremas ya hechos.

\section{Teoría básica de la medida y la integración}

A estas alturas, ya deberíamos conocer perfectamente la teoría básica. En cualquier caso, sólo hace falta recordar que una medida es una función que nos asigna un número a los conjuntos medibles, que forman lo que se llama una σ-álgebra (como la \nlref{def:SAlgebraBorel}). Estudiamos las funciones medibles (\fref{def:FuncMedible}) y vemos cómo integrarlas en la \fref{sec:Integracion} (lo que nos lleva, obviamente, a la definición de una \nlref{def:FuncIntegrable}).

Una vez hecho eso, podemos saltar a algo más avanzado con el \nref{thm:FubiniTonelli}, que nos permitirá integrar en varias variables con la integral de Lebesgue; o ver la \nlref{sec:IntegPolares}. Este último tema nos da una cosa interesante, que es la posibilidad de medir la bola de cualquier dimensión con el \fref{crl:MedidaBn}.

Además, vemos dos teoremas de ``casi resultados'', el \nref{thm:Egorov} y el \nref{thm:Lusin}, que nos dan resultados para convergencia casi uniforme a partir de convergencia en casi todo punto y la casi continuidad de funciones medibles.

Después, vemos resultados de convergencia y cambio de límite con la integral en la \fref{sec:Convergencia}. Los principales son los siguientes:

\begin{itemize}
\item \nref{thm:ConvMonotona}: Con una sucesión monótona de funciones podemos intercambiar el límite y la integral.
\item \nref{thm:Fatou}: Con una sucesión de funciones no negativas, la integral del $\liminf$ es menor o igual que el $\liminf$ de la integral. La versión análoga es el \nref{thm:FatouInverso}, que funciona con el $\limsup$ y simplemente cambia el sentido de la desigualdad.
\item \nref{thm:ConvDominada}: Dada una sucesión convergente CTP dominada por una función integrable positiva, entonces podemos intercambiar el límite y la integral.
\end{itemize}

\section{Complementos de teoría de la integral y la medida}

Una vez repasado el curso de TIM, vamos con las cosas más avanzadas. La primera es ver el término que falta en el \nref{thm:Fatou}, que nos lo da el \nref{thm:LiebLoss}. Con una sucesión de funciones medibles convergentes a $f$ CTP, integrables de orden $p$ todas ellas y acotadas, se cumple que \[ \lim_{n\to ∞ } \int_X\abs{\abs{f_n}^p - \abs{f}^p - \abs{f_n - f}^p} \dif μ = 0\]

La demostración de ese teorema se hace con dos desigualdades que vendrán muy bien luego: la \nlref{prop:Young} y la \fref{prop:DesigualdadLiebLoss}, que básicamente nos dicen estas dos cosas, con $p,ε > 0$:
\begin{gather*}
 (a+b)^p ≤ C_p (a^p + b^p) \quad a,b > 0\\
\abs{\abs{a+b}^p - \abs{b}^p} ≤ ε\abs{b}^p + C_{ε,p} \abs{a}^p \quad a,b ∈ ℂ
\end{gather*}

Una vez hecho esto, la \fref{sec:ModosConvergencia} explica varios modos de convergencia de funciones, que con el nombre ya se sabe de qué van. Son, en orden, la \nlref{def:ConvLp}, \nlref{def:ConvUniforme}, \nlref{def:ConvEssUnif}, \nlref{def:ConvCasiUnif}, \nlref{def:ConvPuntual}, \nlref{def:ConvCTP} y la \nlref{def:ConvMedida}. Es interesante ver las funciones \eqref{eq:Conv:CE1} a \eqref{eq:Conv:CE4} para ejemplos y contraejemplos patológicos.

Esta sección nos sirve como excusa para demostrar la \nlref{prop:DesigualdadMarkov}, que nos dice que el conjunto donde una función tiene un valor muy grande es muy pequeño:
\[ μ\left(\set{x∈X \tq \abs{f} > ε }\right) ≤ \frac{1}{ε} \int_X \abs{f} \dif μ \]

\subsection{Medidas con signo}

Para trabajos más avanzados con medidas, es necesario poder manejar fácilmente una clase más general de medidas que no nos restrinjan demasiado: \nref{def:MedidaSigno} y las medidas asociadas a funciones medibles $m_f$: \[ m_f(E) = \int_E f \dif m \]

La restricción que pondremos será trabajar con \nlref{def:MedidaSFinita}, esto es, que tengamos un recubriiento del espacio medible con conjuntos de medida finita.

Las medidas asociadas a funciones nos dan un ``inverso'', que es la \nlref{def:MedidaDerivable}: $μ$ es derivable con respecto a $m$ si y sólo si $\dif μ = f \dif m$. Esta $f$ será la llamada Derivada de Radon-Nikodin. La \fref{prop:DerivadaClasicaMedida} nos da una forma de derivar en sentido clásico estas medidas.

Una vez definidas bien las medidas con signo, podemos ver dos teoremas de descomposición: el \nref{thm:DescompHahn} y el \nref{thm:DescompJordan}, que combinados nos dicen que hay una partición $X_+ ∪ X_-$ del espacio de medida y dos medidas $μ^+, μ^-$ con soporte en $X_+$ y $X_-$ respectivamente. En otras palabras, nos aseguran que las medidas con signo se pueden descomponer en una parte positiva y otra negativa.

Pero además hay otro teorema de descomposición, el \nref{thm:LebesgueRadonNikodin}, que nos da una descomposición $μ = m_f + μ_s$ con $m_f$ una medida asociada a una función integrable, y $μ_s$ una \nlref{def:MedidaSingular} a $m$ (esto es, cuyos soportes no intersecan). El \nref{thm:DescLebesgue} nos da un resultado parecido $μ = μ_{AC} + μ_S$ con $μ_AC$ \nlref{def:MedidaAbsCont} y $μ_S$ medida singular, ambas con respecto a la medida general $m$.

Además, si trabajamos con medidas continuas (medidas que a conjuntos formados por un único punto le da valor 0), la \fref{prop:DescompLebesgue} nos dice que la parte singular la podemos descomponer en una parte singular continua y en otra pure-point (suma numerable de deltas de Dirac).

\subsection{Teoría de diferenciación de Lebesgue}

El teorema fundamental del cálculo es algo muy familiar, normalmente expresado de esta forma:
\[ F(x) = \int_a^x f(t) \dif t \] con $F$ la ``antiderivada'' de $f$. Es decir, que derivando $F$ tendremos $f$: \[ \lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = f \]

Podemos unir estas dos ecuaciones y cogiendo la derivada como $\frac{F(x+h) - F(x-h)}{2h}$. En ese caso, nos queda la siguiente expresión del teorema fundamental del cálculo: \[ \lim_{h \to 0} \frac{1}{2h} \int_{x-h}^{x+h} f(t) \dif t = f(x) \]

Esta definición se puede extender a funciones generales y medidas abstractas. El resultado es el \nref{thm:DifLebesgue}, que sólo pide que $f$ sea integrable localmente, y nos da una igualdad para casi todo punto: \[ \lim_{r \to 0} \fint_{E_r(x)} f(y) \dif y = f(x) \], con $\set{E_r}$ una familia que se encoge bien a $x$ (ver la \fref{def:EncogerBien}). El símbolo $\fint$ es la \nlref{def:MediaLocal}, que no es más que la integral en un conjunto dividida por la medida del conjunto.

Aunque la prueba que aparece en los apuntes del teorema es más bien corta, en realidad depende de toda la teoría por detrás. Una parte muy importante viene del \fref{thm:LimiteAr}, que nos da la misma desigualdad pero para bolas y para funciones sin valor absoluto:
\[ \lim_{r\to 0} A_r f(x) = f(x) \]

La prueba de ese teorema es la más relevante, y empieza con el truco de quitarnos los valores lejanos (el teorema es local) para tener una función integrable globalmente. Con eso, introducimos una función continua $g$ muy cercana (con la medida de la integral) a $f$. En esa función continua, $\lim A_r f \convs[][r][0] g$. Eso nos permite hacer un juego de sumas y restas, lo que nos guía a la estimación de la medida de dos conjuntos ``malos''. Midiendo esos conjuntos, podemos aplicar el \nref{thm:Maximal}, que nos da una cota superior para el supremo de las medias locales (ver la \nlref{def:FuncMaximalHL}), y nos permite decir que la medida de los puntos ``malos'' se va a cero, luego efectivamente la desigualdad del teorema se cumple.

El teorema maximal recae en el \nref{lem:Recubrimiento}, que nos da una forma de recubrir (más o menos) un conjunto con bolas disjuntas y con medida aproximada.

\section{Espacios de Banach y Hilbert. Espacios $L^p$}

La idea del \nlref{def:EspLp} es coger las clases de equivalencia de funciones $p$-integrables (las que $\int_X \abs{f}^p < ∞$), donde dos funciones son equivalentes si son iguales en casi todo punto. Así, tenemos una sencilla descomposición que nos dice que podemos ``descojonar'' una función en casi todo punto todo lo que queramos, que seguirá siendo la misma clase de equivalencia.

Además, se define la norma $L^p$ cono la raíz $p$-ésima de la función elevada a $p$ sobre todo el espacio, que le da una estructura de espacio normado a $L^p$.

Para trabajar con las funciones \espLp, desarrollamos varias desigualdades integrales. Una de las más importantes es la \nlref{prop:DesHolder}, que nos dice que dados $1≤p,q≤∞$ con $\frac{1}{p} + \frac{1}{q} = 1$ (uno es el exponente conjugado del otro), y dos funciones $f ∈ \espLp$, $g ∈ L^q$, tenemos que \[ \int_X \abs{fg} \dif μ ≤ \norm{f}_p \norm{g}_q \], por lo que $fg ∈ L^1$.

Esta desigualdad también se puede generalizar (\fref{prop:DesHolderExt}) para $\frac{1}{p} + \frac{1}{q} = \frac{1}{r}$, y entonces nos dirá que $\norm{fg}_r ≤ \norm{f}_p \norm{g}_q$. La desigualdad también nos dice que $L^p(X) ⊆ \espLloc[1][X]$ (\fref{thm:LpIntegrableLocal}).

Otra desigualdad importante es la \nlref{thm:DesigualdadJensen}, que nos dice que \[ \fint_X φ(f(x)) \dif μ ≥ φ\left(\fint_X f(x) \dif μ\right) \] para φ convexa y obviamente con $μ(X) < ∞$. Además, $[φ(x)]_- ∈ L^1$.

En esta sección, también se demouestra que $L^p$ es un espacio de Banach (\fref{thm:RieszFrechetBanach}). Igualmente, vemos el tema de operadores (el espacio dual de $L^p$), que nos lleva al \nref{thm:ReprRiesz}, que nos dice que todo operador lineal λ sobre funciones $L^p$  se corresponde con la siguiente representación única \[ λ(f) = λ_g(f) = \int_X fg \dif μ \] con $g ∈ L^\frac{p}{p-1}$.
