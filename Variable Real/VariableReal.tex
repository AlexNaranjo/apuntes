\documentclass[nochap,palatino]{apuntes}

\usepackage{fancysprefs}
\usepackage{natbib}

\bibliographystyle{plainnat}

\title{Variable Real}
\author{Guillermo Julián Moreno}
\date{15/16 C1}

\begin{document}
\pagestyle{plain}
\maketitle

\tableofcontents
\newpage
% Contenido.

\section{Introducción. Repaso de teoría de la integral y la medida}

La teoría moderna de la integración sigue lo que se dice los tres principios de J.E. Littlewood (1885 - 1977), que dan de cierta forma la idea detrás de la integración según Lebesgue.

\begin{enumerate}
\item Cada conjunto (medible) es \textit{casi} una suma finita de intervalos.
\item Cada función absolutamente integrable es \textit{casi} continua.
\item Cada sucesión convergente puntualmente de funciones absolutamente integrable es \textit{casi} uniformemente convergente.
\end{enumerate}

Por ejemplo, uno de los problemas que se pretende resolver con la integral de Lebesgue es el de la convergencia de funciones. Con la integral de Riemann, para que se pueda intercambiar el límite con la integral (esto es, que $\int \lim f_n = \lim \int f_n$), la hipótesis necesaria es que $f_n$ converja uniformemente. La integral de Lebesgue si nos permitirá dar una noción más completa de convergencia (tercer principio) que nos permita intercambiar fácilmente la integral con el límite.

La teoría de Lebesgue también nos permite saltarnos problemas como el planteado por la \concept[Función\IS de Dirichlet]{función\IS de Dirichlet}, dada por \[ \mathbb{D}(x) = \begin{cases} 1 & x ∈ ℚ \\ 0 & x ∈ ℝ \setminus ℚ \end{cases} \]

$\mathbb{D}$ no es continua y por lo tanto no es integrable Riemann. La cuestión es que es \textit{casi} continua (segundo principio), así que con Lebesgue podemos quitarnos los problemas que aparecen en los puntos $x ∈ ℚ$ e integrarla sin problemas.

En resumen, en todos los casos lo que tendremos es que, para todo ε, existe un conjunto de puntos de medida ε (los ``puntos malos'') de tal forma que nos lo podemos quitar y tendremos una función convergente, continua o integrable.

Este curso consistirá en la búsqueda y manejo de esos ``puntos malos'': veremos si podremos integrar en ellos, derivarlos y qué ocurre con las funciones en esos puntos.

Para trabajar con estas ideas desarrollaremos el concepto de las medidas que, por así decirlo, serán ``funciones generalizadas''. Por ejemplo, la \concept[Delta\IS de Dirac]{delta\IS de Dirac}, una ``función'' que vale cero en todo punto menos en $x = 0$, donde tiene un valor no concreto, se define en realidad como una medida dada por \[ δ_0 (A) = \begin{cases} 1 & 0 ∈ A \\ 0 & 0 ∉ A \end{cases} \] de tal forma que $\int_{ℝ} f(x) \dif δ = f(0)$.

\subsection{Conjuntos, espacios y funciones medibles}

A lo largo del curso trabajaremos con varias convenciones. Trabajaremos sobre la tres-tupla $(X, \mathcal{X}, μ)$, lo que llamaremos un espacio de medida. $X$ será el conjunto sobre el que mediremos. Normalmente será un subconjunto de $ℝ^n$, pero para el caso nos da igual. $\mathcal{X}$ será la σ-álgebra, el conjunto de subconjuntos medibles de $X$\footnote{Ver apuntes de TIM de Pedro.}. Por último, μ será la medida que usemos para integrar, usando la integral de Lebesgue.

¿Cuál es la diferencia entre las integrales de Riemann y de Lebesgue? Lo que se suele decir es que el primero mide en vertical y el segundo en horizontal. Una analogía es verlo como contar billetes. Por ejemplo, tenemos un billete de 50, uno de 20, dos de 10 y dos de 5. Riemann los contaría según le salen de la cartera, mientras que Lebesgue los agruparía primero en conjuntos de billetes iguales y luego contaría.

Mirando funciones, lo que hace Riemann es montar rectángulos en el eje $X$, mientras que Lebesgue los monta en el eje $Y$. De esta forma, la integral de Lebesgue es más estable, mientras que la de Riemann ve mejor las oscilaciones, por así decirlo. Un ejemplo curioso es el de la siguiente integral, \( \int_0^∞ \frac{\sin x}{x} \dif x \label{eq:IntRiemmanNoLeb} \) que es Riemann integrable pero no Lebesgue porque el valor absoluto no es integrable.

Para seguir trabajando con las medidas y poder integrar, necesitaremos saber qué funciones podemos medir y cuáles no.

\begin{defn}[Función\IS medible] Dados dos espacios de medida $(X, \mathcal{X}, μ),\,(Y, \mathcal{Y},ν)$, se dice que una función \stdf es medible si y sólo si $\inv{f}(E) ∈ \mathcal{X}\quad ∀E ∈ \mathcal{Y}$.
\end{defn}

También necesitaremos saber en qué σ-álgebra estamos trabajando. Nosotros usaremos normalmente la σ-álgebra de Borel:

\begin{defn}[{σ}-álgebra\IS de Borel] Denotada por \borel, es la σ-álgebra más que pequeña tal que los abiertos son medibles.\end{defn}

Otra $\salgb$ importante es la \concept{{σ}-álgebra\IS de Lebesgue}, denotada por $\lebg (ℝ^n)$. La relación entre esta y la de Borel es que la de Borel está contenida en la de Lebesgue: $\borel \subsetneq \lebg $. De hecho, $\lebg  \setminus \borel = \mathcal{N}$, que es el conjunto de conjuntos de medida Lebesgue 0. Por ejemplo, las uniones numerables tienen medida cero, como los racionales. Este es el gran avance de Lebesgue: identificar los conjuntos de medida 0 para poder integrar más funciones.

Algo que nos interesará es ver la composición de funciones.

\begin{prop}

\begin{enumerate}
\item La composición de funciones \borel-medibles es \borel-medible.
\item La composición de funciones \lebg-medibles no es, en general, \lebg-medible.
\item La composición de funciones \lebg-medibles con una de ellas continua sí es \lebg-medible.
\end{enumerate}
\end{prop}

\subsection{Medidas positivas}

\begin{defn}[Medida\IS positiva]\footnote{Positivas implicará a partir de ahora mayor \textit{o igual} que cero.} Una medida positiva (no negativa) en un espacio medible \meds es una función
\begin{align*}
\appl{μ}{\mathcal{X}&}{[0,+∞)} \\
E &\longmapsto μ(E) ≥ 0
\end{align*} y tal que
\begin{enumerate}
\item $μ(∅) = 0$.
\item $μ\left(\bigcup_{n=1}^∞ E_n\right) = \sum_{n=1}^∞ μ(E_n)$ con $E_n$ disjuntos dos a dos.
\end{enumerate}
\end{defn}

Hay dos nombres cocretos que nos interesarán. Si $μ(X) < ∞$, entonces se dice que μ es una \concept[Medida\IS finita]{medida\IS finita}. Si $μ(X) = 1$, será una \concept[Medida\IS infinita]{medida\IS de probabilidad}.

Un ejemplo de una medida que no es una función es la delta de Dirac que habíamos visto antes, que de hecho es una medida de probabilidad.

\begin{prop}[Propiedades de la medida] Dado un espacio medible \meas:

\begin{enumerate}
\item \textbf{Monotonía}: Si $E⊂F$, entonces $μ(E) ≤ μ(F)$.
\item \textbf{Sub-aditividad}: $μ\left(\bigcup_{n=1}^∞ E_n\right) ≤ \sum_{n=1}^∞ μ(E_n)$ (sólo es igual si los conjuntos son disjuntos).
\item \textbf{Convergencia monótona}: Dada una sucesión de conjuntos $E_1 ⊂ E_2 ⊂ \dotsb$, entonces $μ\left(\bigcup_{n=1}^∞ E_n\right) = \lim μ(E_n)$.
\item \textbf{Convergencia dominada}: Dada una sucesión decreciente de conjuntos $E_1 ⊃ E_2 ⊃ \dotsb$, entonces $μ\left(\bigcap E_n\right) = \lim μ(E_n)$.
\end{enumerate}
\end{prop}

\subsection{Teorema de Littlewood}

Al principio de esta sección veíamos los principios de Littlewood. Estos se traducen en teoremas para los que ya tenemos suficiente teoría para enunciarlos. El primer teorema, obviamente, corresponde al primer principio de Littlewood.

\begin{theorem} Para todo $ε>0$ y para todo $E∈\mathcal{X}$ con $μ(E) < ∞$, existe un $F∈\algbA⊂ \mathcal{X}$ tal que \[ μ\left((E\setminus F) ∪ (F \setminus E)\right) < ε \], con $\algbA$ la familia de conjuntos simples (intervalos, cuadrados o cubos según la dimensión, que son los que sabemos medir).
\end{theorem}

Lo que este teorema nos dice es que cualquier conjunto medible se puede aproximar tan bien como queramos por conjuntos simples, que es la idea del primer principio de Littlewood.

\subsection{Integración}

Dado \meas un espacio de medida, definiremos la integral de la siguientes formas. Primero iremos a lo más simple, que son (atención al nombre) las funciones simples:

\begin{defn}[Función\IS simple] Se dice que $\appl{f}{X}{[0, +∞)}$ es simple si $f$ es de la forma \[ f(x) = \sum a_i \ind_{E_i}(x) \] para $\set{E_i} ⊆ \mathcal{X}$.\end{defn}

Para funciones simples $\appl{f}{X}{[0,+∞)}$ como \[ \int_X f\ \dif μ = \sum_{i=1}^n a_i μ\set{\inv{f}(a_i)} \] Como notación, hay que tener en cuenta que \[ \set{\inv{f}(a_i)} \equiv \set{x∈X\tq f(x)=a_i} \]

Para funciones más complicadas usaremos, como siempre, límites. Dada $\appl{f}{X}{[0, +∞)}$ medible, definiremos su integral como \[\int_X f \dif μ = \sup_{\substack{0≤g≤f \\ g \text{ simple}}} \int_X g \dif μ \]

Una observación que necesitaremos para poder usar esa definición es la siguiente proposición:

\begin{prop} Dada una familia de funciones $\appl{f_n}{X}{(-∞,+∞)}$ medibles, entonces $\sup f_n$ y $\inf f_n$ son medibles.\end{prop}

Con esto, ya podemos dar la definición de función integrable, que es bastante sencilla:

\begin{defn}[Función\IS integrable] Se dice que $f$ es integrable si y sólo si $\int f \dif μ < ∞$.\end{defn}

Ahora sólo nos falta aprender a integrar funciones negativas. Para eso definiremos las dos partes de una función: \begin{align*}
f_+ &= \max\set{f,0} \\
f_- &= \max\set{-f, 0}\end{align*}, de tal forma que $f = f_+ - f_-$, $\abs{f}= f_+ + f_-$ y entonces su integral es \[ \int_X f \dif μ = \int_X f_+ \dif μ - \int_X f_- \dif μ \]

Análogamente podemos hacer la integral de funciones complejas descomponiendo \[ f = (\Re f)_+ - (\Re f)_- + \imath (\Im f)_+ - \imath (\Im f)_- \] e integrando igual que antes.

Vamos a ver ahora las propiedades de las integrales.

\begin{prop} Dada $\appl{f}{X}{[-∞,+∞]}$, entonces

\begin{enumerate}
\item $f$ es integrable si y sólo si $\abs{f}$ es integrable\footnote{Esto en Riemann no es cierto, ver el contraejemplo de la \fref{eq:IntRiemmanNoLeb}.}, esto es, que $\int_X \abs{f} \dif μ < ∞$. En este caso decimos $f ∈ \lebg^1\meas \equiv \lebg^1 (X) \equiv \lebg_μ^1 (X) \equiv \lebg^1$, según lo que demos por supuesto en cada caso, donde $\lebg^1$ es el espacio vectorial de las funciones absolutamente integrable.
\item La aplicación que lleva cada función a su integral $f\longmapsto \int_X f \dif μ$ es lineal. Es fácil ver que $αf + βg = α \int_X f \dif μ + β \int_X g\dif μ$.
\item \concept{Desigualdad\IS triangular en $\lebg^1$}. Dada $\appl{f}{X}{ℂ}$ absolutamente integrable, entonces $\abs{\int f \dif μ} ≤ \int \abs{f}\dif μ$.
\item \textbf{Comparación}. Si $0 ≤ f ≤ g$, entonces $0 ≤ \int f \dif μ ≤ \int g \dif μ$. Además, si $f ≥ 0$ entonces $\int f = 0$ si y sólo si $f = 0$ en casi todo punto\footnote{$f = 0$ en casi todo punto si $∃N ⊂ X$ tal que $μ(N) = 0$ con $f ≠ 0$ en $N$.}. En el otro sentido, si $\int\abs{f} = 0$ entonces $f \equiv 0$ en casi todo punto.
\item Una función integrable se puede modificar todo lo que se quiera en un conjunto de medida nula mantieniendo su integral constante. Esta propiedad será un problema para definir los espacios de funciones integrables, como veremos más tarde.
\item $f ∈ \lebg^1_μ(X;ℂ)$ entonces $f$ es finita en casi todo punto.
\item La integral de Lebesgue ``generaliza'' la de Riemman, en el sentido de que todas las fórmulas como integración por partes, jacobianos y cambios de coordenadas son las mismas.
\end{enumerate}
\end{prop}

\begin{proof}
\begin{enumerate}
\item % TODO.
\end{enumerate}
\end{proof}

Ahora vamos con varios teoremas sobre integración.

\begin{theorem}[Teorema\IS de Fubini-Tonelli] Dada $\appl{f}{X×Y}{ℂ}$ medible, entonces \[ \iint\limits_{X×Y} f \dif μ \dif ν = \int_X \underbrace{\left(\int_Y f(x,y) \dif ν(y)\right)}_{F_1(x)} \dif μ(x) = \int_Y \underbrace{\left(\int_X f(x,y) \dif μ(x)\right)}_{F_2(y)} \dif ν(y) \] con $F_1$, $F_2$ medibles.

Concretamente, Tonelli nos da la medibilidad para funciones no negativas y Fubini la condición de integrabilidad.

\label{thm:FubiniTonelli}
\end{theorem}

Otro teorema, que se corresponde con el tercer principio de Littlewood.

\begin{theorem}[Teorema\IS de Egorov] Dada $\appl{f}{X}{ℂ}$ medible y $f_n \convs f$ en casi todo punto en $A⊆X$, entonces $f_n \convs f$ casi uniformemente en $A$. Esto es, converge uniformemente salvo en un conjunto de medida cero. Más formalmente, $∀ε>0$ existe un $N_ε⊆A$ tal que $f_n \convs f$ en $A\setminus N_ε$ y $0 ≤ μ(N_ε) < ε$.
\end{theorem}

La prueba de este teorema es sencilla y bonita:

\begin{proof} Podemos asumir que $f_n \convs f$ en todo punto\footnote{TODO: Entender por qué.}. Entonces, para $k,n ∈ ℕ$ definimos \[ E_n(k) = \sum_{m=n}^∞ \set{x∈X \tq \abs{f_m(x) - f(x)} > \frac{1}{k}} \], es decir, el conjunto de puntos en los que la función se aleja del límite.
Para todo $k$ fijo, es fácil ver que $E_n(k) ⊇ E_{n+1}(k) ⊇ \dotsb $ y además $\bigcap_{n=1}^∞ E_n(k) = ∅$\footnote{Esto también queda TODO.}. Entonces, por convergencia dominada de las medidas, sabemos que $\lim_{n\to \infty} μ(E_n(k)) = μ\left(\bigcap E_n\right) = μ(∅) = 0$.

Ahora la prueba se acaba de forma bastante sencilla: dado $ε > 0$ y $k∈ℕ$, elegimos $m_k$ tal que $μ(E_n(k)) ≤ \frac{ε}{2^k}$. Entonces, definimos $E = \bigcup_{k=1}^∞ E_{n_k}(k)$, y entonces $μ(E) ≤ \sum_{n≥1} μ(E_{n_k}) ≤ \sum_{k≥1} \frac{ε}{2^k} ≤ ε$.

Así, si $n > n_k$ y $x ∉ E$, tendremos que $\abs{f_n(x) - f(x)} < \frac{1}{k}$.

En definitiva, lo que hemos hecho ha sido coger todos los puntos donde va a converger y hacer algo más que me he perdido completamente.
\end{proof}

\begin{theorem}[Teorema\IS de Lusin] Dada $\appl{f}{X}{ℂ}$ medible con $μ(X) < ∞$, entonces $f$ es casi continua, que como viene siendo hasta ahora significa que $f$ es continua salvo en un conjunto de medida cero. Esto es, que $∀ε>0$ existe un $N_ε⊆X$ tal que $f$ es continua en $X\setminus N_ε$ y $μ(N_ε) < ε$.
\end{theorem}

\subsubsection{Integración en coordenadas polares}

Además de las coordenadas lineales, en los reales podemos usar (y lo haremos habitualmente) las coordenadas polares o esféricas, esto es, coordenadas basadas en el uso de una esfera o equivalente en $ℝ^n$ en lugar del cuadrado/cubo/cosa. Veamos cómo generalizar las coordenadas polares sin necesidad de usar cosenos y senos por todas partes.

\begin{defn}[Coordenadas\IS polares] Sea $\set{x ∈ ℝ^n \tq \md{x} = 1} = \bbs^{n-1}$ la esfera unidad en $ℝ^n$. Entonces, si $x ∈ ℝ^n \minuszero$ las coordenadas polares de $x$ son
\begin{align*}
r  &= \md{x} ∈ (0,∞) \\
θ &= \frac{x}{\md{x}} ∈ \bbs^{n-1} \\ % TODO: Esta notación es caca.
\end{align*}
con el cambio de coordenadas dado por la aplicación biyectiva
\begin{align*}
\appl{Φ}{ℝ^n\minuszero&}{(0,∞)×\bbs^{n-1}} \\
x &\longmapsto (r,θ)
\end{align*} con inversa continua $\inv{Φ}(r,θ) = rθ$.
\end{defn}

Dadas estas coordenadas, necesitamos definir una medida. Lo fácil será hacerlo usando $ℝ^n$, que para eso sabemos medirlo perfectamente. Denotaremos por $μ_\ast$ la medida de Borel en $(0,∞)×\bbs^{n-1}$ inducida por Φ desde la medida $μ$ de Lebesgue en $ℝ^n$. En otras palabras, \[ μ_\ast (E) = μ(\inv{Φ}(E)) \]

Pero podemos definir esa misma medida de forma constructiva, desde el espacio de las coordenadas polares.

\begin{theorem} \citep[Teorema 2.49]{folland99} Sea $ρ=ρ_n$ la medida en $(0,∞)$ dada por $ρ(E) = \int_E r^{n-1}\dif r$. Entonces existe una única medida de Borel $σ = σ_{n-1}$ en $\bbs^{n-1}$ tal que $μ_\ast = ρ × σ$. Si $f$ es Borel-medible en $ℝ^n$ y $f ≥ 0$ o $f ∈ \lebg^1(μ)$, entonces
\(
\int_{ℝ^n} f(x) \dif x = \int_0^{∞} \int_{\bbs^{n-1}} f(rθ) r^{n-1} \dif σ(θ) \dif r
\label{eq:MedidaPolares} \)
\end{theorem}

\begin{proof} Es fácil ver que, si $f$ es la función característica de un conjunto (esto es, $f \equiv \ind_E$), entonces \eqref{eq:MedidaPolares} es simplemente otra forma de decir que $μ_\ast = ρ × σ$, y se puede generalizar a $f$ sin mucha dificultad\footnote{TODO: Generalízalo, anda, so vago.}. Entonces, sólo tenemos que construir σ.

Si $E$ es un conjunto de Borel en $\bbs^{n-1}$ y $a > 0$, sea \[ E_a = \inv{Φ}\left((0,a] × E\right) = \set{rθ \tq 0 < r ≤ a, θ ∈ E }\]

Dado que \eqref{eq:MedidaPolares} se tiene que cumplir cuando en particular $f = \ind_{E_1}$; tenemos que tener que \[ μ(E_1) = \int_0^1\int_E r^{n-1} \dif σ(θ) \dif r = σ(E) \int_0^1 r^{n-1} \dif r = \frac{σ(E)}{n} \]

Definimos entonces $σ(E) = n · μ(E_1)$. Dado que la aplicación $E\mapsto E_1$ lleva conjuntos de Borel a conjuntos de Borel y conmuta con la unión, intersección y comlemento, está claro\footnote{TODO: Esto debería mirarlo bien.} que σ es una medida de Borel en $\bbs^{n-1}$. Además, dado que $E_a$ es la imagen de $E_a$ por la aplicación $x \mapsto ax$, se sigue de \citep[Teorema 2.44]{folland99} que $μ(E_a) = a^n μ(E_1)$, y por lo tanto si $0 < a < b$, entonces \[ μ_\ast\left((a,b] × E\right) = μ(E_b \setminus E_a) = \frac{b^n-a^n}{n}σ(E) = σ(E) \int_a^b r^{n-1}\dif r = (ρ × σ) \left((a,b]×E\right)\]

Fijado un conjunto de Borel $E$ de $\bbs^{n-1}$, sea $\algbA_E$ la colección de uniones finitas y disjuntas de conjutnos de la forma $(a,b] × E$, que es un álgebra en $(0,∞)×E$ que genera la σ-álgebra $\mathcal{M}_E = \set{A×E \tq A ∈ \borel_{\bbs^{n-1}}}$. Por el cálculo anterior tenemos que $μ_\ast = ρ × σ$ en $\algbA_E$, y por ser la medida única entonces esta ecuación también se cuple en $\mathcal{M}_E$. Pero\footnote{Se me acaba el tiempo y no me apetece seguir copiando. TODO.}

\end{proof}

\begin{corol} Si $f$ es una función medible en $ℝ^n$ tal que $f(x) = g(\abs{x})$ para alguna función $g$ en $(0,∞)$, entonces \[ f(x) \dif x = σ(S^{n-1}) \int_0^{∞} g(r) r^{n-1}\dif r \]
\label{crl:MediblePolares1}
\end{corol}

\begin{prop} \citep[Proposición 2.53]{folland99} Si $a > 0$, entonces \[ \int_{ℝ^n} e^{-a\md{x}^2} \dif x = \left(\frac{π}{a}\right)^\frac{n}{2} \]
\end{prop}

\begin{proof} Denotamos la integral por $I_n$. Para $n=2$, por el \fref{crl:MediblePolares1} tenemos que \[ I_2 = 2π\int_0^∞ re^{-ar^2} \dif r = \eval{- \left(\frac{π}{a}\right) e^{-ar^2}}_0^∞ = \frac{π}{a} \]

Dado que $e^{-a\md{x}^2} = \prod_{j=1}^n e^{-ax_j^2}$, por el teorema de Tonelli (\ref{thm:FubiniTonelli}) tenemos que $I_n=(I_1) ^ n$. En particular $I_1 = (I_2)^{\frac{1}{2}}$, y la proposición sigue naturalmente.
\end{proof}

Este resultado nos permitirá calcular $σ(\bbs^{n-1})$ para todo $n$ en términos de la función $Γ$.

\begin{prop} \citep[Proposición 2.54]{folland99} \label{prop:MedidaSn} \[ σ(\bbs^{n-1}) = \frac{2π^\frac{n}{2}}{Γ(n/2)} \]
\end{prop}

Podemos usar esta proposició para sacar la medida de la esfera unitaria en $n$ dimensiones.

\begin{corol} \label{crl:MedidaBn} Sea $\bola^n = \set{x ∈ ℝ^n \tq \md{x} < 1}$. Entonces \[ μ(\bola^n) = \frac{π^{n/2}}{Γ\left(\frac{n}{2} + 1\right)} \]
\end{corol}

También tenemos que ver si es cierto que $\int_{ℝ^ℕ}\frac{1}{\abs{x}^α} \dif x = ∞$ para todo $α∈ℝ$ (spoiler: sí).

Comprobar que $\int_{ℝ^N} \frac{1}{(1 + \abs{x})^α} < ∞$ para cierto $α$ encontrarlo (pone algo de cambio a polares) y luego que $\int_{B_1(0)} \frac{1}{\abs{x}^{β}} < ∞$ y $\int_{B_1(0)} \frac{1}{(1-\abs{x})^α}$.

\section{Teoría de la integral y la medida}

\section{Espacios de Banach y Hilbert. Espacios $L^p$}

\section{SOC en espacio de Hilbert. Series de Fourier}

\section{Transformada de Fourier}

\section{Introducción a la teoría espectral}

\section{La ecuación del calor}

%% Apéndices (ejercicios, exámenes)
\appendix

\chapter{Ejercicios}
\input{tex/VariableReal_Ejs.tex}

\nocite{terence10,folland99}

\bibliography{../Apuntes.bib}{}
\printindex
\end{document}
