%
% Soluciones a los ejercicios de Probabilidad II.
%
% Curso 2014 - 2015 2º cuatrimestre
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hoja 1}

Se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$, y que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra.

%%%%%%%%%%%%%%%%%%  PROBLEMA 1.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1]Probar el lema de Kronecker: si $\{x_n\}_1^\infty$ es una sucesión de números reales y $0 < b_1 \le b_2 \le \dots$ satisface $\lim_n b_n = \infty$, entonces la convergencia de $\sum_{i=1}^{\infty} x_i/b_i$ a un número real implica que $\lim_n b_n^{-1} \sum_{i=1}^{n} x_i =0$.
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 1.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2]Dar un ejemplo de tres eventos $A, B, C$ independientes 2 a 2, que no sean independientes.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 1.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3]Dado $C$ con $P(C) > 0$, decimos que $A$ y $B$ son condicionalmente independientes con respecto a $C$ si $P(A\cap B|C) =P(A|C) P(B|C)$. Probar que si  $P(B\cap C) > 0$, $P(A\cap B|C) =P(A|C) P(B|C)$ es equivalente a $P(A|C) = P(A|B \cap C)$. 
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 1.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4]Consideramos $[0,1)$ con los conjuntos de Borel y la medida de Lebesgue. 
Sea $D_n$ la colecciÓn de subintervalos diádicos en $[0,1)$ de la generación $n$, es decir, $D_n = \{[0, 2^{-n}), [2^{-n}, 2\cdot  2^{-n}), \dots, [1 - 2^{-n}, 1)\}.$ Usamos $\mathcal{A}_n$ para denotar la $\sigma$-álgebra generada por $D_n$. Sea $f(x) = x$. Decidir si $\lim_{n\to\infty} E(f|\mathcal{A}_n)$ existe, y en que sentido.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 1.5  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5] Estudiar para $ \alpha>0 $ la convergencia en
media cuadrática (es decir, en $L^2$) de la sucesión $\{X_n\}_{n=1}^\infty$, sabiendo que

\[  P(X_n=n)=\frac{1}{n^\alpha}, \hspace{5mm} P(X_n=0)=1-\frac{1}{n^\alpha}.
  \]
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Hoja 2}

Salvo afirmación expresa en sentido contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..

Recordatorio: si $1\le p < \infty$, $\|f\|_p := \left(\int|f|^p\right)^{1/p}$, mientras que
$\|f\|_\infty$ denota el supremo esencial de $|f|$. De hecho, la definición
 $\|f\|_p := \left(\int|f|^p\right)^{1/p}$ tiene sentido para cualquier $p > 0$ finito, pero puede
demostrarse que si $p < 1$ esta expresi\'on no define una norma.

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1]En el esquema que aparece a continuaci\'on, el agua fluye  desde $A$ hacia
$B$. Hay, como se indica en el dibujo, ocho compuertas.
Independientemente unas de otras, cada compuerta est\'{a} abierta con
probabilidad $p$, $0 <p <1$. Calcular la probabilidad de que el agua llegue
 de $A$ a $B$. Calcular dicha probabilidad cuando $p = 1/3$.
% Drawing generated by LaTeX-CAD 1.8a - requires latexcad.sty
% (c) 1996 John Leis leis@usq.edu.au
$$\xymatrix{    &   & \circ\ar @{.}[dr]!U||&  &   \circ  \ar @{.}[dr]!U|| &  &  \\
A \ar[r]  & \circ  \ar @{.}[ru]!U||   \ar @{.}[rd]!U||   & &  \circ \ar @{.}[ru]!U||  \ar @{.}[rd]!U||  & & \circ \ar[r]  & B\\  
  &   & \circ \ar @{.}[ru]!U||  &  &   \circ  \ar @{.}[ru]!U||   &  &  }$$
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 2.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2]Probar o refutar:
Para toda $X:\Omega \to \mathbb{R}$, $E(X|  \mathcal{A})^+ = E(X^+|  \mathcal{A})$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3]La desigualdad aritm\'etico-geom\'etrica 
dice que la media  aritm\'etica de un conjunto de n\'umeros no negativos es al menos tan grande
como su media  geom\'etrica, es decir, si $a_1, \dots ,a_n > 0$ satisfacen  $a_1 + \cdots  + a_n = 1$,  y  
 $x_1, \dots ,x_n \ge 0$, entonces $\Pi_{i=1}^n x_i^{a_i} \le \sum_{i=1}^n a_i x_i$.
Demostrar dicha desigualdad. Sugerencia: usar la concavidad
de log, o la convexidad de exp.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4]Demostrar la siguiente desigualdad de Young: para $t, u \ge 0$, y $p,q > 1$ tales que
$1/p + 1/q =1$, tenemos $tu \le t^p/ p + u^q/ q$. Observaci\'on: \'esta es otra forma de
escribir la  desigualdad aritm\'etico-geom\'etrica para $n=2$, mediante un cambio obvio de variables.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.5  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5]Sean $p,q \ge 1$ exponentes conjugados, es decir, $p$ y $q$ satisfacen
$1/p + 1/q =1$ (si $p=1$, entonces $q = \infty$, y viceversa).
Dado un espacio de medida arbitrario $(\Omega, \mathcal{A}, \mu)$, demostrar la desigualdad de
H\"older: si $f\in L^p$ y $g\in L^q$, entonces $fg\in L^1$, y $\|fg\|_1 \le \|f\|_p\|g\|_q$.
Sugerencias: El caso $p=1, q=\infty$ sale directamente de las definiciones.
Para $p >1$, suponemos que  $\|f\|_p, \|g\|_q\ne 0$, y reemplazamos 
$f$ y $g$ con 
 $f/\|f\|_p$ y $g/\|g\|_q$.  Despu\'es usamos la desigualdad de Young (punto a
punto) e integramos.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.6  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[6] Dada $f:\Omega\to \mathbb{R}$ en $L^p$,  $1 < p <  \infty$, escoger $g\in L^q$ tal que
$\int fg = \|fg\|_1 = \|f\|_p\|g\|_q$. Concluir que 
$\|f\|_p= \operatorname{sup}_{\{g\in L^q: \|g\|_q=1\}} \int fg $.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.7  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[7]Usar $\|f\|_p= \operatorname{sup}_{\{g\in L^q: \|g\|_q=1\}} \int fg $ cuando $1 < p <  \infty$
para obtener la desigualdad triangular o de Minkowski: $\|f + g\|_p \le \|f\|_p + \|g\|_p$.
Probar tambi\'en los casos (bastante obvios) $p=1$  y  $p = \infty$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.8  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[8]Probar que $\|\cdot\|_p$ es una norma en $L^p$ (considerando que dos funciones
son iguales
cuando son iguales en casi todo punto).
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.9  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[9]Probar la desigualdad de Jensen: si $X:\Omega\to I\subset \mathbb{R}$, donde
$I$ es un intervalo en $\mathbb{R}$, y $X$ tiene media finita, entonces para toda funci\'on
convexa $g:I\to \mathbb{R}$, $g(EX) \le E(g(X))$. Comentario: el caso particular $g(t) = t^2$
ya se ha visto (y usado) en clase. Es consecuencia de la no negatividad de la varianza.
Sugerencia: si $L(t) := a t + b$ es una recta, entonces conmuta con la integraci\'on:
$L(\int X(\omega) dP (\omega)) = \int L (X(\omega)) dP (\omega)$. La desigualdad de Jensen
es consecuencia de esta observaci\'on, junto con el hecho de que las funciones convexas
est\'an por encima de todas sus rectas soporte.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 2.10  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[10]Probar que si $0 < r\le s \le \infty$,
 entonces $\|f\|_{L^r(\Omega, \mathcal{A}, P)}\le \|f\|_{L^s(\Omega, \mathcal{A}, P)}$, luego $L^s(\Omega, \mathcal{A}, P) \subset L^r(\Omega, \mathcal{A}, P)$ (sugerencia, usar Jensen o H\"older). Demostrar que si el espacio tiene medida infinita, esta
inclusi\'on puede fallar.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Hoja 3}

Salvo afirmaci\'on expresa en sentido
contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..


Recordatorio: si $1\le p < \infty$, $\|f\|_p := \left(\int|f|^p\right)^{1/p}$, mientras que
$\|f\|_\infty$ denota el supremo esencial de $|f|$. \

%%%%%%%%%%%%%%%%%%  PROBLEMA 3.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1] Pepe y Jaime juegan con una moneda equilibrada, lanz\'andola hasta que por primera vez 
aparece la sucesi\'on  de longitud dos  elegida por uno de ellos. Usamos 1 para representar
cara, 0 para representar cruz.
Pepe escoge la sucesi\'on 11, y a continuaci\'on, Jaime elige  01, pensando que ello le da ventaja. 
Hallar la probabilidad de que gane Jaime.
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 3.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2] Probar que si $X := \{X_n\}_{n=0}^{\infty}$  es una martingala adaptada a la filtraci\'on
$\{\mathcal{A}_n\}_{n=0}^{\infty}$, entonces para todo $n>0$ tenemos 
$EX_n = EX_0$. 
Enunciar los resultados an\'alogos para sub y supermartingalas.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 3.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3] Probar que si $X := \{X_n\}_{n=0}^{\infty}$  es una martingala adaptada a la filtraci\'on
$\{\mathcal{A}_n\}_{n=0}^{\infty}$, entonces para todo $m, n\ge 0$ tenemos
$E(X_{n + m}|\mathcal{A}_n) = X_n$. Enunciar los resultados an\'alogos para sub y supermartingalas.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 3.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4] Sea $\{X_n\}_{n=0}^{\infty}$ una sucesi\'on de v.a.i.i.d., tales que 
$P(X_i = 1)= P(X_i = -1) = 1/2$, y sea $S_n := \sum_{i=0}^n X_i$.
Probar que $S := \{S_n\}_{n=0}^{\infty}$  es una martingala adaptada a la filtraci\'on
$\{\mathcal{A}_n\}_{n=0}^{\infty}$, donde $\mathcal{A}_n := \sigma(X_0, \dots, X_n)$.
En la demostraci\'on puede usarse el hecho de que si la v.a. $Y$ es independiente
de la $\sigma$-\'algebra $\mathcal{B}$, entonces $E(Y|\mathcal{B}) = E(Y)$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 3.5  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5] C\'omo ganar un euro con probabilidad 1, en un juego justo: la estrat\'egia del doble o nada.
Apostamos un euro a que sale cara. Si sale cara nos plantamos, si sale cruz apostamos
2 euros a que sale cara. Si sale cara nos plantamos, si sale cruz apostamos
4 euros a que sale cara. Etc.. Demostrar que la  estrat\'egia anterior gana un euro
 con probabilidad 1.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newpage
\section{Hoja 4}

Salvo afirmaci\'on expresa en sentido
contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..

Recordatorio: si $0 < p < \infty$, $\|f\|_p := \left(\int|f|^p\right)^{1/p}$, mientras que
$\|f\|_\infty$ denota el supremo esencial de $|f|$. 

%%%%%%%%%%%%%%%%%%  PROBLEMA 4.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1] Demostrar que si $X := \{X_t\}_{t\in T}$  es una colecci\'on uniformemente integrable
de variables aleatorias, entonces
$\|X\|_1 := \sup_{t\in T} \|X_t\|_{1} < \infty$.
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 4.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2] Sea $Y\in L^1$. Dada la filtraci\'on
$\{\mathcal{A}_n\}_{n=0}^{\infty}$, definimos
$X_n := E(Y|\mathcal{A}_n)$. 
Probar que $X := \{X_n\}_{n=0}^{\infty}$  es una martingala uniformemente integrable, 
adaptada a 
$\{\mathcal{A}_n\}_{n=0}^{\infty}$.  Decidir razonadamente a qu\'e converge.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 4.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3] Probar que si $X := \{X_n\}_{n=0}^{\infty}$  es una martingala adaptada a la filtraci\'on
$\{\mathcal{A}_n\}_{n=0}^{\infty}$, entonces para todo $n\ge 0$ tenemos 
que $\sigma (X_0, \dots ,X_n) \subset \mathcal{A}_n$, y $X$  es una martingala adaptada a  
$\sigma (X_0, \dots ,X_n)$. Aqu\'{\i} $\sigma (X_0, \dots ,X_n)$ denota la $\sigma$-\'agebra m\'as
peque\~{n}a que hace que todas las funciones $ X_0, \dots ,X_n $ sean medibles.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 4.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4] Probar que si $X := \{X_n\}_{n=0}^{\infty}$  es una submartingala, y 
$0  <  r\le s\le \infty$, entonces $\|X\|_r  \le \|X\|_s$, donde 
$\|X\|_p := \sup_{n\in \mathbb{N}} \|X_n\|_{p}$. 
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Hoja 5}

Salvo afirmaci\'on expresa en sentido
contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..

Recordatorio: si $0 < p < \infty$, $\|f\|_p := \left(\int|f|^p\right)^{1/p}$, mientras que
$\|f\|_\infty$ denota el supremo esencial de $|f|$. 

%%%%%%%%%%%%%%%%%%  PROBLEMA 5.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1] Los l\'{\i}mites superior e inferior de una sucesi\'on de conjuntos  $\{A_n\}_{n=1}^{\infty}  $ se
definen respectivamente como $\limsup_n A_n := \cap_{n\ge 1 } \cup_{k\ge n } A_k$ y 
$\liminf_n A_n := \cup_{n\ge 1 } \cap_{k\ge n } A_k$. Determinar que conjunto es m\'as grande.
Hallar la relaci\'on entre  $\limsup_n A_n$ y  $\limsup_n \mathbf{1}_{ A_n}$. Hacer lo mismo con los
 l\'{\i}mites inferiores.
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 5.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2] Probar que si $\{X_n\}_{n=1}^{\infty}$  converge c. s. a $X$, entonces para todo $\epsilon > 0$,
$P(\limsup_n\{ |X_n - X| > \epsilon\}) = 0$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 5.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3] Probar que si para todo $\epsilon > 0$,
$P(\limsup_n\{ |X_n - X| > \epsilon\}) = 0$, entonces  $\{X_n\}_{n=1}^{\infty}$  converge casi seguro a $X$.
Sugerencia: Tomar $\epsilon = 1/k$, $k$ natural, y usar el hecho de que la uni\'on numerable de conjuntos
de probabilidad cero tiene probabilidad cero.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 5.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4] Probar que la convergencia casi seguro implica la convergencia en probabilidad. Sugerencia: Usar alguno de los
problemas anteriores.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Hoja 6}

Salvo afirmaci\'on expresa en sentido
contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..

Recordatorio: si $0 < p < \infty$, $\|f\|_p := \left(\int|f|^p\right)^{1/p}$, mientras que
$\|f\|_\infty$ denota el supremo esencial de $|f|$. 


%%%%%%%%%%%%%%%%%%  PROBLEMA 6.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1] Dar un ejemplo de dos variables incorreladas pero dependientes.

\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 6.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2] Decidir razonadamente si la independencia de los sucesos $A$ y $B$ es equivalente a la independencia de $A$ y $B^c$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 6.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3] Hallar la relaci\'on entre la independencia de los sucesos $A$ y $B$, y la independencia de las variables aleatorias $\mathbf{1}_A$ y $\mathbf{1}_B$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 6.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4] Probar que si $X_n\to  X$ en $L^p$, donde  $0 < p \le \infty$, entonces $X_n\to  X$ en probabilidad.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 6.5  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5] Probar que si $X_n\to  X$ en  probabilidad, entonces $X_n\to  X$ en distribuci\'on. Decimos que
 $X_n\to  X$ en distribuci\'on si para todo punto $x$ de continuidad de $F_X$, $\lim_n F_{X_n} (x) = F_X (x)$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Hoja 7}

Salvo afirmaci\'on expresa en sentido
contrario se asume siempre que estamos trabajando en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$,
que  $\mathcal{B}\subset \mathcal{A}$ es una sub-$\sigma$-\'algebra, que las funciones son medibles, etc..


%%%%%%%%%%%%%%%%%%  PROBLEMA 7.1  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[1] Lanzamos una moneda lastrada, con probabilidad de sacar cara
igual a $3/5$. Si sale cara lanzamos un dado equilibrado con cuatro
caras numeradas del 1 al 4, y si sale cruz lanzamos un dado
equilibrado con seis caras numeradas del 1 al 6. Sea $Y$ el n\'umero
obtenido. Denotando $X=1$ si sale cara, $X=0$ si sale cruz, hallar
a) $E(Y|X)$, y  b) $E(Y)$.
\solution

\begin{expla}

\end{expla}

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  PROBLEMA 7.2  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[2] Tenemos un dado equilibrado con 6 caras numeradas del 1 al 6. Lanzamos la  primera vez y 
apuntamos el n\'umero $x$ obtenido. A continuaci\'on, 
lanzamos el dado $x$ veces y sumamos los valores $y_i$ obtenidos: $s_x = y_1 + \cdots  + y_x$.
Hallar $E(X)$, $E(Y_i)$, y $E(S_X)$, donde $X$ es la variable aleatoria ``resultado del primer lanzamiento", $Y_i$ el resultado del lanzamiento
$ 1 + i$, y $S_X = \sum_{k = 1}^X Y_k$. Se asume que todas
las tiradas son independientes. 
Determinar la relaci\'on entre las tres medias.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.3  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[3] a) Enunciar la Ley Fuerte de Los Grandes N\'umeros.

b) Consideramos $(0,1)$ con la medida de Lebesgue, Escribimos $w\in (0,1)$ usando
la expansi\'on decimal habitual. Definimos $X_n(w)$ como el n\'umero de sietes que aparecen
en las $n$ primeras posiciones de la expansi\'on decimal de $w$ (por ejemplo, $X_3(0.777) = 3,
 x_3(0.12345) = 0$.  Decidir razonadamente si $\lim_n n^{-1}X_n$ converge casi seguro, y
 en caso de respuesta afirmativa, hallar el l\'{\i}mite.
 
 c) Decidir razonadamente si 
 $$
 \lim_n \frac{X_n - 10^{-1}n}{n^{2/3}}
 $$ 
 converge casi seguro, y
 en caso de respuesta afirmativa, hallar el l\'{\i}mite.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.4  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[4]  Calcular las funciones generatrices de probabilidad, de momentos y las funciones caracter\'{\i}sticas de $X$ cuando $X$ es
a) Bernoulli$(p)$,
b) Binomial$(n,p)$,
c) Poisson$(\lambda)$. Usar unicidad y la propiedad multiplicativa para conclu\'{\i}r que la suma de v.a. independientes
con distribuci\'on Poisson$(\lambda_i)$, $i = 1, \dots, n$, es Poisson$(\sum_1^n \lambda_i)$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.5  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5] Calcular la funci\'on generatriz de momentos y la funci\'on caracter\'{\i}stica de $X\sim \operatorname{Uniforme}(0,1)$. 
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.6  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[6]Calcular la funci\'on generatriz de momentos y la funci\'on caracter\'{\i}stica de $Z\sim N(0,1)$. 
 
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.7  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[7]Probar que la funci\'on caracter\'{\i}stica de $X$ con media 0 y varianza $1$
satisface
$$
\phi_X(t) = 1 - \frac{1}{2} t^2   + o(t^2)
$$ 
cuando $t\to 0$. Sugerencia: usar la expansi\'on de Taylor de $e^{ir}$, donde $r$ es real.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.8  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[8] Demostrar el TCL usando los ejercicios anteriores, unicidad y la propiedad multiplicativa de las funciones
caracter\'{\i}sticas, y el Teorema de Continuidad de L\'evy-Cram\'er.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.9  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[9]Para $n=1, 2, 3, \dots$, sea  $\{X_{n,m}\}_{m=1}^{n}$  una configuraci\'on triangular de v.a., tales que las variables en cada fila son independientes, sea $S_{n} := \sum_{i=1}^n X_{n,i}$, y sean $0 < a < b < 1$. Supongamos que las
variables en la fila $n$ son Bernoulli($p_n$), es decir, $P(X_n = 1) = p_n$, $P(X_n = 0) = 1 - p_n$.
Usar el Teorema de Berry-Esseen para demostrar que si $a \le p_n \le b$ para todo $n$,
entonces $(S_n - n p_n)/\sqrt{n p_n (1 - p_n)}$ converge en distribuci\'on a $Z\sim N(0,1)$.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.10  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[10]Probar que si $\{X_n\}_{n=0}^{\infty}$  es una sucesi\'on de v.a.i.i.d. en $L^2$, se cumple
la condici\'on de Lindeberg. Sugerencia, usar el Teorema de la Convergencia Dominada de
Lebesgue.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.11  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[11] Para $n=1, 2, 3, \dots$, sea  $\{X_{n, m}\}_{m=1}^{n}$  una configuraci\'on triangular de v.a., tales que las variables en cada fila son independientes, y sea $S_{n} := \sum_{i=1}^n X_{n, i}$.

a) Enunciar la condici\'on de Lindeberg.

b) Suponiendo que las variables en la fila $n$ son Bernoulli($p_n$), con
$p_n = n^{- 1/2}$,
decidir razonadamente
si 
$(S_n - n p_n)/\sqrt{n p_n (1 - p_n)}$ converge en distribuci\'on a $Z\sim N(0,1)$.

c) Sea $s \in (0,1)$. Decidir razonadamente qu\'e sucede si en el apartado anterior, en
vez de  $p_n = n^{ - 1/2}$ tenemos $p_n = n^{ - s}$.

d) Decidir razonadamente qu\'e sucede si en el apartado b), en
vez de  $p_n = n^{- 1/2}$ tenemos $p_n = n^{ - 1}$.
Sugerencia: recordar la Ley de los N\'umeros Peque\~nos.
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%  PROBLEMA 7.12  %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[12] Probar que la condici\'on de Lyapunov implica la condici\'on de Lindeberg. 
La condici\'on de Lyapunov nos dice que existe un $\delta > 0$ tal que
$\lim_{n\to \infty} Lyap(n, \delta) = 0$, donde 
$$
Lyap(n, \delta) := \frac{1}{s_n^{2 + \delta}} \sum_{k=1}^n  E|X_k - \mu_k|^{2 + \delta} .
$$
\solution

\begin{expla}

\end{expla}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}[5]Determina si es verdadero o falso:

\ppart Si añadimos 7 a todos los datos de un conjunto, el primer cuartil aumenta en 7 unidades y el rango intercuartílico no cambia.

\ppart Si todos los datos de un conjunto se multiplican por -2, la desviación típica se dobla.

\ppart Si todos los datos de un conjunto se multiplican por 2, la varianza se dobla.

\ppart Al multiplicar por tres todos los datos de un conjunto, el coeficiente de asimetría no varía

\ppart Si el coeficiente de correlación entre dos variables vale -0.8, los valores por debajo del promedio de una variable están asociados con valores por debajo del promedio de la otra.

\ppart Si $\forall i\,y_i<x_i$ entonces el coeficiente de correlación es negativo.


\ppart Si cambiamos el signo de todos los datos de un conjunto, el coeficiente de asimetría también cambia de signo.

\ppart Al restar una unidad a cada dato de un conjunto, la desviación típica siempre disminuye.

\ppart Si a un conjunto de datos con media $\gx$ se le añade un nuevo dato que coincide con $\gx$, la
media no cambia y la desviación típica disminuye.

\solution 

\spart Falso. Añadir siete a todos los datos es una traslación, así que la distribución de los datos no cambia. El rango intercuartílico se mantiene y el cuantil también.

\spart Teniendo en cuenta que si multiplicamos todos los datos del conjunto por $-2$ la media también se multiplica por $-2$, y sustituyendo en la fórmula de la varianza:

\[ \sigma' = \sqrt{\frac{1}{n} \sum_{i=1}n (-2x_i)^2 - (-2\avg{x})^2} = \sqrt{\frac{1}{n} \sum_{i=1}4\left(n x_i^2 - \avg{x}^2\right)} = \sqrt{4\sigma^2} = 2\sigma \]

Por lo tanto, la desviación típica sí se dobla.

\spart Usando los cálculos del apartado anterior vemos que la varianza se multiplica por cuatro.

\spart Efectivamente: cambiar el signo haría una reflexión de los datos sobre el eje Y y la asimetría estaría orientada hacia el lado contrario. 

\spart  Teniendo en cuenta que si multiplicamos todos los datos del conjunto por $3$ la media también se multiplica por $3$

El coeficiente de asimetría se calcula:

\[\frac{1}{n} \sum_{i=1}^n (x_i-\gx)^3\]

Sustituyendo en la fórmula del coeficiente de asimetría

\[\frac{1}{n} \sum_{i=1}^n (3x_i - 3\gx)^3 = \frac{1}{n} \sum_{i=1}^n 3^3 (x_i-\gx)^3 = 27 \cdot \frac{1}{n} \sum_{i=1}^n (x-\gx)^3\]

Por lo tanto el coeficiente de asimetría sí varía.

\spart Falso. \[ \hat\sigma^2 = \frac{1}{n} \sum_{j=1}^n (y_j - \avg{y})^2 = \begin{cases} y_j = x_j - 1 \\ \avg{y} = \frac{1}{n} \sum_{j=1}^n (x_j - 1) = \frac{1}{n} ( \sum_{j=1}^n x_j ) - 1 = \avg{x} - 1 \end{cases} \]
\[ = \frac{1}{n} \sum_{j=1}^n (x_j - 1 - ( \avg{x} - 1))^2 = \frac{1}{n} \sum_{j=1}^n (x_j - \avg{x})^2  = \sigma^2 \]

\spart Falso. 2 variables pueden tener una correlación creciente aunque $y_i<x_i$.

\spart Falso. La desviación típica se mantiene (los datos siguen estando ``igual de separados'').

\spart Verdadero. Al hacer el cálculo de la media no varía (en la fórmula del ejercicio 2 se puede comprobar que si añadimos un $x_i=\gx$ el sumatorio de la derecha queda igual) y la desviación típica disminuye.

\end{problem}
