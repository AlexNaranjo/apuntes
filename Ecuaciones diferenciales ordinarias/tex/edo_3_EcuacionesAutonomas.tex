\section{Ecuaciones autónomas}
En algunos de los ejemplos que hemos realizado hemos trabajado con ecuaciones diferenciales ordinarias que \textbf{no} dependían explícitamente de $x$. Son las denominadas ecuaciones diferenciales ordinarias autónomas:

\begin{definition}\name[Ecuación diferencial ordinaria]{autónoma}
Una EDO autónoma es aquella que no depende explícitamente de $x$. Formalmente, es aquella cuya expresión es, en forma explícita: $$F(y, y^\prime, y^{\prime\prime}, \hdots, y^{(n-1)}) = y^{(n)}$$
\end{definition}

En adelante trataremos las ecuaciones autónomas de primer orden por simplicidad, dado que ya hemos visto que toda EDO de orden $n$ se puede reducir a un sistema de $n$ EDO de orden $1$. Es decir, analizaremos las EDO de la forma $$y^\prime(x) = f(y(x))$$

Las EDO autónomas son un caso particular de EDO que tienen las siguientes \textbf{propiedades}:

\img{img/propiedades-autonomas.png}{Gráfica de $f$ de la EDO $y(x)^\prime = f(y(x))$}{propiedades-autonomas}{0.8}

\begin{itemize}
\item Las soluciones son invariantes por traslaciones.

$$y_0(x) \text{ es solución } \implies y_c(x) = y_0(x-c) \text{ es solución.}$$

\item Los puntos críticos o estacionarios son solución.

$$f(c) = 0 \implies y=c \text{ es solución.}$$

\item Monotonía en las regiones en las que $f\neq 0$.

Dado que $y^\prime(x) = f(y(x))$, tenemos que si $f\gt0$ entonces $y$ será monótona creciente, y si $f\lt0$ entonces $y$ será monótona decreciente. Para ver esto mejor suponer que $a,b$ y $c$ son puntos críticos y observar la \textbf{Figura \ref{fig:propiedades-autonomas}}.

Denominaremos a estas regiones \textbf{Bandas (o regiones) de monotonía}\index{Bandas de monotonía}.

\item Las únicas posibles asíntotas horizontales de las soluciones de la ecuación son los puntos críticos de $y$, siendo $f$ continua.

Supongamos que $\exists a $ tal que $a$ es una asíntota horizontal de las soluciones de la EDO y \textbf{no} es un punto crítico de $y$. Entonces si $y(x)\to a$ cuando $x\to \infty$ tenemos que $y^\prime(x)\to 0$ por ser $a$ una asíntota. Como partimos de que $$y^\prime(x) = f(y(x))$$ entonces
\begin{equation}
f(y(x))\to 0
\label{eq:eq_autonomas1}
\end{equation}

Usando que $f$ es continua vemos que como
\begin{equation}
y(x)\to a \implies f(y(x))\to f(a)
\label{eq:eq_autonomas2}
\end{equation}
Por tanto usando \ref{eq:eq_autonomas1} y \ref{eq:eq_autonomas2} concluimos que $f(a) = 0$, lo cual es una contradicción porque hemos partido suponiendo que $a$ \textbf{no} es un punto crítico de $y$.
\end{itemize}

\subsection{Diagramas de fases}
Sea $y^\prime = f(y)$ una EDO en la que $f$ es la mostrada en la \textbf{Figura \ref{fig:propiedades-autonomas}}. Podemos observar que si nos situamos ``a la izquierda de $a$'' o ``entre $b$ y $c$'' la función $y$ es decreciente. Del mismo modo, si nos situamos ``entre $a$ y $b$'' o ``a la derecha de $c$'' la función será creciente mientras que en los puntos $a, b$ y $c$ la función ni crece ni decrece. El diagrama de fases de la \textbf{Figura \ref{fig:diagrama-fases}} representa lo descrito anteriormente.

En este caso diremos que $a$ y $c$ son puntos \textbf{inestables} pues una pequeña perturbación hará que nos alejemos de ellos. Igualmente, diremos que $b$ es un punto \textbf{estable} porque una pequeña perturbación hará que volvamos de nuevo a desplazarnos hacia $b$.

\img{img/diagrama-fases.png}{Diagrama de fases}{diagrama-fases}{0.8}

\subsection{Primer teorema de existencia y unicidad local}
Antes de enunciar el primer teorema de existencia y unicidad local, vamos a proporcionar unas definiciones y teoremas previos para poder demostrar el teorema:

\begin{definition}\name{Espacio métrico}
Un espacio métrico es un conjunto $M$ junto con una función $\app{d}{M\times M}{\R}$ que cumple las 5 propiedades de las distancias.
\end{definition}

\begin{definition}\name[Espacio métrico]{completo}
Un espacio métrico se dice que es completo si el límite de \textbf{toda} sucesión de Cauchy existe y está dentro del espacio. Es decir, si \textbf{toda} sucesión de Cauchy es convergente.
\end{definition}

\begin{definition}\name{Función continua de Lipschitz}
Diremos que una función $\app{F}{M}{N}$, con $M, N$ espacios métricos, es continua de Lipschitz si

$$\norm{F(x)-F(y)}_* \leq \alpha\norm{x-y}_\bullet\ \forall x,y\in M$$ donde
\begin{itemize}
\item $\alpha > 0$
\item $\norm{\ }_*$ indica la norma en $N$
\item $\norm{\ }_\bullet$ indica la norma en $M$.
\end{itemize}
\end{definition}

\begin{lemma}
$$f\in C^1 \implies f \text{ continua de Lipschitz}$$
\end{lemma}
\begin{proof}
Dado que $f\in C^1$ podemos aplicar el Teorema del valor medio. Dados $x,y,z \st z\in[x,y]$:
$$\abs{f(x) - f(y)} \leq \abs{f^\prime(z)}\abs{x-y} < C\abs{x-y}$$
Por tanto $f$ es continua de Lipschitz.
\end{proof}

\begin{definition}\name{Aplicación contractiva}
Una aplicación contractiva es una función continua de Lipschitz tal que $\alpha \in (0,1)\ \forall x,y\in M$
\end{definition}

\begin{theorem}[de la aplicación contractiva (o del punto fijo de Banach):]
Sea $\app{F}{X}{X}$ una aplicación contractiva con $X$ un espacio métrico completo. Entonces \textbf{existe} un \textbf{único} punto fijo $x_0$ de $f$.
\end{theorem}
\begin{proof}
\begin{itemize}
\item \textbf{Existencia}

La sucesión $\set{x, f(x), f^2(x), \hdots}$ es una sucesión de Cauchy porque $f$ es contractiva. Como $X$ es completo, la sucesión de Cauchy converge a un punto $x_0$ de $X$.

\item \textbf{Unicidad}

Supongamos que existen dos puntos fijos: $x_0 \neq x_0^\prime$. Entonces $d = \norm{F(x_0)-F(x_0^\prime)}_* = \norm{x_0-x_0\prime}_*$ donde $\norm{\ }_*$ indica la norma en $X$.

Como $f$ es contractiva $d = \norm{F(x_0)-F(x_0^\prime)}_* \leq \alpha\norm{x_0-x_0\prime}_* \lt \norm{x_0-x_0\prime}_*$ porque $\alpha < 1$. Tenemos $d\lt d$, que es una contradicción, por tanto $x_0 = x_0^\prime$.
\end{itemize}
\end{proof}

A partir de aquí ya disponemos de las herramientas necesarias para demostrar el teorema que abarca esta sección:

\begin{theorem}[de existencia y unicidad local para EDO autónomas:]
Dada una EDO autónoma de la forma
$$
y^\prime(x) = f(y(x))
$$
y un dato $y(x_0) = c$.

Entonces si $f$ es $C^1$, en particular, si es \textbf{continua de Lipschitz}, dado un entorno \textbf{local} de $x_0$, \textbf{existe} una \textbf{única} función $y$ tal que

$$
\left\lbrace
  \begin{array}{l}
     y^\prime(x) = f(y(x)) \\
     y(x_0) = c  \\
  \end{array}
  \right.
$$
\end{theorem}

\begin{proof}
\begin{enumerate}
\item Comencemos definiendo la aplicación $$\app{T}{\mathcal{X}}{\mathcal{X}}$$ tomando como $\mathcal{X} = \mathcal{C}([x_0-\delta, x_0+\delta])$ el espacio de las funciones continuas definidas sobre un intervalo cerrado y acotado (compacto) centrado en $x_0$ y de tamaño $2\delta$.

\item Sea $\norm{y}_\mathcal{X} = \max_{x\in [x_0-\delta, x_0+\delta]} \abs{y(x)}$ la norma definida sobre $\mathcal{X}$.
Vamos a analizar la convergencia en $\mathcal{X}$ con esta norma:

$y_n\to y \iff \norm{y_n-y}_\mathcal{X}\to 0 \iff max_{x\in [x_0-\delta, x_0+\delta]} \abs{y_n(x)-y(x)}\to 0 \iff y_n\to y$ uniformemente en $[x_0-\delta, x_0+\delta]$.

Tenemos por tanto que la convergencia en $\mathcal{X}$ es uniforme, que nos asegura que

$$\set{y_n}\subset \mathcal{X}\implies y_n\to y\ y\in \mathcal{X} \implies \mathcal{X}\text{ completo.}$$

\item Dado que disponemos de una norma en $\mathcal{X}$ podemos definir una distancia asociada, por lo que tenemos que $\mathcal{X}$ es un espacio métrico completo. Tenemos entonces que $$\app{T}{\mathcal{X}}{\mathcal{X}}$$ está definida sobre un espacio métrico completo.

\item Dada una EDO autónoma y un dato
$$
\left\lbrace
  \begin{array}{l}
     y^\prime(x) = f(y(x)) \\
     y(x_0) = c  \\
  \end{array}
  \right.
$$
podemos reescribir el problema integrando ambos lados de la primera ecuación:
$$\int_{x_0}^x y^\prime(x) = \int_{x_0}^x f(y(s))ds$$
$$ y(x) - y(x_0) = \int_{x_0}^x f(y(s))ds$$
Tenemos entonces el problema reescrito de forma integral como
$$ y(x) = y(x_0) + \int_{x_0}^x f(y(s))ds$$
Construimos ahora la aplicación $T$ como
$$ T(y) = y(x_0) + \int_{x_0}^x f(y(s))ds$$
Como $f$ es continua, la imagen de $T$ será una función continua, por lo que $\app{T}{\mathcal{X}}{\mathcal{X}}$ está bien definida. Y vemos que si $y$ es un punto fijo de $T$ entonces $y$ es solución de la EDO.

\item Sólo falta ver que si $T$ es contractiva entonces existirá un único punto fijo y por tanto la EDO tendrá una solución que además será única:
$$\norm{T(y(x)) - T(z(x))}_\mathcal{X} = $$
$$= \norm{\int_{x_0}^x (f(y(s)) - f(z(s)))ds}_\mathcal{X} = $$
$$= max_{x\in [x_0-\delta, x_0+\delta]} \abs{\int_{x_0}^x (f(y(s)) - f(z(s)))ds} \leq $$
$$\leq max_{x\in [x_0-\delta, x_0+\delta]} \int_{x_0}^x \abs{f(y(s)) - f(z(s))}ds$$

Como $f$ es continua de Lipschitz:
$$\norm{T(y(x)) - T(z(x))}_\mathcal{X} \leq $$
$$\leq max_{x\in [x_0-\delta, x_0+\delta]} \int_{x_0}^x C\abs{y(s) - z(s)}ds \leq$$
$$\leq \int_{x_0}^x C\ max_{x\in [x_0-\delta, x_0+\delta]}\abs{y(s) - z(s)}ds \leq$$
$$\leq C(x-x_0)\norm{y(x) - z(x)}_\mathcal{X} \lt $$
$$\lt C\delta \norm{y(x) - z(x)}_\mathcal{X}$$

Por tanto, escogiendo un entorno suficientemente pequeño, es decir, un $\delta$ suficientemente pequeño, tenemos que
$$\norm{T(y(x)) - T(z(x))}_\mathcal{X} \lt \norm{y(x) - z(x)}_\mathcal{X}$$
por lo que $T$ es contractiva para un entorno de $x_0$ y por tanto, en dicho entorno, la solución para la EDO \textbf{existe} y es \textbf{única}.
\end{enumerate}
\end{proof}

Vamos a ver un ejemplo de aplicación del teorema.

\begin{example}
Analicemos el sistema $\left\lbrace\begin{array}{l}y^\prime(x) = 1-y^2(x)\\y(0) = y_0\\\end{array}\right.$

que tiene dos puntos estacionarios $y=\pm1$.

Si $y_0\neq \pm1$ entonces la solución tendrá como asíntotas las rectas $y=\pm1$. Esto se debe a que si la solución ``tocase'' alguna de las rectas $y=\pm1$, entonces habría más de una solución en el punto de corte para la EDO, y esto no puede ser porque $f(y(x)) = 1-y^2(x)$ es $C^1$ y por tanto es continua de Lipschitz. Podemos aplicar el teorema y ver que la solución ha de ser única.
\end{example}

\subsection{Unicidad de soluciones}
En esta sección analizaremos cuándo no tenemos unicidad de soluciones con una EDO de la forma $y^\prime = f(y(x))$ cuando $f$ no cumple las hipótesis del teorema enunciado.

Comencemos viendo que $$y^\prime = f(y(x)) \wedge f(y(x))\neq 0 \iff \frac{y^\prime(x)}{f(y(x))} = 1$$
Integrando ambos términos tenemos $$\int_0^x \frac{y^\prime(s)}{f(y(s))}ds = \int_0^x ds=x$$
Realizamos el cambio de variables
$\left\lbrace
  \begin{array}{l}
     y(s) = u \\
     y^\prime(s)ds = du  \\
  \end{array}
  \right.
$ obtenemos $$F(y(x)) = \int_{y(0)}^{y(x)} \frac{1}{f(u)}du = x$$

Por lo que si $F\inverse(x)$ existe y es derivable, tenemos que $$F\inverse(x) = y(x)$$

Entonces, si se cumple que:
\begin{itemize}
\item $f(y(x))\neq 0$ lo que quiere decir que nos encontramos en las \textbf{bandas de monotonía}.
\item $F\inverse (x)$ existe, para que exista la solución $y(x)$.
\item $F\inverse (x)$ es derivable, porque $y(x)$ es derivable.
\end{itemize}
entonces $F\inverse(x) = y(x)$, por lo que la solución existe y es única.

Por el Teorema de la función inversa para que $F\inverse$ sea derivable, $F$ ha de ser $C^1$ y $F^\prime\neq 0$. Teorema Fundamental del Cálculo, para que $F$ sea derivable, $\frac{1}{f(u)}$ ha de ser continua, es decir $f(u)$ ha de ser continua y $f(u)\neq 0$.

En conclusión:
\textit{Si $f$ es continua, entonces tenemos existencia y unicidad en el interior de las bandas de monotonía.}

Consideremos la interpretación gráfica. Dada la EDO y el dato inicial que siguen
\begin{equation*}
  \left\lbrace
  \begin{array}{l}
     y^\prime(x) = f(y(x)) \\
     y(0) = y_0  \\
  \end{array}
  \right.
\end{equation*}

distinguimos tres casos, en los que consideraremos $c$ un punto estacionario:

\img{img/unicidad1.png}{Caso 1: Gráfica de la función $y$.}{unicidad1}{0.7}
\img{img/unicidad2.png}{Caso 1: Gráfica de la función $f$.}{unicidad2}{0.7}
\img{img/unicidad3.png}{Caso 2: Gráfica de la función $y$.}{unicidad3}{0.7}
\img{img/unicidad4.png}{Caso 2: Gráfica de la función $f$.}{unicidad4}{0.7}
\img{img/unicidad5.png}{Caso 3: Gráfica de la función $y$.}{unicidad5}{0.7}
\img{img/unicidad6.png}{Caso 3: Gráfica de la función $f$.}{unicidad6}{0.7}

\begin{enumerate}
\item En la \textbf{Figura \ref{fig:unicidad1}} se puede ver la gráfica de la supuesta solución de la EDO. En este caso, la solución tiene una asíntota horizontal en $y=c$. Por tanto, al tener que $F\inverse = y$, la gráfica de la función $F$ es simétrica a la de $y$ con respecto a la recta $y=x$ (\textbf{Figura \ref{fig:unicidad2}}).

Vemos entonces que para que se de el caso de que $c$ sea una asíntota de la solución tiene que cumplirse que $$\lim _{y\to c^-} \int_{y_0}^y \frac{du}{f(u)} = +\infty$$
teniendo así una \textbf{única} solución para la EDO.

\item En la \textbf{Figura \ref{fig:unicidad3}} se puede ver la gráfica de la supuesta solución de la EDO. En este caso, la solución corta a $y=c$ en el punto $M$. Por tanto, al tener que $F\inverse = y$, la gráfica de la función $F$ es simétrica a la de $y$ con respecto a la recta $y=x$ (\textbf{Figura \ref{fig:unicidad4}}).

Vemos entonces que para que se de el caso de que $M$ sea un punto de corte con $y=c$ de la solución, tiene que cumplirse que $$\lim _{y\to c^-} \int_{y_0}^y \frac{du}{f(u)} = M \lt \infty$$
teniendo así \textbf{múltiples} soluciones para la EDO, ya que como $c$ es un punto estacionario, $y=c$ también es solución.

\item En la \textbf{Figura \ref{fig:unicidad5}} se puede ver la gráfica de la supuesta solución de la EDO. En este caso, la solución está por encima de $y=c$ y tiene una asíntota vertical en $x=A$. Por tanto, al tener que $F\inverse = y$, la gráfica de la función $F$ es simétrica a la de $y$ con respecto a la recta $y=x$ (\textbf{Figura \ref{fig:unicidad6}}).

Esto es lo que se conoce como ``explosión en tiempo finito'', que quiere decir que la solución sólo está definida para $x\lt A$. Para que esto ocurra, tenemos que $$\lim _{y\to + \infty} \int_{y_0}^y \frac{du}{f(u)} = A$$
\end{enumerate}

Veamos esto con un ejemplo:

\begin{example}
Dada la EDO $$y^\prime = \sqrt{1-y^2}$$ y el dato $y(0) = y_0\in(-1,1)$,
vemos que los puntos críticos de la función son $y=\pm1$.
Analizando el comportamiento en $y=1$ hemos visto que existe más de una solución. Podemos comprobar que esto es cierto viendo que
$$\lim_{y\to 1^-}\int_{y_0}^y \frac{du}{\sqrt{1-u^2}} = \lim_{y\to 1^-} \arcsin(y) - \arcsin(y_0) = \frac{\pi}{2}-\arcsin(y_0) \lt \infty$$
\end{example}

