% -*- root: ../EDP2016.tex -*-
\chapter{Comportamiento cualitativo}

% clase 15/3/2016

En este capítulo vamos a ver:

\begin{itemize}

	\item Ondas (hiperbólica)
	\item Calor (parabólica)
	\item Laplace (elípticas)

\end{itemize}


\section{Ondas}

	Hemos visto ya el problema en dimensión 1: la cuerda vibrante.

	Hemos visto también el método de separación de variables que solo nos valdrá en un dominio acotado. Pero, ¿qué podemos hacer en dominios no acotados? ¿Hay más soluciones?.

	Después vimos la fórmula D'Alambert \eqref{eq:DALEMBERT}, que sí que nos sirve para dominios no acotados pero es difícil de interpretar en dominios acotados. Veamos un ejemplo de esta afirmación:

	\begin{example}

		\[\begin{cases}
			u_{tt} - u_{xx} = 0, x \in (0,L) t > 0 \\
			u(0,t) = u(L,t) = 0, t > 0\\
			u(x,0) = f(x) \\
			u_t(x,0) = 0
		\end{cases}\]

		Y tenemos la fórmula a la que llegamos:

		\[ u(x,t) = \frac{1}{2} \{f(x+t)+f(x-t)\}  \]

		Resulta que tenemos una fórmula muy útil pero ocurre que en un dominio acotado no podemos calcular $f$ cerca del borde al realizar $x+t$ o $x-t$. Tenemos que encontrar una manera de extender $f$ de manera que esté de acuerdo con el contorno. No es lo mismo que una cuerda esté sujeta y la onda se refleje de una manera de vuelta en la cuerda a que no esté sujeta.

		\begin{center}
			\begin{tikzpicture}
			\draw[-] (-1,0) -- (3,0);
			\draw[-] (0,-0.5) -- (0,2);


			\draw[dashed] (1.5,0) node [below] {$L$} -- (1.5,1.5);

			\draw[thick, blue] plot[smooth, tension=.9] coordinates{(0.7,0) (0.8,0.2) (1,0.4) (1.2,0.7) (1.5,0.9)};

			\end{tikzpicture}
		\end{center}

	\end{example}

	\subsection{Unicidad y conservación de la energía}

		Uno de los problemas más habituales al tratar las ecuaciones en derivadas parciales es saber si las soluciones son únicas o no. Partimos de nuestro problema
		\[ \begin{cases}
			u_{tt}-u_{xx} = 0\qquad x \in (0,L), t >0 \\
			u(x,0) = f(x) 	\\
			u_t(x,0) = g(x) \\
			\text{Datos de contorno Dirichlet, Neumann o periódicos}
		\end{cases} \]

		Supongamos que existen dos soluciones $u_1, u_{2}$. Entonces, tendremos que $u = u_1 - u_2$ será solución del sistema
		\( \begin{cases}
			u_{tt}-u_{xx} = 0\qquad x \in (0,L), t >0 \\
			u(x,0) = 0 	\\
			u_t(x,0) = 0 \\
			\text{Datos de contorno}
		\end{cases} \label{eq:Onda:ProblemaUnicidad} \)

		Para comprobar la unicidad, querremos saber si $u \equiv 0$ ($u_1$ y $u_2$ son iguales y la solución es única) o no.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{EnergiaOnda}
		\caption{Una ilustración de las fuerzas que dependen de la velocidad ($\vf_c$) y de la posición ($\vf_p$) que llevan a la definición de energía cinética y potencial.}
		\label{fig:EnergiaOnda}
		\end{figure}

		Para ello, vamos a introducir la ``energía'' de la onda y vamos a ver si nos da algo interesante. En cada punto $x ∈ [0,L]$ vamos a tener dos ``fuentes'' de energía. Una dependerá de la velocidad que lleve un punto, que será la cinética. Mirando a la ecuación de onda, esa velocidad no es más que la derivada de la onda $u$ con respecto al tiempo: si en $t_0 + Δt$ la onda ha crecido entonces llevamos velocidad positiva.

		La otra fuente de energía será la potencial, que depende de la altura $u$ del punto que consideremos. Si nos fijamos de nuevo en la \fref{fig:EnergiaOnda}, de lo que depende es de la derivada con respecto a $x$ por razones que ahora mismo no tengo claras. En cualquier caso, haciendo un ejercicio de imaginación la expresión de la energía será entonces la suma de ambas a lo largo de toda la cuerda:
		\( E(t) = \frac{1}{2} \int_0^L (u_t)^2 + (u_x)^2 \dif x \label{eq:Onda:Energia} \)

		Podemos derivar esta ecuación con respecto al tiempo, ya que $u ∈ C^2$, y entonces tenemos que  \( E'(t) = \int_{0}^L u_t u_{tt} + u_x u_{xt} \dif x \label{eq:Onda:DerivadaEnergia} \)

		¿Cuánto vale esta derivada? Vamos a verlo calculando la integral de $u_x u_{xt}$:
		\begin{multline}
		\int_0^L \underbracket{u_x}_u \underbracket{u_{xt} \dif x}_{\dif v} = \eval[2]{u_x u_t}_{x= 0}^L - \int_0^L u_{xx} u_t \dif x = \\
		= u_x(L,t) u_t(L, t) - u_x(0,t) u_t(0,t) - \int_0^L u_t u_{xx} \dif x \label{eq:Onda:ContornosIntegral}
		\end{multline}

		Como se puede ver, aquí entran en juego las condiciones de contorno. Recordamos las tres posibilidades que tenemos:

		\begin{itemize}[itemsep = 0pt]
		\item \textbf{Neumann}: $u_x(L, t) = u_x(0,t) = 0$.
		\item \textbf{Dirichlet}: $u(0,t) = u(L, t) = 0 = u_t(0,t) = u_t(L, t)$.
		\item \textbf{Periódicas}: $u(L, t) = u(0,t)$, $u_x(L, t) = u_x(0,t)$, $u_t(L, t) = u_t(0,t)$.
		\end{itemize}

		En cualquiera de los tres casos, lo que vamos a tener va a ser lo mismo: que $u_x(L,t) u_t(L, t) - u_x(0,t) u_t(0,t) = 0$. Sustituyendo eso en \eqref{eq:Onda:ContornosIntegral}, lo que nos quedará será que \[ \int_0^L u_x u_{xt} \dif x = - \int_{0}^L u_t u_{xx} \dif x \], y a su vez esto nos permite resolver la ecuación para la derivada de la energía \eqref{eq:Onda:DerivadaEnergia}:
		\[ E'(t) = \int_0^L u_t \left(u_{tt} - u_{xx} \right) \dif x = 0\]
		simplemente fijándonos en que la ecuación de onda nos dice que $u_{tt} - u_{xx} = 0$.

		Finalmente, a lo que hemos llegado no es más que al tradicional principio de \textbf{conservación de la energía}. En este caso, la energía de la onda se conserva a lo largo del tiempo para la ecuación de onda homogénea, y $E(t) = E(0)$, donde
		\[ E(0) = \frac{1}{2} \int_0^L (u_t)^2 (x,0) + (u_x)^2 (x,0) \dif x = \frac{1}{2} \int_0^L g^2(x)+(f'(x))^2 \dif x \]

		\paragraph{Consecuencias} Una vez que tenemos esto, volvemos a las condiciones iniciales \eqref{eq:Onda:ProblemaUnicidad} del problema del que $u = u_1 - u_2$ era solución, en el que los datos iniciales eran $u(x,0) = u_t(x,0)$. Esto nos dice que $E(0) = 0$, y como la energía se conserva tenemos que $E(t) = 0\;∀t ∈ ℝ^+$. Equivalentemente, $0 = \int_0^L (u_t)^2 + (u_x)^2 \dif x$, luego $u_t = u_x = 0$ así que la solución es constante. Finalmente, como el dato inicial era $u(x,0) = 0$, la solución es $u \equiv 0$, luego tenemos \textbf{unicidad}.

		 	Veamos el caso Dirichlet, pero esto es válido para todos:

		 	\[ \begin{cases}
		 		u_{tt} - u_{xx} = F(x,t)\\
		 		u(0,t) = \alpha(t), u(L,t) = \beta{t} \\
		 		u(x,0) = f(x) \\
		 		u_t(x,0) = g(x)
		 	\end{cases}\]
		 	\[u_1,u_2 \in C^2 \text{ soluciones}\]

		 	En este problema no tenemos conservación, debido a $\alpha$, $\beta$ y $F(x,t)$ pero podemos transformarlo en un problema de $W$ en donde si tengamos esta propiedad:

		 	\[\begin{cases}
		 		W = u_1 - u_2 \\
		 		W_{tt} - W_{xx} = 0 \\
		 		W(0,t) = 0 = W(L,t) \\
		 		W(x,0) = 0 \\
		 		W_t(x,0)
		 	\end{cases}\]

		 	Por conservación de la energía tenemos:

		 	\[ \int_0^L (W_t)^2 + (W_x)^2 \dif x = 0 \Rightarrow W_t = W_x = 0 \Rightarrow W \equiv \text{cte.} \eqreason[\Rightarrow]{$W|_{t=0} = 0$} W(x,t) = 0 \forall x \forall t \Rightarrow u_1 = u_2 \]

		 	Por lo que hemos obtenido unicidad de las soluciones del problema inicial. Pero aunque sepamos que la solución es única, no sabemos si existe tal solución. Volvemos al problema inicial:

		 	\[ \begin{cases}
		 		u_{tt} - u_{xx} = F(x,t)\\
		 		u(0,t) = \alpha(t), u(L,t) = \beta{t} \\
		 		u(x,0) = f(x) \\
		 		u_t(x,0) = g(x)
		 	\end{cases}\]


		 	\[ C(x,t) \text{ tq. } C(0,t) = \alpha(t), C(L,t) = \beta{t}\]

		 	Por ejemplo: $C(x,t) = \alpha(t) + \frac{x}{L} (\beta(t)-\alpha(t))$

		 	Consideramos $v(x,t) = u(x,t) - c(x,t)$ (de modo que $v(0,t) = v(L,t) = 0$)

		 	\[\begin{cases}
		 		v_{tt} - v_{xx} = u_{tt} - c_{tt} - u_{xx} + c_{xx} = F - c_{tt} + c_{xx} = \gor{F} \\
		 		v(0,t) = v(L,t) = 0 \\
		 		v(x,0) = u(x,0) - c(x,0) = f(x) - c(x,0) = \gor{f}(x) \\
		 		u_t (x,0) = … = \gor{g}(x)
		 	\end{cases}
		 	\]

		 	Reescribimos nuestro sistema inicial con $v$ y obtenemos:

		 	\[ \begin{cases}
		 		v_{tt} - v_{xx} = \gor{F}(x,t)\\
		 		v(0,t) = 0, v(L,t) = 0 \\
		 		v(x,0) = \gor{f}(x) \\
		 		v_t(x,0) = \gor{g}(x)
		 	\end{cases}\]

		 	Tomando $v = H + W$ podemos separar nuestro problema en dos:

		 	\[ \begin{cases}
		 			H(x,t) \rightarrow
		 			\begin{cases}
				 		H_{tt} - H_{xx} = 0\\
				 		H(0,t) = H(L,t) = 0 \\
				 		H(x,0) = \gor{f}(x) \\
				 		H_t(x,0) = \gor{g}(x)
			 		\end{cases}\\
			 		W(x,t) \rightarrow
			 		\begin{cases}
				 		W_{tt} - W_{xx} = \gor{F}(x,t)\\
				 		W(0,t) = 0 = W(L,t) \\
				 		W(x,0) = 0 \\
				 		W_t(x,0) = 0
				 	\end{cases}
				 \end{cases}
			\]

			El sistema de la $H$ ya lo sabemos resolver por separación de variables, Fourier...

			El problema de la $W$ lo resolvemos aplicando Duhamel (método del impulso). \fbox{Fijamos $s>0$}:

			\[\begin{cases}
				\left.
				\begin{array}{l}
					\Phi_{tt} - \Phi_{xx} = 0 \\
					\Phi(0,t) = \Phi(L,t) = 0 \\
					\Phi(x,0) = 0 \\
				\end{array}
				\right| \text{ separación de variables, Fourier} \\
				\Phi_t(x,0) = \gor{F}(x,s)
			\end{cases}\]


			\textbf{Notación:} $ \Phi = \Phi(x,t,s) $

			Respuesta al impulso $\gor{F}(x,s)$ que actúa en $t=0$.

			\[ \Phi(x,t-s,s)\]

			Respuesta al impulso $\gor{F} (x,s)$ que actúa en $t-s = 0$ ($t=s$)

			Aplicando Duhamel:

			\[ W(x,t) = \int_0^t \Phi(x,t-s,s) ds \]

			\[ G(x,t,z) = \int_0^z \Phi(x,t-s,s) ds\]
			\[ G_t = \int_0^z \Phi_t (x,t-s,s) ds \]
			\[ G_z = \Phi(x,t-z,z) \]
			\[ W(x,t) = G(x,t,t)\]
			\[ W_t = G_t + G_z z_t = G_t(x,t,t) + G_z (x,t,t) \cdot 1\]

			\[ W_t(x,t) = \Phi(x,0,t)+ \int_0^t \Phi_t (x,t-s,s) ds\]
			\[ W_{tt} = \Phi_{s} (x,0,t) + \Phi_t(x,0,t) + \int_0^t \Phi_{tt} (x,t-s,s) ds  \]
			\[ W_{xx} = \int_0^L \phi_{xx} (x,t-s,s) ds \]
			\[ W_{tt} - W_{xx} = \Phi_{s}(x,0,t) + \Phi_t(x,0,t) + \int_0^L \phi_{tt} - \Phi_{xx} dx \]

			\[ W(0,t) = \int_0^t \underbrace{\Phi(0,t-s,s)}_{\equiv 0} ds = 0  \]
			\[ W(L,t) = \int_0^t \Phi(L,t-s,s) ds = 0 \]

			\[ W(x,0) = \int_0^0 \Phi(x,0-s,s) ds = 0 \]
			\[ W_t (x,0) = 0\]

			Nos hemos dejado el lado derecho de la ecuación, que es:

			\[\Phi_s (x,0,t) + \underbrace{\Phi_t(x,0,t)}_{\gor{F}(x,t)} \]

			Finalmente:

			\[ \Phi(x,0,s) = 0, \forall s \Rightarrow \Phi_s (x,0,s) = 0 \forall s  \]
			\[ \Phi_t(x,0,s) = \gor{F}(x,s), \forall s \]

			Hemos descompuesto el problema en cuatro problemas más pequeños. Y hemos resuelto cada uno, completándolo con este último. La suma de ellos será una solución del primero, y además sabemos que es única por el resultado obtenido antes.

			Ahora veamos que pasa con otras condiciones de contorno:

			\[ \begin{cases}
		 		u_{tt} - u_{xx} = F(x,t)\\
		 		u(0,t) = \alpha(t), u(L,t) = \beta(t) \\
		 		u(x,0) = f(x) \\
		 		u_t(x,0) = g(x)
		 	\end{cases}\]

		 	Lo cual cambiamos al problema:

		 	\[ \begin{cases}
		 		v_{tt} - v_{xx} = F(x,t)\\
		 		v(0,t) = \alpha(t), v(L,t) = \beta(t) \\
		 		v(x,0) = \gor{f}(x) \\
		 		v_t(x,0) = \gor{g}(x)
		 	\end{cases}\]

		 	Y llegamos igual que antes hasta el problema de $W$ ($W = u-v$):

		 	\[ \begin{cases}
		 		W_{tt} - W_{xx} = 0\\
		 		W(0,t) = 0 = W(L,t) \\
		 		W(x,0) = f - \gor{f} \\
		 		W_t(x,0) = g-  \gor{g}
		 	\end{cases}\]

		 	Por conservación de la energía:

		 	\[ \frac{1}{2} \int_0^L (W_t)^2 + (W_x)^2 dx = \frac{1}{2} \int_0^L (g-\gor{g})^2 + ((f-\gor{f})')^2 dx \]

		 	Hemos demostrado también dependencia continua de datos. Lo que quiere decir que datos pequeños nos llevan a energías pequeñas.

		 	Y por lo tanto acabamos diciendo que el problema de las ondas es un problema bien propuesto: tiene existencia, unicidad y dependencia contínua.


		 	% Clase gjulianm 29/3

		\subsection{Deducción de la ecuación de onda}

		\begin{figure}[hbtp]
		\centering
		\inputtikz{TensionCuerda}
		\caption{Esquema para la demostración, dejando sólo un trozo de cuerda y sustituyendo por la tensión.}
		\label{fig:TensionCuerda}
		\end{figure}

		La idea para la deducción de la ecuación de onda es la siguiente: quitar un cacho de cuerda y sustituirlo por una tensión $T(x,t)$, que representa el efecto del trozo de cuerda a la derecha del punto $x$ en el instante $t$.

		Las componentes horizontales están en equilibrio, luego tienen que anularse: \( T(x+h) \cos θ(x+h) - T(x) \cos θ(x) = 0 \label{eq:Onda:EquilibrioHorizontal} \)

		Las componentes verticales tienen que seguir la Ley de Newton: \( T(x + h) \sin θ(x+h) - T(x) \sin θ(x) = m · u_{tt} \label{eq:Onda:LeyNewton} \), donde $m$ es la masa que se calcula a partir de la densidad ρ (constante) y de la longitud de la curva: \[ m = ρ \int_{x}^{x+h} \sqrt{1+u_x^2} \dif s\]

		Para hacer la deducción de la ecuación, dividiremos entre $h$ en \eqref{eq:Onda:LeyNewton}, y haciendo tender $h \to 0$ tenemos la derivada: \[ \left(T(x) \sin θ(x)\right)_x = ρ\sqrt{1+u_x^2(x,t)} u_{tt} \]

		Haciendo el truco de escribir $\sin θ = \cos θ · \tan θ$, tenemos que $\tan θ = u_x$ y nos queda lo siguiente:  \[ \left(T(x) \cos θ(x) u_x \right)_x = ρ\sqrt{1+u_x^2(x,t)} u_{tt} \]

		Ahora derivamos y vemos qué ocurre: \[ \left(T(x) \cos θ(x) u_x \right)_x = \left(T(x) \cos θ(x)\right)_x u_x + T(x) \cos θ(x) u_{xx} \]

		Podemos simplificar viendo que \eqref{eq:Onda:EquilibrioHorizontal} nos decía que $T(x+h) \cos θ(x+h) - T(x) \cos θ(x) = 0$, luego $(T(x) \cos θ(x))_x = 0$. Además, por no sé qué tenemos que $T(x) \cos θ(x)$ es constante. % TODO

		Sólo nos falta quitarnos la raíz esa fea. Para ello hacemos la simplificación de tener oscilaciones pequeñas, de tal forma que $u_x$ es pequeño, $u_x^2$ es todavía más pequeño y $1 + u_x^2 \approx 1$. Así, nos queda la ecuación que ya conocemos: \[ u_{tt} - c^2 u_{xx} = 0\]

		\subsection{Ecuación de ondas en $ℝ$}

		Partimos de nuestra ecuación homogénea: \[ \begin{cases}
		u_{tt} - c^2 u_{xx} = 0 \\
		u(x,0) = f(x) \\
		u_t(x, 0) = g(x)
		\end{cases}\]

		La cuestión es que aquí no podemos aplicar las series de Fourier, porque no tenemos una longitud acotada: estamos estudiando la ecuación en todo $ℝ$. Lo que haremos será ver si aplicando la Fórmula de D'Alembert nos sale algo. Para eso, hacemos el siguiente cambio de variables: \begin{align*}
		ξ &= x + ct & ξ_x = 1,\,& ξ_t = c \\
		η &= x - ct & η_x = 1,\,& η_t = - c \\
		\end{align*}

		Haciendo las cuentas tenemos lo siguiente: \begin{align*}
		u_x &= u_ξ + u_η \\
		u_{xx} &= u_{ξξ} + 2 u_{ηξ} + u_{ηη} \\
		u_t &= c u_ξ - c u_η \\
		u_{tt} &= c^2 u_{ξξ} + 2c^2 u_{ηξ} + c^2 u_{ηη}
		\end{align*}

		La conclusión de todo esto es que la ecuación nos queda así: \[ 0 = u_{tt} - c^2 u_{xx} = -4c^2 u_{ηξ} \], de tal forma que la ecuación final nos queda muy simple: \[ u_{ηξ} = 0\]

		De ahí podemos sacar fácilmente que $u_η = α(η)$, una función que sólo depende de $η$. Por tanto, podemos sacar la fórmula para $u$: \[ u = \int α(η) \dif η + B(ξ) = A(η) + B(ξ) = A(x-ct) + B(x+ct)\]

		Si $u(x,0) = f(x)$, entonces $f(x) = A(x) + B(x)$, y si $u_t(x,0) = g(x)$ entonces $g(x) = -cA'(x) + cB'(x)$. El sistema resultante es el siguiente: \[ \begin{cases}
		A' + B' = f \\
		-A' + B' = \dfrac{1}{c} g
		\end{cases} \]

		Resolviéndolo, llegaremos de nuevo a la fórmula de D'Alembert: \( u(x,t) = \frac{1}{2} \left(f(x + ct) + f(x-ct)\right) + \frac{1}{2c} \int_{x-ct}^{x+ct} g(s) \dif s \label{eq:Onda:DAlembert} \)

		A partir de aquí podemos encontrar algunas consecuencias y estudiar la función de onda. Lo primero es ver que la única solución del problema en todo $ℝ$ viene dada por esta fórmula: no hemos introducido ni quitado nuevas soluciones.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{ReprGraficaEcOnda}
		\caption{Representación gráfica y dominio de dependencia de la solución y de influencia de los datos.}
		\label{fig:ReprGraficaEcOnda}
		\end{figure}

		Lo siguiente es estudiar lo que se ve en la \fref{fig:ReprGraficaEcOnda}. $u(x,t)$ sólo dependerá de los valores de $f$ en los puntos $a,b$ y del valor de $g$ en el intervalo $(a,b)$. La zona sombreada en la figura será el dominio de influencia del intervalo $[a,b]$: es sólo ahí donde influyen los datos de $f,g$ de esos puntos. Por ejemplo, si en $t = 0$ $f = g \equiv 0$ fuera de $[a,b]$, entonces en $t = T$ la solución será cero fuera de $[a - cT, b + cT]$. En otras palabras, hay una velocidad de propagación finita de los datos.

		La aplicación de esto es la demostración de la conservación de la energía. Partíamos de una ecuación \[ E(t) = \frac{1}{2} \int_{-∞}^∞ u_x^2 \dif x + \frac{c^2}{2} \int_{-∞}^∞ u_t^2 \dif x\], y derivando y haciendo cuentas nos salía que \[ E'(t) = \int_{-∞}^∞ u_t(u_{tt} - c^2 u_{xx}) \dif x = 0\], luego la energía se conservaba.

		Ahora bien, cuando hacíamos eso en dominios acotados, lo que necesitamos era la hipótesis de los valores de contorno para poder demostrar que salía lo que tenía que salir. Aquí lo que necesitaremos simplemente es que $f(x)$ y $g(x)$ sean funciones de soporte compacto (son $0$ fuera de un intervalo $[-M, M]$), de tal forma que para tiempos finitos se cumple que en el instante $t$, $u(x,t)$ es $0$ fuera del intervalo $[-M - ct, M + ct]$ y por tanto los términos de borde en la integración por partes para sacar $E'(t)$ se anulan.

		Como nota, no podríamos pedir sólo que $u_x$ y $u_t$ fuesen integrables $L^2$, más que nada porque eso no implica que se vayan a $0$ en $∞$.

		La conservación de la energía nos dará unicidad de solución, también para el problema no homogéneo; y dependencia continua de los datos. Estos resultados habría que compararlos con el teorema en dominios acotados, que es donde lo demostramos en su día.

		\subsubsection{Aplicación a ecuaciones en dominios acotados}

		Todo esto que hemos hecho para dominios no acotados se aplicar de vuelta a dominios acotados y problemas con reflexiones. Tenemos una cuerda en el intervalo $[0, ∞)$ y nuestro sistema \[ \begin{cases}
		u_{tt} - c^2u_{xx} = 0 & x > 0,\, t ∈ ℝ \\
		u(0,t) = 0 & ∀ t ∈ ℝ \\
		u(x,0) = f(x) & x > 0 \\
		u_t(x,0) = g(x) & x > 0
		\end{cases}\]

		El primer método implicará una extensión de los datos a funciones $\tilde{f}, \tilde{g}$ a las que ya veremos qué valor dar cuando $x ≤ 0$, y sacaremos una solución $\tilde{u}$ por la fórmula de D'Alembert \eqref{eq:Onda:DAlembert}. En particular, querremos que $\tilde{u}(0,t) = 0\,∀t ∈ ℝ$. Sustituyendo en la fórmula, \[ 0 = \tilde{u}(0,t) = \frac{1}{2} \left(f(ct) + f(ct)\right) + \frac{1}{2c} \int_{-ct}^{ct} g(s) \dif s \]

		Para que eso sea 0, necesitamos que $\tilde{f}$ y $\tilde{g}$ sean impares. Así, nuestras extensiones serán \[
		\tilde{f}(x) = \begin{cases}
		f(x) & x > 0 \\
		-f(-x) & x ≤ 0
		\end{cases} \qquad
		\tilde{g}(x) = \begin{cases}
		g(x) & x > 0 \\
		-g(-x) & x ≤ 0
		\end{cases}
		\]

		De ahí sacaríamos la solución $\tilde{u}(x,t)$ y nuestra solución final sería $u(x,t) = \tilde{u}(x,t)$ restringida a $x > 0$.

		Sin embargo, tenemos un segundo método de resolución a través de una interpretación geométrica: gracias al método del paralelogramo podremos sacar el valor de la solución despejando (ver \fref{fig:AplicacionParalelogramo}), sabiendo que \( u(A) + u(C) = u(B) + u(D) \label{eq:Onda:Paralelogramo} \)

		\begin{figure}[hbtp]
		\inputtikz{AplicacionParalelogramo}
		\caption{Para poder obtener los valores cuando sólo sabemos parte de la solución (en este caso, el sombreado azul), podemos usar la regla del paralelogramo, colocando tres puntos en zonas donde sabemos el valor de la solución (uno en el dato inicial, otros dos en la solución calculada) y despejamos para el cuarto punto (en rojo).}
		\label{fig:AplicacionParalelogramo}
		\end{figure}

		Vamos a ver un ejemplo de este método, con la ecuación de siempre y datos iniciales $g \equiv 0$ y \[ f(x) = \begin{cases} 1 & x ∈ [1,2] \\ 0 & x ∈ [0,1) ∪ (2,∞) \end{cases} \]

		Sacando con la regla del paralelogramo los valores tendríamos algo como lo de la \fref{fig:OndaReflexion}, donde la onda rebotaría por la izquierda pero invertida. Además, en la zona donde la onda se anula, la energía se quedaría en la derivada $u_t$, no se nos pierde.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{OndaReflexion}
		\caption{Propagación de la onda con un borde en la izquierda. En las zonas sin sombreado, la onda tiene amplitud nula.}
		\label{fig:OndaReflexion}
		\end{figure}


		Como ejercicios, habría que ver qué ocurre con las ondas en tiempos $t = 2, \frac{3}{4}, \frac{1}{3}$ con $c = 1$. También es interesante ver qué es lo que ocurre cuando $f \equiv 0$ y $g = \ind_{[1,2]}$: el dibujo cambiará de forma esencial.

		El último ejercicio sería ver qué ocurriría con dos bordes. Veríamos los rebotes y las zonas donde las dos ondas que se propagan se juntan.

		\subsection{Caso no homogéneo}
		\label{sec:Onda:NoHomogeneo}

		Nos vata saber qué es lo que ocurre cuando tenemos una fuerza externa, es decir, cuando nuestro sistema es \[ \begin{cases}
		u_{tt} - c^2 u_{xx} = F(x,t) & t ∈ ℝ, \, x ∈ ℝ \\
		u(x,0) = f(x) \\
		u_t(x,0) = g(x) \end{cases}\]

		Recuperando lo que habíamos visto en casos anteriores, lo que haremos será separar en dos sistemas \[ \begin{cases}
		v_{tt} - c^2 v_{xx} =0  & t ∈ ℝ, \, x ∈ ℝ \\
		v(x,0) = f(x) \\
		v_t(x,0) = g(x) \end{cases} \qquad \begin{cases}
		w_{tt} - c^2 w_{xx} = F(x,t) & t ∈ ℝ, \, x ∈ ℝ \\
		w(x,0) = 0 \\
		w_t(x,0) = 0) \end{cases}\]

		Resolviendo ambos sistemas, la solución final será la suma de soluciones. Para el primero usaríamos la fórmula de D'Alembert, y para el segundo usaríamos el método de Duhamel. Fijamos $t = τ > 0$, y entonces resolvemos el problema \[ \begin{cases}
		Φ_{tt} - c^2 Φ_{xx} = 0 \\
		Φ(x,0) = 0 \\
		Φ_t(x,0) = F(x,τ) \end{cases}\]

		\begin{wrapfigure}{R}[0.1\textwidth]{0.4\textwidth}
		\centering
		\inputtikz{IntegralOndaNoseque}
		\caption{La integral que hacemos es la del triángulo, con $f$ aportando en los puntos iniciales (verde), $g$ aportando en el intervalo naranja y $F$ en la zona sombreada.}
		\label{fig:Onda:Noseque}
		\end{wrapfigure}

		Así, el impulso $F(x,τ)$ en $t= 0$ sale como \[ Φ(x,t) = \frac{1}{2c} \int_{x-ct}^{x+ct} F(s,τ) \dif τ\], y para $t = τ$ tendríamos \[ Φ(x, t-τ) = \frac{1}{2c} \int_{x-c(t-τ)}^{x + c(t - τ)} F(s, τ) \dif s\]

		De esta forma, la solución para un punto dado es el impulso a lo largo del tiempo, esto es, \[ w(x,t) = \frac{1}{2c} \int_0^t Φ(x,t-τ) \dif τ = \frac{1}{2c} \int_0^t \int_{x-c(t-τ)}^{x + c(t - τ)} F(s, τ) \dif s \]

		Esta integral es en el fondo lo mismo que integrar en el triángulo de la \fref{fig:Onda:Noseque} con las aportaciones que se comentan. Además, la conservación de la energía nos daría la unicidad de la solución para este problema.

		Y ahora, dentro del mundo de cosas que no sé qué son (creo que un ejercicio, llevo mucho tiempo copiando), hay un ejercicio en el que una condición adicional es que $u_x(0,t) = 0$. Habría que hacer las extensiones, calculando $\tilde{u}$ y derivando para sacar las condiciones sobre las extensiones. Ahora bien, también se puede pasar a una condición de contorno tipo Dirichlet buscando la solución $v = u_x$, que nos quedaría el sistema de otra ecuación de onda \[ \begin{cases} v_{tt} - c^2v_{xx} = 0 \\ v(0,t) = 0 \\ v(x,0) = f'(x) \\ v_t(x,0) = g'(x) \end{cases}\] con condiciones de contorno tipo Dirichlet, que podemos resolver por la identidad del paralelogramo de antes.

		BOOOOOM.

		\subsection{Energía}

			Vamos a repasar dos de los problemas de la hoja 3:

			\begin{problem}

				\[\begin{cases}
					u_{tt} - c^2u_{xx} + u_t = 0, \quad x \in (a,b)\\
					u(a,t) = u_x (b,t) = 0\\
					u(x,0) = f(x) \\
					u_t(x,0) = g(x)
				\end{cases}\]

				¿Tenemos unicidad?

				\solution

				Suponemos $u_1,u_2$ soluciones:

				\[ \begin{cases} W = u_1 - u2 \\
				W_{tt} - c^2 W_{xx} + W_t = 0 \\
				W(a,t) = W_x (b,t) = 0\\
				W(x,0) = 0\\
				W_t (x,0) = 0
				\end{cases}\]

				Método de la energía:
				\[ 0 = (W_{tt} - c^2 W_{xx} + W_t) W_t dx\]

				Si integramos seguimos teniendo 0:

				\[ 0 = \int_a^b (W_{tt} - c^2 W_{xx} + W_t) W_t dx\]
				\[ = \int_a^b W_{tt} W_t dx - c^2 \int^b_a W_{xx} W_t dx + \int_{a}^b W^2_t dx  \]

				Tenemos que $W_{tt}W_t \equiv (\frac{1}{2} (W_t)^2)_t $. Además, integrando por partes:

				\[ \int_a^b \underbrace{W_{xx}}_{dv} \underbrace{W_t}_{u} dx = W_x W_t |_a^b - \int_a^b \underbrace{W_x W_{tx}}_{(\frac{W_x^2}{2})_t} dx \]
				Observamos que
				\begin{itemize}
					\item $W_x (b,t) = 0$, $\forall t $
					\item $W(a,t) = 0$, $\forall t \implies W_t (a,t) = 0$
				\end{itemize}
				Luego $W_x W_t |_a^b = 0$

				{\bf Conclusión:}
				\[ E'(t) + \int_a^b W_t^2 dx = 0 \rightarrow \text{ la energía {\bf no} se conserva}\]
				\[ E'(t) = -\int_a^b W_t^2 dx \leq 0 \]

				\[ \left. \begin{array}{r}
					E \text{ decrece} \\
					E \geq 0 \\
					E(0) \eqreason{en w} 0 \end{array} \right\} \Rightarrow E \equiv 0 \Rightarrow W \equiv 0 \Rightarrow u_1 \equiv u_2 \]

			\end{problem}

			\begin{problem}

				\[\begin{cases}
					u_{tt} - c^2 u_{xx} + hu = F(x,t), \quad x \in \real \\
					u, u_x, u_t \convs[ ][x][±\infty] 0, \forall t\\
					\int_{-\infty}^\infty u_t^2 + c^2 u_x^2 + hu^2 dx < \infty \quad (\forall t) \\
					u(x,0) = f(x) \\
					u_t(x,0) = g(x)
				\end{cases}\]

				¿Hay unicidad?

				\solution

				Suponiendo $u_1,u_2$ soluciones:

				\[\begin{cases}
					W = u_1 - u_2 \\
					W_{tt} - c^2 W_{xx} + h W = 0\\
					W(x,0) = 0\\
					W_t(x,0)=0
				\end{cases}\]

				Energía:
				\[ 0 = \int_{-\infty}^\infty (w_{tt} - c^2 W_{xx} + h W)W_t dx = … \]

				Integrando por partes en $\int\limits_{-\infty}^\infty W_{xx} W_{t}$, los términos de borde se anulan como en el caso anterior:

				\[ … = \int_{-\infty}^{\infty}  (\frac{W_t^2}{2})_t dx + c^2 \int_{-\infty}^\infty (\frac{W_x^2}{2})_t dx + h \int_{-\infty}^\infty (\frac{W^2}{2})_t dx \]

				Con lo que llegamos (usando $hWW_t = h (\frac{W^2}{2})_t$):

				\[ 0 = (\int_{-\infty}^\infty  \frac{W_t^2}{2} + c^2 \frac{W_x^2}{2} + h \frac{W^2}{2} dx)_t\]

				Integrando obtenemos
				\[ E(t) = \int_{-\infty}^{\infty} \frac{W_t^2}{2} + c^2 \frac{W_x^2}{2} + h \frac{W^2}{2} dx = cte \quad \forall t \]

				Utilizando que la energía inicial es finita, y observando que $E(0) = 0$, podemos deducir que $W \equiv 0$, y por tanto, tenemos unicidad de la solución.

			\end{problem}


			Entremos un poco más en detalle con la energía y sus reflexiones en base a lo descrito anteriormente. Tomemos:

			\[\begin{cases}
				u_{tt} - u_{xx} = 0, x > 0 \\
				u(0,t) = 0 \quad \forall t \\
				u(x,0) = f(x) \\
				u_t(x,0) = 0
			\end{cases}\]

			(FALTA TERMINAR EL DIBUJO)

			\begin{center}
			\begin{tikzpicture}
				\draw[->] (-2.1, 0) -- (4.2,0) node[right] {$x$};
				\draw[->] (0, -0.1) -- (0,3.2) node[above] {$t$};

				\node[vnlin, label = {below:$1$}] at (1,0) {};
				\node[vnlin, label = {below:$2$}] at (2,0) {};
				\node[vnlin, label = {below:$-1$}] at (-1,0) {};
				\node[vnlin, label = {below:$-2$}] at (-2,0) {};

				\draw[gray] (1,0) -- (4,3) ;
				\draw[gray] (2,0) -- (4,2) ;
				\draw[gray] (2,0) -- (0,2) -- (1,3);
				\draw[gray] (1,0) -- (0,1) -- (2,3);
				\draw[gray] (-1,0) -- (0,1);
				\draw[gray] (-2,0) -- (0,2);
				\draw[gray,dashed] (-2,0) -- (-3,1);
				\draw[gray,dashed] (-1,0) -- (-2,1);

				\fill[pattern = north east lines, pattern color = red] (1, -0.05) rectangle (2, 0.05);
				\fill[pattern = north east lines, pattern color = blue] (-2, -0.05) rectangle (-1, 0.05);
			\end{tikzpicture}
			\end{center}

			\[ u_x = \frac{1}{2} f'(x+t) (x+t)_x + \frac{1}{2} \gor{f}'(x-t)(x-t)_x = \frac{1}{2} \{f' + \gor{f}'\} \eqreason{$t = \frac{3}{2}$} 0 \]

			Lo que hemos perdido en energía potencial, lo hemos ganado en cinética.

			\[ u_t = \frac{1}{2} f'(x+t) (x+t)_t + \frac{1}{2} \gor{f}' (x-t)(x-t)_t = \frac{1}{2} \{ f'(x+t) - \underbrace{\gor{f} (x-t)}_{=-f} \} \eqreason{$t = \frac{3}{2}$} f'  \]

			% No he copiado la explicación especial que dió sobre funciones no derivables TODO

			\obs Esta definición que viene ahora no entra y viene acompañada de un ejemplo que no se ha incluido aquí.

			\begin{defn}[Derivada débil]

				G es la derivada débil de $F$ si y solo si:

				\[ \int_{-\infty}^\infty G\Phi dx = -\int_{-\infty}^\infty F \Phi' dx, \ \forall \Phi \in C^1, \ \Phi \text{ con soporte compacto} \]

				\begin{itemize}
					\item $F$ derivable (clásico) $\Rightarrow F'$ es su derivada débil.
					\item A veces la derivada débil existe aunque $F$ no sea derivable en el sentido clásico.

				\end{itemize}
			\end{defn}

			Vamos entonces a ver que diferencias habría (en el caso de una cuerda de guitarra), entre darle un golpe a la cuerda y tocarla:

			\[\begin{cases}
				u_{tt} -u_{xx} =0, \quad x \in \real \\
				u(x,0) = f \\
				u_t(x,0) = g
			\end{cases}\]

			Aplicamos la fórmula de D'Alembert: \index{Fórmula de D'Alembert}
			\[ u(x,t) = \frac{1}{2} \{ f(x+t) + f(x-t) \} + \frac{1}{2} \int_{x-t}^{x+t} g(s) \ ds \]

			Contemplamos varios casos:

			\begin{itemize}
				\item $f \neq 0, g = 0$
					(DIBUJO)

				\item $f=0, g \neq 0$
					(DIBUJO)

			\end{itemize}


	% Clase 5-4-2016

	\section{Laplaciano}

	Si nos fijamos en la ecuación del calor, para dimensión espacial $N$ nos queda que \[ u_t - (u_{x_1x_1} + u_{x_2x_2} + \dotsb + u_{x_N x_N})\]

	Para la ecuación de ondas, tenemos algo parecido:  \[ u_{tt} - (u_{x_1x_1} + u_{x_2x_2} + \dotsb + u_{x_N x_N})\]

	Ese último paréntesis es una operación en si misma, que llamaremos el \concept{Laplaciano}: \( Δu = \sum_{i=1}^N u_{x_i x_i} = \tr (\Dif^2 u) = \dv (\grad u) \label{eq:Laplaciano}\)

	Es especialmente interesante verlo como la divergencia del gradiente, para después poder aplicar en un futuro el teorema de Gauss para poder integrar.

	Una forma de ver la ecuación de ondas o del calor es como soluciones estacionarias de algo. Por ejemplo, si nos fijamos en el típico experimento de hacer vibrar una membrana con el sonido, estaríamos ante una ecuación \[ \begin{cases} u_{tt} - u_{xx} - u_{yy} \\ \restr{u}{∂Q} = 0 \\ u(x,0) = f(x) \\ u_t(x,0) = g(x) \end{cases} \] con $Q = (0,1) × (0,1)$.

	Podríamos aplicar entonces el método de separación de variables, buscando dos funciones cuyo producto sea la solución: \[ u(x,y,t) = Φ(x,y) T(t) \] de tal forma que las soluciones serían de la forma \[ \frac{T''}{T} = \frac{ΔΦ}{Φ} = λ \]

	La resolución en $Φ$ nos daría un problema de autovalores: \[ \begin{cases} ΔΦ = λ Φ \\ \restr{Φ}{∂Q} = 0 \end{cases} \], lo cual es un problema de autovalores. El resultado sería una sucesión de autovalores $λ_k$ y autofunciones $Φ_k$.

	Volviendo al caso de la membrana, si ponemos arena en la membrana se quedará con una forma, más concretamente en los nodos de la membrana: los puntos en los que no vibra.

	Nosotros no veremos el problema de resolver el laplaciano para dominios arbitrarios porque necesitamos mucho análisis funcional y en este curso no da tiempo. Nos vamos a centrar en dominios acotados, y vamos a desarrollar varias herramientas que nos permitan inferir cosas sobre la solución a partir de la ecuación.

	\subsection{Funciones armónicas, subarmónicas y superarmónicas}

	Podemos clasificar las soluciones en tres clases posibles según el signo del laplaciano.

	\begin{defn}[Función\IS armónica] Si $-Δu = 0$ en Ω, entonces $u$ es armónica en $Ω$. \end{defn}
	\begin{defn}[Función\IS subarmónica] Si $-Δu ≤ 0$ en Ω, entonces $u$ es subarmónica en $Ω$. \end{defn}

	\begin{defn}[Función\IS superarmónica] Si $-Δu ≥ 0$ en Ω, entonces $u$ es superarmónica en $Ω$. \end{defn}

	En dimensión $1$, las funciones armónicas son lineales, las subarmónicas convexas y las superarmónicas convexas.

	En dimensiones superiores, las cosas se complican un poco más. Por ejemplo, una función lineal sigue siendo armónica, pero $u(x,y) = x^2 - y^2$ también es armónica.

	Un ejemplo de función subarmónica es un paraboloide en dimensión $N$: \[ u(x_1, \dotsc, x_N) = \norm{\vx}^2 = x_1^2 + \dotsb + x_N^2 \] es subarmónica ya que $-Δu = -2N$.

	En dimensión $2$, la función \[ F(x,y) = \log (x^2 + y^2)\] tiene laplaciano $-ΔF = 0$ en $ℝ^2 \setminus \set{(0,0)}$, por lo que es armónica.

	En dimensión $N > 2$, la función \[ G(\vx) = \frac{1}{\norm{\vx}^{N-2}}\] también es armónica: $-ΔG = 0$ en $ℝ^N \setminus \set{\vec{0}}$.

	Estos dos ejemplos son llamadas \concept{Soluciones\IS fundamentales}, y ya veremos más tarde por qué se llaman así.

	Las funciones armónicas tienen unas propiedades básicas.

	\begin{prop} \label{prop:PropsFuncArmonicas} Sean $u,v$ funciones armónicas en $Ω$.
	\begin{enumerate}[itemsep = 0pt]
	\item La suma $u +v$ es armónica.
	\item El producto $uv$ en general no es armónico.
	\item La traslación $u(x-x_0)$ es armónica en $\set{x \tq x - x_0 ∈ Ω}$.
	\item El escalado $u(kx)$ es armónica en $\set{x \tq kx ∈ Ω}$.
	\item Dada una transformación lineal $\appl{A}{ℝ^N}{ℝ^N}$ con $\norm{Ax} = \norm{x}\;∀xx ∈ ℝ^N$ (isometría), entonces $u(Ax)$ es armónica en $\set{x \tq Ax ∈ Ω}$.
	\item \concept{Transformada\IS de Kelvin} La función \[ K(\vx) = \frac{1}{\norm{\vx}^{N-2}} u\left(\frac{\vx}{\norm{\vx}^2}\right) \] es armónica en $\set{ \vx \tq \frac{\vx}{\norm{\vx}^2} ∈ Ω}$.
	\end{enumerate}
	\end{prop}

	La transformada de Kelvin es especialmente importante, ya que lleva de puntos de dentro de una bola a puntos fuera, y permite estudiar lo que pasa en el centro de la bola (en el $0$) viendo lo que ocurre en el infinito. La cuenta es un poco infernal, y nosotros lo haremos sólo en un caso.

	\begin{proof}[Transformada de Kelvin - $u$ radial]
	Suponemos que $u$ es radial, esto es, que $u$ sólo depende de la norma del vector $\vx$. Diremos entonces que $u \equiv u(r)$ con $r = \norm{\vx}$.

	Vamos a estudiar la ``armonicidad'' de la función. Primero calculamos la derivada $r_i$: \begin{align*}
	r^2 &= x_1^2 + \dotsb + x_N^2 \\
	2rr_{x_i} &= 2x_i \\
	r_{x_i} &= \frac{x_i}{r}
	\end{align*}

	Con esto ya podemos calcular la segunda derivada de $u$: \begin{align*}
	u_{x_i} &= u_{r} r_{x_i} = u_{r} \frac{x_i}{r} \\
	u_{x_ix_i} &= \dotsb = \left(\frac{ur}{r}\right)_r \frac{x_i^2}{r} + \frac{u_r}{r}
	\end{align*}

	Así, el laplaciano queda que es igual a \[ Δu = \sum_{i=1}^N = \left(\frac{ur}{r}\right)_r · r + N\frac{u_r}{r} = \dotsb = u_{rr} + \frac{N-1}{r} u_r \]

	El ejercicio a cargo del lector consistiría en ver que dada la transformada de Kelvin \[ H(r) = \frac{1}{r^{N-2}} u\left(\frac{1}{r}\right)\] entonces \[ H_{rr} + \frac{N-1}{r} H_r = 0\]

	\end{proof}

	¿Cómo se escribiría la transformada de Laplace si dependiese también del ángulo? En ese caso, cada punto $\vx ∈ ℝ^N$ se escribiría como $\vx = r · ω$, con $r ∈ [0, ∞)$ y $ω ∈ \crc[N-1]$, de tal forma que el laplaciano sería \[ Δu(\vx) = u_{rr} + \frac{N-1}{r} u_r + \frac{1}{r^2} Δ_{\crc[N-1]} u \] , donde $Δ_{\crc[N-1]}$ sería el \concept{Operador\IS de Laplace-Beltrami} que es la restricción del laplaciano a la esfera. Esta sería la conexión de esto con la geometría y no vamos a ver nada más de esto.

	\subsection{Propiedades fundamentales: Principios del máximo y de la media}

	El principio del máximo nos dice lo siguiente: si tenemos una cuerda en equilibrio (una función armónica), no tenemos ni máximos ni mínimos fuera de la frontera. Si, por ejemplo, tenemos ondas en una membrana, entonces no está en equilibrio: está vibrando.

	Podemos mirarlo desde otro lado, tomando una función superarmónica con $-Δu = F ≥ 0$. Es decir, que hay un equilibrio en presencia de una fuerza externa $F$. Esta fuerza será positiva si actúa hacia arriba, y negativa si lo hace hacia abajo. El principio del máximo nos dirá que, respectivamente, sólo será posible una onda hacia arriba $u > 0$ o hacia abajo $u < 0$. (dibujo aquí.)

	\begin{prop}[Principio\IS del máximo débil] \label{prop:PrincipioMaximoDebil} Sea $Ω$ un dominio\footnote{Conjunto abierto y conexo} acotado en $ℝ^N$, y sea $u$ una función subarmónica en Ω y $u ∈ C^2(Ω) ∩ C(\adh{Ω})$. Entonces el máximo en el cierre es igual al máximo en la frontera: \[ \max_{\adh{Ω}} u = \max_{∂Ω} u \]
	\end{prop}

	El principio del máximo débil sí que nos permite casos en los que el máximo se alcanza en la frontera y también en el interior. Con artillería más fuerte veremos que estos casos, en la práctica, no son posibles; aunque para ello tendremos que esperar un poco.

	\begin{proof}

	\proofpart{$-Δu < 0$ en Ω (desigualdad estricta)}

	Haremos la demostración por reducción al absurdo: supongamos que $\max_{\adh{Ω}}$ se alcanza en $x_0 ∈ \mop{int} Ω$. En ese punto de máximo tiene que pasar dos cosas: que el gradiente se anula ($\grad u = \vec{0}$) y que el hessiano $\Dif^2 u$ tiene que ser semidefinida negativa. Esto es, los autovalores de $\Dif^2 u$ tienen que ser menores o iguales que $0$.

	En ese caso, la traza ha de ser menor o igual que cero, pero $\tr \Dif^2 u(x_0) = Δu(x_0) ≥ 0$, contradicción porque habíamos dicho que $-Δ u < 0$.

	\proofpart{$-Δu ≤ 0$ en Ω (desigualdad no estricta)}

	En este caso miraremos una función modificada $v_ε \approx u$, tal que $-Δv_ε < 0$. Tomaremos entonces \[ v_ε(\vx) = u(\vx) + ε\norm{\vx}^2\], de manera que \[ -Δv_ε (\vx) = -Δu(\vx) - ε Δ(\norm{\vx}^2) = -Δu(\vx)  - 2εN < 0 \]

	Aplicamos entonces el caso anterior a $v_ε$, y entonces hacemos tender $ε \to 0$. Esto queda como ejercicio para el lector. En el paso al límite, tendremos que aceptar la desigualdad no estricta, lo que nos da la debilidad de este principio.
	\end{proof}

	Aunque este principio lo hemos hecho sólo para funciones subarmónicas, para superarmónicas es sólo cambiar el signo. Para funciones armónicas, como son sub y super armónicas, tendremos que el mínimo y máximo se alcanzan en la frontera.

	Este principio será muy potente: nos permitirá demostrar unicidad, estimaciones, y más cosas que no he llegado a copiar.


	% Clase 6-4-2016
	\subsubsection{Aplicaciones}

	Antes de ir directamente con la prueba y desarrollo de esos principios, vamos a ver de qué nos sirven.

	\begin{example}[1 - Comparación]
		El principio del máximo nos permite comparar dos posibles soluciones si el laplaciano de una es mayor que el de otra. Partimos de una función superarmónica que es positiva en el borde:
		\[ \begin{cases}
		- Δ u ≥ 0 & \text{en } Ω \\
		\restr{u}{∂Ω} ≥ 0
		\end{cases} \implies u ≥ 0 \text{ en }\adh{Ω} \]

		Si tenemos otra solución $v$ ``menor'' que $u$ en el sentido de los datos, esto es,
		\[ \begin{cases}
		- Δ u ≥ -Δv & \text{en } Ω \\
		\restr{u}{∂Ω}  ≥ \restr{v}{∂Ω}
		\end{cases} \] podemos restar ambas soluciones y aplicar el principio del máximo para tener que
		\[ \begin{cases}
		- Δ u - (-Δv) ≥ 0 & \text{en } Ω \\
		\restr{u-v}{∂Ω} ≥ 0
		\end{cases} \implies u - v ≥ 0 \implies u ≥ v \text{ en }\adh{Ω} \]

		Es decir, que el principio del máximo implicará directamente un \concept{Principio\IS de comparación débil}. Más tarde veremos un principio de comparación fuerte para desigualdades estrictas.
	\end{example}

	\begin{example}[2 - Unicidad]

		Con condiciones de Dirichlet, el principio del máximo nos dará unicidad de la solución. Partimos del problema
		\[ \begin{cases}
			-\Delta u = F & \text{ en } \Omega \\
			u|_{∂ \Omega} = g  & \text{ Dirichlet}
			\end{cases}
		\]

		Si tenemos $u_1, u_2$ solucione, tenemos que su resta resuelve el problema
		\[ \begin{cases}
			-\Delta u = 0 & \text{ en } \Omega \\
			u|_{∂ \Omega} = 0 & \text{ Dirichlet}
			\end{cases}
		\] y el principio del máximo nos dice que $u_1 - u_2 = 0$, esto es, que la solución es única. Más tarde veremos qué que pasa con condiciones Neumann, condiciones de la forma
		\[ \begin{cases}
		-\Delta u = F \\
		\left. \dpd{u}{m}\right|_{∂ \Omega} = g
		\end{cases} \]

	\end{example}

	\begin{example}[3 - Estimación a priori]
		El principio del máximo también nos permitirá sacar unas acotaciones a priori para la solución sin tener que calcularla, sólo a partir de los datos que se nos den en un dominio acotado.

		El problema del que partimos es el siguiente:
		\[\begin{cases}
		-\Delta u  = F &\text{ en } \Omega ⊆ \bola_R(0)) \\
		u|_{∂ \Omega} = g
		\end{cases}\] con las siguientes cotas para $F$ y g:
		\[ m \leq F \leq M, \quad \gor{m} \leq g \leq \gor{M} \]

		Querremos aplicar el principio de comparación con una función simple para tener una cota que nos valga para $u$. Definiremos entonces la siguiente función auxiliar
		\[ \Phi(\vx) = A - B \norm{\vx}^2 \] con $A,B ∈ ℝ$ y ahora veremos cómo cuadrar esos coeficientes.

		Si sacamos el laplaciano de Φ, vemos que tenemos que tomar $B = \frac{M}{2N}$, con $N$ la dimensión del espacio, para que sea mayor que $-Δu$:
		\[ - \Delta \Phi = \dotsb = 2NB \eqreason{$\displaystyle B = \frac{M}{2N}$} M \geq F = -\Delta u \]

		Viendo además el valor en el borde, tendremos que $A = \bar{M} + \frac{M}{2N}R^2$:
		\[ \restr{\Phi(x)}{∂Ω} = A - \frac{M}{2N} \norm{\vx}^2 \eqreasonup[≥]{$\vx ∈ Ω ⊆ \bola_R(0)$} A - \frac{M}{2N} R^2 \eqreason{$A = \gor{M} + \frac{M}{2N} R^2 $} \gor{M} \geq g = u|_{∂\Omega} \]

		Así, la función que nos queda es
		\[ \Phi(\vx) = \gor{M} + \frac{M}{2N} R^2 - \frac{M}{2N} \norm{\vx}^2 \] y ahora podemos aplicar el principio de comparación. Tenemos que
		\[ \begin{cases}
		-\Delta \Phi \geq - \Delta u & \text{ en } \Omega \\
		\Phi |_{∂ \Omega} \geq u|_{∂ \Omega}
		\end{cases} \] luego $Φ ≥ u$ en $\adh{Ω}$. Finalmente, esto nos la cota que buscábamos:
		\[ u(\vx) \leq \gor{M} + \frac{M}{2N} (R^2 - \norm{\vx}^2)\qquad \forall \vx \in \Omega \]
	\end{example}

	\begin{example}[4 - Dependencia continua]
		Como último ejemplo, podemos ver que tenemos una dependencia continua de los datos, es decir, que si cambiamos un poco los datos la solución también cambia poco. Sean $u_1, u_2$ soluciones respectivas de los problemas
		\[ \begin{cases}
			-\Delta u = F_1 & \text{ en } \Omega \\
			u|_{∂ \Omega} = g_1
			\end{cases}
			\qquad
			\begin{cases}
			-\Delta u = F_2 & \text{ en } \Omega \\
			u|_{∂ \Omega} = g_2
			\end{cases}
		\] con $\norm{F_1 - F_2}_∞ = \sup \abs{F_1 - F_2} < ε$ y $\norm{g_1 - g_2}_∞ < δ$.

		Podemos aplicar ahora la estimación a priori que veíamos en el ejemplo anterior al problema con datos $F_1 - F_2$ y $g_1 - g_2$ y tenemos que $u(\vx) ≤ ε + \frac{δ}{2N}(R^2 - \norm{\vx}^2)$, que es precisamente lo que buscábamos: cambios pequeños en los datos acotan los cambios en las soluciones
	\end{example}

	\obs Si tomamos la ecuación:

	\[ \begin{cases}
		-\Delta u = 0 \text{ en } \Omega \\
		u|_{\delta \Omega} = g
	\end{cases}\]

	Hay que interpretarlo como una solución estacionaria de una ecuación del calor.

	(DIBUJOS ESPINA DE LEBESGUE)

	\subsubsection{Propiedad de la media}

		Una vez vistos ejemplos, vamos con la teoría y la demostración del principio de la media. Empezaremos con el caso fácil, en dimensión $N = 2$.

		\begin{prop}[Propiedad\IS de la media (bolas en $ℝ^2$)] \label{prop:MediaBolaR2} Sea $\bola_R(\va) ⊆ ℝ^2$ la bola de radio $R$ centrada en $\va ∈ ℝ^2$. Consideramos el problema \[
		\begin{cases}
			-\Delta u = 0 & \text{ en } \bola_R(\va) \\
			u|_{∂\bola_R(\va)} = f
		\end{cases}\]

		Entonces, se cumple la propiedad de la media: \[ u(\va) = \frac{1}{2πR} \int_{∂\bola_R(\va)} f \]

		Es decir, el valor de $u$ en el centro de la bola es igual a su valor medio en el borde.
		\end{prop}

		\begin{proof} Sabemos que la solución al problema del laplaciano en $\bola_R$ viene dado por el núcleo de Poisson \eqref{eq:NucleoPoisson}, esto es, \[ u(r, \theta) = \frac{1}{2π} \int_{0}^{2\pi} u(1,s) P_r(\theta-s) \dif{s} = \frac{1}{2\pi} \int_0^{2\pi} u(1,s) \frac{1-r^2}{1 + r^2 - 2r\cos(\theta-s)} \dif{s} \]

		Sustituyendo para $r = 0$, tenemos que \[ u(0,θ) = \frac{1}{2π} \int_0^{2π} u(1,s) \dif s = \frac{1}{2π} \int_{∂\bola_1(\vec{0})} f \]

		Ahora sólo falta tener la solución en una bola de radio $R$ centrada en $\va = (a_1, a_2)$. Para eso hacemos la parametrización \[ \sigma_R (s) = (a + R \cos s , b + R \sin s) \quad s \in [0,2\pi) \] con $\norm{σ_R'} = R$. Entonces ya podemos sustituir y ver que efectivamente sale lo que buscamos: \[ \frac{1}{2πR} \int_{∂\bola_R(\va)} f \dif σ_R = \frac{1}{2πR} \int_0^{2π} f(σ_R(s)) \norm{σ_R'} \dif s = \frac{1}{2π} \int_0^{2π} u(1, s) \dif s  = u(0, θ) = u(\va) \]
		\end{proof}

		A partir de esta propiedad de la media del valor en el borde podemos sacar que también es válido si la media la hacemos sobre todos los valores del interior.

		\begin{prop} \label{prop:MediaBolaInteriorR2} Bajo las mismas hipótesis de la \fref{prop:MediaBolaR2}, tenemos que  \[ u(\va) = \frac{1}{πR^2} \int_{\bola_R(\va)} u(x,y) \dif x \dif y  \]
		\end{prop}

		\begin{proof} Lo primero que miramos es que si $\bola_R(\va) ⊂ Ω$ con $\va = (a_1, a_2)$, entonces $∀ρ ∈ [0,R]$ tendremos igualmente que $\bola_ρ(\va) ⊂ Ω$. Con esto podemor plantear la propiedad anterior para radio ρ e integrar a ambos lados en ρ de $0$ a $R$. Para que todo sea más fácil consideramos el cambio de coordenadas correspondiente, y lo abreviamos como $x(ρ, s)$ y $y(ρ,s)$ (es un cambio típico a coordenadas polares).

		Vamos a ello:
		\begin{align*}
		ρ · u(a,b) &= \frac{1}{2π} \int_0^{2π} u(x(ρ, s), y(ρ,s)) · ρ \dif s \\
		\int_0^R ρ · u(a,b) \dif ρ &= \frac{1}{2π} \int_0^R \int_{0}^{2π} u(x(ρ, s), y(ρ, s)) ρ \dif r \dif s \\
		\frac{R^2}{2} u(a,b) &= \frac{1}{2π} \iint_{\bola_R(\va)} u(x,y) \dif x  \dif y \\
		u(a,b) &= \frac{1}{πR^2} \iint_{\bola_R(\va)} u(x,y) \dif x \dif y \\
		u(a,b) &=  \frac{1}{|\bola_R|} \iint_{\bola_R(\va)} u(x,y) \dif x \dif y
		\end{align*} que es precisamente lo que buscábamos: el valor en el centro es la media de valores en toda la bola.
		\end{proof}

		% Clase 11-4-2016

		Investiguemos un poco más que pasa en $N > 2$. Realizaremos una prueba apoyada en las identidades de Green y demás teoremas del análisis matemático. El primero será el de Gauss, que pasamos a recordar a continuación.

		\begin{theorem}[Teorema\IS de Gauss] \label{thm:Gauss} Sea $Ω ⊂ ℝ^3$ una región con borde $∂Ω$, y $\appl{\vf}{Ω}{ℝ^3}$ un campo vectorial continuo y derivable. Entonces se cumple que \[
			\iint_{∂V} \vf \dif S = \iiint_{Ω} \dv \vf \dif x \dif y \dif z
		\]
		\end{theorem}

		Recordamos también que la divervencia dado un campo $\vf = (F_1, \dotsc, F_n)$ se calcula como \[ \dv \vf = \pd{F_1}{x_1} + \dotsb + \pd{F_n}{x_n} \] y que la integral sobre una superficie con vector normal unitario $\vn$ es \[ \int_{∂V} \vf \dif S = \int_{∂V} \pesc{\vf, \vn} \dif x \dif y \dif z \]

		Este ejemplo nos interesa particularmente porque el laplaciano es la divergencia del gradiente, esto es, $Δu = \dv (\grad u)$.

		También tendremos la siguiente identidad a partir del Teorema de Gauss, que nos será útil para simplificar los cálculos.

		\begin{prop}[Identidad\IS de Green] \label{prop:IdGreen} Sean $u,v ∈ C^2(U)$ con $U ⊂ ℝ^3$. Entonces se cumple que \( \int_U v · Δu - u · Δv \dif V = \int_{∂U} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S \label{eq:IdGreen} \) donde $\pd{v}{\vn}$ no es más que una forma pija\footnote{Seguro que ha sido un físico.} de poner la derivada direccional: \[ \dpd{v}{\vn} = \pesc{\grad v, \vn} = \grad_{\vn} v\]
		\end{prop}

		Es espcialmente interesante porque nos dará una forma de ``integrar por partes'' en dimensiones superiores, ya que podemos reescribir $\int v Δu$ quitándonos el laplaciano en $u$.

		Con todas estas herramientas ya podremos probar la propiedad de la media:
		\begin{prop}[Propiedad\IS de la media] \label{prop:MediaBola} Sea $\bola_{R}(\va) ⊂ ℝ^N$ una bola $N$-dimensional de radio $R$ centrada en $\va ∈ ℝ^N$, y sea $u$ solución del problema dado por \[
		\begin{cases}
			-\Delta u(\vx) = 0 & x ∈ \bola_R(\va) \\
			u(\vx)|_{∂\bola_R(\va)} = f(\vx)
		\end{cases} \]

		Entonces, se cumple la propiedad de la media: \[ u(\va) = \frac{1}{\abs{∂\bola_R}} \int_{∂\bola_R} u(\vx) \dif σ\] donde $\abs{∂\bola_R(\va)}$ es la medida del borde de la bola (es decir, el área/volumen/loquesea de la hiperesfera de radio $R$).
		\end{prop}

		\begin{proof} Vamos a tratar de aplicar las identidades anteriores, aunque para ello necesitaremos un campo vectorial, y nosotros sólo tenemos una función escalar. Definiremos pues $\vf = v · \grad u = \left(v u_{x_1}, \dotsc, v u_{x_n}\right)$, de tal forma que la divergencia nos queda $\dv \vf = \pesc{\grad v, \grad u} + v Δ u$.

		Como idea feliz para el caso $N > 2$ (que es el que queremos demostrar, el resto ya lo tenemos) tomaremos $v$ de la siguiente forma\footnote{Si tuviésemos $N=2$ tomaríamos $\log \norm{\vx}$.}: \[ v(\vx) = \frac{1}{\norm{\vx}^{N-2}} = (x_1^2 + \dotsb + x_N^2)^{\frac{2-N}{2}}\]

		Haciendo cuentas, nos salen dos resultados interesantes para el gradiente y el laplaciano (ambos definidos sólo cuando $\vx ≠ \vec{0}$):
		\begin{align*}
		\grad v  &= (2-N) \frac{\vx}{\norm{\vx}^N} \\
		- Δ v &= 0
		\end{align*}

		Ahora trataríamos de aplicar la \nref{prop:IdGreen}, pero tenemos que tener cuidado porque ni $v$ ni su gradiente son continuas en todo $ℝ^n$. Tendremos que quitarnos el punto conflictivo, así que integraremos en $B = \bola_R \setminus \bola_ε$ con $ε > 0$.

		Ahora sí podemos aplicar Green, con la ventaja de que $Δu = Δv = 0$. Así, nos queda que \[ \int_{∂B} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S = \int_{B} v Δu - uΔv = 0 \]

		\begin{wrapfigure}[8]{R}[0.1\textwidth]{0.3\textwidth}
		\centering
		\inputtikz{BolaRBolaEpsilon}
		\caption{Frontera de $B$, con las orientaciones concretas para cada bola.}
		\label{fig:BolaRBolaEpsilon}
		\end{wrapfigure}

		Vamos a hacer la integral sobre la frontera, teniendo en cuenta la orientación de los dos anillos (\fref{fig:BolaRBolaEpsilon}, son orientaciones opuestas). Como esa integral es cero, lo que nos queda es que las integrales sobre cada borde son iguales: \begin{align*}
		0 &= \int_{∂B} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S \\
		 \int_{∂\bola_{R}} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S &=  \int_{∂\bola_ε} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S
		\end{align*}

		Sabiendo que $v = \frac{1}{\norm{\vx}^{N-2}}$, resolvemos la integral sobre un borde:
		\[ \int_{∂\bola_R} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S = \int_{∂\bola_R} \frac{1}{R^{N-2}} \dpd{u}{\vn} - u \frac{2-N}{R^{N-1}} \dif S = \dotsb
		\]

		% TODO: Completar esto.
		Después de cálculos desconocidos, llegamos a que
		\[\frac{1}{R^{N-1}} \int_{∂ \bola_R} u \dif \sigma_R = \frac{1}{\epsilon^{N-1}} \int_{∂\bola_\epsilon} u \dif \sigma_\epsilon \]
		y después de algunos cálculos más a que \[ m_\epsilon \leq \frac{1}{\abs{∂ \bola_{\epsilon}}} \int_{∂ \bola_\epsilon} u \dif \sigma_\epsilon \leq M_\epsilon  \]

		Por continuidad: \[M_\epsilon. m_\epsilon \convs[\epsilon][0] u(0) \]

		\end{proof}


		En \textbf{conclusión}, hemos llegado a lo que buscábamos:
		\[ u(0) = \frac{1}{|\bola_R|} \int_{∂ \bola_R} u(y) \dif  \sigma_R \]

		Sin demostrarlo, vamos a ver que tenemos algunas desigualdades si $u$ es sólo superarmónica o subarmónica.

		\begin{prop}[Desigualdad\IS para funciones sub/superarmónicas] Si $u$ es subarmónica, entonces tenemos que \[ -Δ u ≤ 0 \implies u(0)  ≤  \frac{1}{|\bola_R|} \int_{∂ \bola_R} u(y) \dif  \sigma_R\]

		Si $u$ es superarmónica, entonces
		\[ -Δ u ≥ 0 \implies u(0)  ≥  \frac{1}{|\bola_R|} \int_{∂ \bola_R} u(y) \dif  \sigma_R\]
		\end{prop}

		Por supuesto, la desigualdad vale para cualquier bola centrada en cualquier punto:
		\[ u(\vx_0) = \frac{1}{|∂ \bola_R(\vx_0)|} \int\limits_{∂\bola_R(\vx_0)} u(y)\ \dif \sigma_R \]

		También tendremos un resultado análogo al que teníamos en dimensión 2 (\fref{prop:MediaBolaInteriorR2}):

		\begin{prop} \label{prop:MediaBolaInterior} Bajo las mismas hipótesis de la \fref{prop:MediaBola}, tenemos que  \[ u(\va) = \frac{1}{\abs{\bola_R(\va)}} \int_{\bola_R(\va)} u  \]
		\end{prop}

		La propiedad de la media es también interesante porque nos permitirá probar el principio del máximo fuerte.

		\subsubsection{Principio del máximo fuerte}

		Hasta ahora tenemos unicidad para condiciones de Dirichlet, por el \nref{prop:PrincipioMaximoDebil}.

		Veamos los casos dependiendo del contorno:

		\begin{itemize}
			\item Dirichlet:

				\[ \begin{cases}
					-\Delta u = F \text{ en } \Omega \\
					u |_{\delta \Omega} = g \\
					u_1,u_2 \text{ soluciones} \\
					W = u_1 - u_2
				\end{cases} \]

				\[ 0 = - \int_{\Omega} w \Delta w dx = - \left\{  \int_{\delta \Omega} \eqreason[w]{= 0} \frac{\delta w}{\delta u} d\sigma = \int_{\omega}|\grad w|^2 dx \right\}  \]

				(FALTA)

			\item Newman:

				\[ \left. \begin{array}{r}
					-\Delta u = F \text{ en } \Omega \\
					\frac{\delta u}{\delta u}|_{\delta \Omega} = g
					\end{array} \right\} … \left\{ \begin{array}{l}
						- \Delta w = 0 \\
						\frac{\delta w}{\delta u}|_{\delta \Omega} = 0
					\end{array}  \right.  \]

					\[ … \int_{\Omega} |\grad w|^2 dx = 0 \Rightarrow \grad w = 0 \Rightarrow W = \text{cte.}  \]

					Tenemos unicidad salvo constantes

			\item Mixtas:

				(No me da tiempo, salto a lo siguiente)

		\end{itemize}


		\begin{prop}[Principio\IS del máximo fuerte] \label{prop:MaximoFuerte} Sea $u$ una función superarmónica en Ω ($-Δu ≥ 0$).

			\[ - \Delta u \geq 0 \text{ en } \Omega \]
			\[ u (\bar{x}) \geq \frac{1}{|\delta B_R(\bar{x})|} \int\limits_{\delta B_R (\bar{x})} u(\bar{y}) d \sigma_R \quad \forall x \in \Omega, \forall R : B_R(\bar{x}) \subset \Omega \]

		\end{prop}

		\begin{proof}

			Supongamos que sabemos que $u$ es continua y cumple la propiedad anterior. Intentemos probar que el mínimo se alcanza en la frontera. Intentemos demostrarlo por reducción al absurdo: Supongamos que existe $\bar{x_m} \in \text{int} \Omega$ tal que $u(\bar{x_m}) \leq (\bar{x_m}) \leq u(\bar{x}), \forall \bar{x} \in \bar{\omega}$

			Tomamos un $R$ tal que $B_R (\bar{x_m}) \subset \Omega$:

			\[ u(x_m) \geq \frac{1}{|\delta B_R|}  \int\limits_{\delta B_R} u(\bar{y}) d \sigma_R \]

			Si $u(y) \eqreason[>]{estricta} u(x_m) \text{ en } \rho \subset \delta B_R (x_m)$, entonces tendría $\frac{1}{|\delta B_R|} \int\limits_{\delta B_R} u(y) d \sigma_R > u(x_m) $ (u es contínua).

			Por tanto $u \equiv u(x_m)$ en todos los puntos de $\delta B_R(x_m)$, (para todo $R$ tal que $B_R \subset \Omega$). Es decir, $u \equiv u(x_m)$ en toda la bola $B_R$.

			Supongamos $\Omega$ conexo. Podemos conectar $x_m$ con $x_*$ mediante una curva contenida en $\Omega$

			(DIBUJAZO)

			Repetimos el argumento para $x_1$ y encontramos otra bola en la que $u \equiv u(x_m)$. En un número finito de pasos podemos llegar hasta $x_*$. Como $\Omega$ está acotado es compacto, con conceptos de topología podemos asegurar que los radios de las circunferencias tienen un mínimo (distancia a la frontera) y nos aseguramos de que llegaremos a $x_*$.

			Por lo tanto $u$ es constante en $\Omega$.

		\end{proof}

		\begin{theorem}

			Dado $\Omega$ dominio abierto y conexo.

			\begin{itemize}
				\item $-\Delta u \geq 0$ en $\Omega$ entonces:
				\begin{itemize}
					\item $\min_{\bar{\Omega}} u = \min_{\delta \Omega} u$
					\item Además si $u(x_m) = \min_{\bar{\Omega}} u$ para algún $x_m \in \text{int} \Omega$ entonces $u \equiv$ cte.
				\end{itemize}

				\item $-\Delta u \leq 0$ en $\Omega$:
				\begin{itemize}
					\item $\max_{\bar{\Omega}} u = \max_{\delta \Omega} u$
					\item Además si $u(x_m) = \max_{\bar{\Omega}} u$ para algún $x_m \in \text{int} \Omega$ entonces $u \equiv$ cte.
				\end{itemize}

				\item $-\Delta u = 0$: Entonces se cumplen las dos condiciones anteriores.

			\end{itemize}

		\end{theorem}

		\begin{example}[Dominio no acotado]

			\[\begin{array}{l}
				-\Delta u = 0 \text{ en } \|x\| > 1 \\
				\lim_{\|x\| \to \infty} u(x) = 0 \\
				u|_{\|x\| = 1} = f(x), \text{ con } 1 < f(x) < 2
			\end{array}\]

			Nos hace falta saber que le pasa a la función en el infinito. El máximo será el máximo de $R=1$ y el mínimo cuando $R$ tiende a 2.

		\end{example}


		\begin{theorem}
			\[ \left. \begin{array}{l}
				u(\bar{x}) = \frac{1}{|B_R|} \int\limits_{B_R(\bar{x})} d\bar{y} \forall B_R(\bar{x}) \subset Omega \\
				u \text{ contínua }
			\end{array} \right\} \Rightarrow u \text{ armónica } \]

			(Se podría hacer también con el contorno pero sería equivalente)

		\end{theorem}

		\begin{proof}

			¿Como es posible que esa identidad indique que $u \in C^2$. Veámoslo:

			Sea $B_R \subset \Omega$. Consideramos:

			\[ \left. \begin{array}{l}
				- \Delta \Phi = 0 \text{ en } B_R \\
				\Phi |_{\delta B_R = u}
			\end{array} \right\} \Rightarrow \begin{cases}
				\text{ Sabemos resolver en } n = 2 \text{(Poisson)}\\
				\text{Asumimos que tiene solución para cualquier} N
			\end{cases}
			\]

			Queremos probar que $u \equiv \Phi$ en $B_R$, ya que $\Phi$ es armónica. Como es armónica cumple la propiedad de la media. $u$ también cumple la propiedad de la media, por lo que $\Phi - u$ también. Esto es suficiente para cumplir el principio del máximo y como $\Phi -u = 0$ en la frontera, $\Phi = u$.

		\end{proof}

		\textbf{Otros resultados}

		\begin{itemize}
			\item $u$ armónica $\Rightarrow u$ analítica
			\item Los ceros de una función armónica no pueden ser puntos aislados.
			\item Si $u$ es armónica, $u \equiv 0$ en $B_R$. Entonces $u \equiv 0$.
		\end{itemize}



		% Clase 18-4-2016

		Recordamos el teorema de Liouville:

		\begin{theorem}
			\[ \left. \begin{array}{r}
				-\Delta u = 0 \text{ en } \real^n \text{ con u acotada.} \\
				(\exists M \in \real \text{ tal que } - M \leq u(x) \leq M)
			\end{array} \right\} \Rightarrow u \equiv \text{ cte.} \]
		\end{theorem}

		\begin{theorem}[Teorema\IS de Harnack]
			\[ \left. \begin{array}{r}
				-\Delta u = 0  \\
				u \geq 0
			\end{array} \right\} \text{ en } \Omega\]

			\[ B_R(\bar{x_0}) \subset \Omega\]
			\[ \exists C_1(R), C_2(R) \text{ tales que:} \]
			\begin{itemize}
				\item $C_1(R) u(\bar{x_0}) \leq u(\bar{x}) \leq C_2 (R) u(\bar{x_0})), \ \forall \bar{x} \in B_R(\bar{x_0})$
				\item $C_1(R)\max\limits_{\bar{B}_R(\bar{x_0})} u \leq C_2(R) \min\limits_{\bar{B}_R(\bar{x_0})} u $
			\end{itemize}

		\end{theorem}

		\begin{theorem}[Teorema\IS de Hopf]
			\[ \left. \begin{array}{l} \left. \begin{array}{r}
				-\Delta u = 0  \\
				u \geq 0
			\end{array} \right\} \text{ en } \Omega \\
			u(\bar{x_0}) = 0 \text{ para algún } x_0
			\end{array} \right\} \Rightarrow \frac{\partial u} {\partial n} (x_0) < 0
			\]
		\end{theorem}


		Antes de terminar de hablar de la ecuación de Laplace, volvamos a la integral de Dirichlet:
		\[ u_{tt} - u_{xx} = 0 \rightarrow \text{ Energía: } \frac{1}{2} \int_a^b u_t^2 + u_x^2 dx \]

		En dimensión $n$:
		\[ u_{tt}- \Delta u = 0 \rightarrow E \equiv \frac{1}{2}\int\limits_\Omega u^2_t + | \nabla_x u |^2 dx \]

		Posición estacionaria: $u = u(x) \rightarrow u_t = 0$

		\[ - \Delta u = 0 \rightarrow \text{ energía potencial: }\quad \int\limits_\Omega | \nabla u|^2 d\bar{x} \]

		Idea: La solución es la de energía mínima:

		\[ \begin{cases}
			-\Delta u = 0 \text{ en } \Omega \\
			u|_{\partial\Omega} = g
		\end{cases}\]
		\[ A = \{ \omega \in C^2(\Omega) / w |_{\partial \Omega} = g  \} \text{ (funciones admisibles)}\]
		$u$ solución $\Rightarrow$ $u \in A$

		Supongamos $u$ solución:
		Sea $v \in A$:

		\[ 0 = \int\limits_\Omega (-\Delta u)(u-v) d\bar{x} = - \int\limits_{\partial\Omega} \frac{\partial u}{\partial m} (u \eqreason[-]{$g-g=0$}v) + \int\limits_\Omega \pesc{\nabla u, \nabla (u-v)} d\bar{x} \]

		\[ 0 = \int_\Omega \|\nabla u\|^2 d\bar{x} - \int_\Omega \pesc{\nabla u, \nabla v} dx \leq \left( \int_\Omega |\nabla u|^2 dx \right)^{1/2} \left( \int_\Omega |\nabla v|^2 \right)^{1/2} \]

		Donde acabamos de usar el siguiente lema:
		\begin{lemma}[Propiedad\IS de Cauchy-Swartz]
			Todo espacio con un producto escalar *, cumple que
			\[ a * b \leq \|a\| \cdot \|b\| = (a*a)^{1/2} (b*b)^{1/2} \]
		\end{lemma}

		Utilizando el siguiente producto escalar: $u * v = \int\limits_{\Omega} \pesc{\nabla u, \nabla v} dx $

		\textbf{Conclusión:}
		\[ \int_\Omega | \nabla u|^2 dx \leq \left( \int_\Omega |\nabla u|^2 dx \right)^{1/2} \left( \int_\Omega |\nabla v|^2 dx \right)^{1/2} \]

		Es decir:
		\[ \left( \int_\Omega |\nabla u|^2 dx \right) \leq \left( \int_\Omega |\nabla v|^2 dx \right) \quad \forall v \in A \]

		Solución $\Rightarrow$ Energía mínima

		Para demostrar la implicación en el otro sentido:

		\[ E(\Phi) = \int_\Omega |\nabla \Phi|^2 dx \]

		\[ w \in A, \text{ tal que } E(w) \leq E(\Phi), \forall \Phi \in A\]
		\[ w \in A \Rightarrow w|_{\partial \Omega} = g\]

		Queremos probar que $-\Delta w = 0$ en $\Omega$.

		Sea $w+t\psi \in A, t \in \real$:
		\[\begin{cases}
			\psi \in C^2(\Omega)\\
			\Phi|_{\partial \Omega} = 0
	\end{cases}\]

		\[ E(w) \leq E(w + t \psi), \forall t\]

		Fijo $\psi$, definimos $g(t) = E(w + t \psi)$, como el mínimo en $t=0$.

		\[E= \int_\Omega | \nabla (w+t\psi)|^2 dx = \int_\Omega \pesc{\nabla (w+t\psi), \nabla(w + t \psi)} dx\]
		\[ = … = \int_\Omega |\nabla w|^2 dx + t^2 \int_\Omega |\nabla \psi|^2 dx + 2t\int_\Omega \pesc{\nabla w, \nabla \psi} dx \]

		(FALTA UN MONTÓN)

		\textbf{Idea:} Minimizar $E$ en el conjunto $A$:

		Tenemos que $E(\Phi) \geq 0, \forall \Phi \in A$. Si consideramos el conjunto
			\[ \set{ E(\Phi); \Phi \in A} \subset [0, \infty) \]
		Como $[0, \infty)$ está acotado en $\real$, tiene un ínfimo, es decir
		\[ \exists \alpha = \text{inf}\set{E(\Phi) : \Phi \in A} \]
		Pero, ¿se alcanza, es decir, tenemos un mínimo?
		\[ \alpha = \text{inf} \Rightarrow \alpha + \frac{1}{n} \text{ no cota inf.} \]
		\[ \exists W_n \in A \text{ tal que } \alpha \leq E(w_n) < \alpha + \frac{1}{n} \]

		Luego encontramos $\set{w_n} \subset A$. Luego podemos probar sin mucho trabajo que $E(w_n) \rightarrow \infty$

		\[ \begin{rcases*}
			\text{¿} w_n \to w_0 \in A \text{?}\\
			\text{¿} E(W_0) = \alpha \text{?}
		\end{rcases*} \text{ Demostrar la convergencia es difícil.}
		\]

		Entramos en el mundo de la convergencia de funciones. Veremos que $C^2$ no es suficiente.



		\subsubsection{Probabilidad}
		\begin{theorem}[Teorema\IS de la probabilidad total]
		Supongamos que tenemos que $P(A \cup B) = 1$, y $P(A \cap B) = 0$. Entonces
		\[P(C) = P(C|A) P(A) + P(C|B) P(B)\]
		\end{theorem}

		(DIBUJO CAMPO PROBABILIDADES)

		$u(x) \equiv$ probabilidad de encontrar una puerta partiendo de $x$.

		(DIBUJO MOVIMIENTOS PROBABILIDAD)

		Por lo que $u(x,y) = u(x+h,y) \frac{1}{4} + u(x-h,y) \frac{1}{4} + u(x,y+h)\frac{1}{4} + u(x,t-h)\frac{1}{4} $
		\[ 0 = u(x+h,y) + u(x-h,y)+ u(x,y+h) + u(x,y-h) - 4u(x,y) \]
		\[ 0 = \underbrace{u(x+h,y) + u(x-h,y) -2u(x,y)}_{h^2} + \underbrace{u(x,y+h) + u(x,y-h) - 2u(x,y)}_{h^2}\]

		Cuando $h \to 0$:

		\[ 0 = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = \Delta u(x,y)\]

		De otra manera tenemos:

		\[ u(\bar{x}) = \frac{1}{|S_\epsilon|}\int_{S_\epsilon} u(x_\epsilon) d \sigma_{\epsilon}\]

		Lo cual es la propiedad de la media, que está relacionada con la probabilidad condicionada.

		\textbf{Tiempo de parada}

		\[ T(x,y) \equiv \text{ tiempo de parada partiendo de } x\]
		\[ T(x,y) = \frac{1}{4} \{ T(x+h,y) + T(x-h,y) + T(x,y+h) + T(x,y-h) \} + \tau(x,y,h)\]

		\[ … 0 = \frac{\partial^2\tau}{\partial x^2} + \frac{\partial^2 \tau}{\partial y^2} + \lim_{h \to 0} \frac{\tau(x,y,h)}{4h^2} \eqreason{Si $\tau = F(x,y) h^2$} \Delta T + \frac{F}{4} \]

		\[ \begin{cases}
			-\Delta T = F \\
			T |_{\partial \Omega} = 0
		\end{cases}\]

%Clase 19-4-2016

\section{Ecuación de Calor}

	Hemos observado este problema en un dominio acotado (con dimensión espacial 1). Y hemos obtenido diversos resultados como la separación de variables, construcción de series, convergencia… En este último caso hemos obtenido regularidad para $t > 0$ (factor $e^{-\left(\frac{k \pi}{L}\right)^2 t}$).

	Ahora vamos a intentar obtener resultados sobre unicidad (en dimensión 1) y vamos a intentar ver que pasa cuando el dominio no está acotado o cuando aumentamos el número de dimensiones.

	Veamos un ejemplo concreto. Dato el sistema \[ \begin{cases}
		u_{t} - u_{xx} = 0, x \in (0,L), t > 0 \\
		u(x,0) = f(x) \\
		u(0,t) = u(L,t) = 0 \leftarrow \text{Dirichlet homogéneas}
	 \end{cases}\]

	 \begin{quote}
	 	EC.Calor: modelo de las EDP de tipo parabólico
	 \end{quote}

	 Fijamos $T > 0$ y consideramos $Q_T = [0,L]\times [0,T] \in \real^2$, lo cual es un cilindro parabólico.

	 Con la varilla entre dos bloques de hielo, lo que esperamos es que la temperatura de la varilla baje y que tengamos temperaturas mínimas en los extremos. Si resulta que la varilla está más fría que el hielo el proceso contrario ocurrirá y se calentará. En este caso el mínimo se debería alcanzar en algún punto del instante inicial y los máximos estarían en los extremos. Lo que podemos ver es que no es razonable pensar que los mínimos y máximos van a estar en algún punto que no sea los extremos de la varilla o la varilla en el instante inicial.

	 \begin{figure}[hbtp]
	 \centering
	 \inputtikz{EcCalorMaximosMinimos}
	 \caption{Máximos y mínimos en la ecuación del calor: no podemos tenerlos por el medio, sólo en los bordes laterales (verdes) y en el inferior (morado), lo que llamaremos la frontera parabólica.}
	 \label{fig:EcCalorMaximosMinimos}
	 \end{figure}

	 Esto nos va a llevar a un principio del máximo algo más fuerte que nos va a restringir en que partes de la frontera se va a alcanzar.

	 \begin{defn}[Frontera\IS parabólica]
	 	\[\partial_P Q_T = \{(x,0), x \in [0,L]\} \cup \{(0,t), t \in [0,T]\} \cup \{(L,t), t \in [0,T]\}\]
	 \end{defn}

	 \begin{theorem}[Principio\IS del máximo débil] \label{thm:MaximoDebilCalor}
	 	\[ \begin{cases}
	 		u_{t} - u_{xx} = 0, x \in (0,L), t > 0 \\
			u(x,0) = f(x) \\
			u(0,t) = \alpha(t) \\
			u(L,t) = \beta(t)
	 	\end{cases}\]

	 	Entonces $u(x,t)$ alcanza su máximo y su mínimo en puntos de la frontera parabólica $\partial_P Q_T$
	 \end{theorem}

	 \begin{proof}
	 	Demostraremos por reducción al absurdo:

	 	\begin{itemize}

	 		\item Supongamos que se alcanza un máximo en algún punto del interior de $Q_R$.

	 			\[ u_t(x_0,t_0), u_x(x_0,t_0) = (0,0)\]

	 			(DIBUJO)

	 			$u(x,t_0)$ es máximo en $x_0$

	 			$u_{xx}(x_0) \leq 0$. Si la desigualdad fuera estricta habríamos acabado.

	 		\item Supongamos que se alcanza en algún punto de $\delta Q_T - \delta_P Q_T$

	 			(DIBUJO)

	 			\[ \left. \begin{array}{r}
	 				u_t(x_0,T) \geq 0 \\
	 				u_{xx} (x_0,T) \leq 0
	 			\end{array} \right\} \text{ Si la desigualdad fuera estricta habríamos acabado.}\]

	 	\end{itemize}

	 	Idea: Modificar $u$ par obtener en alguna parte desigualdad estricta. Definimos:

	 	\[ \begin{cases}
	 		v^\epsilon(x,t) = u(x,t) + \epsilon x^2\\
	 		v^\epsilon_t = u_t \\
			v^\epsilon_{xx} = u_{xx} + 2\epsilon \\
			v^\epsilon_t - v^\epsilon_{xx} = u_t - u_{xx} - 2\epsilon = - 2\epsilon < 0
	 	\end{cases}\]

	 	Repitiendo los dos items anteriores con $v^\epsilon$ demostramos que $v^\epsilon$ no puede tener máximo en el interior ni en $\partial Q_T - \partial_P Q_T$.

	 	\[ \underbrace{\max v^\epsilon}_{Q_T} = \underbrace{\max v^\epsilon}_{\delta_P Q_T} \]
	 	\[ \left. \begin{array}{r}
	 		u(x,t) \leq v^\epsilon (x,t) = u(x,t) + \epsilon x^2 \leq u(x,t) + \epsilon L^2 \\
	 		v^\epsilon \longrightarrow u(\text{uniforme en } Q_T)
	 		\end{array} \right\} \Rightarrow \max v^\epsilon \convs[][\epsilon][0] \max u
	 	\]

	 	De manera análoga:
	 	\[ \underbrace{\min u}_{Q_T} = \underbrace{\min u}_{\delta_P Q_T} \]


	 \end{proof}

	 Como consecuencias de este principio del máximo tenemos:
	 \begin{itemize}
	 	\item Comparación
	 	\item Unicidad
	 	\item Estimación a priori
	 	\item Dependencia continua de los datos
	 \end{itemize}

	 \begin{example}[Comparación]
	 	\begin{align*}
	 		u_t - u_{xx} = F_1(x,t) &\geq F_2(x,t) = V_t - V_{xx} \\
	 		u(x,0) = f_1(x) &\geq f_2(x) = v(x,0) \\
	 		u(0,t) = \alpha_1(t) &\geq \alpha_2(t) = v(0,t)\\
	 		u(L,t) = \beta_1(t) &\geq \beta_2(t) = v(L,t)
	 	\end{align*}

	 	\textbf{Comentarios}
	 	\begin{itemize}
	 		\item Resultado válido en dim. N, ecuación $u_t - \Delta u = 0$
	 		\item \[u_t - u_{xx} \geq 0 (\text{supersolución})\]
	 			\[ \underbrace{\min u}_{Q_T} = \underbrace{\min u}_{\delta_P Q_T} \]

	 			\[u_t - u_{xx} \leq 0 (\text{subsolución})\]
				\[ \underbrace{\max u}_{Q_T} = \underbrace{\max u}_{\delta_P Q_T} \]


				\[ W = u-v … W_t - W_{xx} \geq 0\]
				\[ \left.\begin{array}{r}
					W(x,0) \geq 0 \\
					W(0,t) \geq 0 \\
					W(L,t) \geq 0
				\end{array} \right\} \eqreason[\Rightarrow]{Principio del máximo} W= 0 \text{ en } Q_T \Rightarrow u \geq v \text{ en } Q_T \]
	 	\end{itemize}

	 \end{example}

	 \begin{example}[Unicidad]

	 	(FALTA)

	 \end{example}

	 \begin{example}[Estimación a priori]

	 	\[\begin{cases}
	 		u_{t} - u_{xx} = F(x,t) \\
			u(x,0) = f(x) \\
			u(0,t) = \alpha(t) \\
			u(L,t) = \beta(t)
	 	\end{cases}\]

	 	Supongamos $|F(x,t)| \leq M, \forall(x,t) \in Q_T$

	 	Definimos $W(x,t) = u(x,t) + \frac{M}{2} x^2$

	 	\[ W_t = u_t ; W_{xx} = u_{xx} + M\]
	 	\[\begin{cases}
	 		W_t - W_{xx} = u_t - u_{xx} - M = F-M \eqreason[\leq]{$F \leq M$} 0 (\text{subsol.})\\
	 		W(x,0) = u(x,0) + \frac{M}{2} x^2 = f(x) + \frac{M}{2} x^2 \leq \underbrace{f(x) + \frac{M}{2}L^2}_{\|f\|_\infty = \max |f|}\\
	 		W(0,t) = u(0,t) = \alpha(t) \\
	 		W(L,t) = u(L,t) + \frac{M}{2}L^2 = \beta(t) + \frac{M}{2} L^2
	 	\end{cases}\]

	 	\[ \underbrace{\max W}_{Q_T} = \underbrace{\max W}_{\delta_P Q_T} \]

	 	\[ W(x,t) \leq \max\limits_{\delta_P Q_T} w \leq \max \{ \|f\|_\infty + \frac{M}{2}L^2, \|\alpha\|_\infty, \|\beta\|_\infty + \frac{ML^2}{2}\} \]

	 	\(\leq \|f\|_\infty + \|\alpha\|_\infty + \|\beta\|_\infty + \frac{\|F\|_\infty}{2}L^2 \label{eq:estimacion_a_priori_calor}\)

	 	\textbf{Conclusión}

	 	\[ u(x,t) \leq u(x,t) + \frac{M}{2}x^2 \leq \eqref{eq:estimacion_a_priori_calor} \]

	 	Análogamente $u(x,t) \geq … $

	 	Resultado: $|u(x,t)| \leq \|F\|_\infty \frac{L^2}{2} + … $





	\end{example}


%Clase  20-4-2016

	\subsection{Prueba alternativa del resultado de unicidad}

	 	Vamos a ver una prueba alternativa más general que la vista anteriormente con el teorema del máximo.

	 	(RELLENAR ENUNCIADO)

	 	Y usámos el método de la energía:

	 	\[ 0 = \int_0^L (W_t-W_{xx}) W dx = \int_0^L \underbrace{W W_t}_{(\frac{W}{2})_t} dx - \underbrace{\int_0^L W W_{xx}}_{W W_x |_{x=0}^L - \int_0^L W^2_x dx} dx  \]

	 	\[ 0 = \left(\int_0^L \frac{W^2}{2}dx\right)_t - \underbrace{\left. W W_x \right|_{x=0}^L}_{(*)=W(L,t)W_x(L,t)-W(0,t)W_x(0,t)} + \int_0^L W^2_x dx \]

	 	\[\text{Condiciones de contorno} \Rightarrow \begin{cases}
	 		\text{ Dirichlet: } &W(0,t) = W(L,t) = 0 \Rightarrow (*) = 0\\
	 		\text{ Neumann: } &W_x(0,t) = W_x(L,t) = 0 \Rightarrow (*) = 0\\
	 		\text{ Periódicas: } &\begin{array}{l}
	 			W(0,t) = W(L,t) \\
	 			W_x(0,t) = W_x(L,t)
	 			\end{array} \Rightarrow (*) = 0 \\
	 		\text{ Mixtas: } &W(0,t) = 0 = W_x(L,t) \Rightarrow (*) = 0
	 	\end{cases}\]

	 	Para cualquier condición de contorno que anule $(*)$:

	 	\[\left( \int_0^L \frac{W^2}{2} dx \right)_t = - \int_0^L W^2_x dx \]

	 	Definimos $e(t) = \int_0^L \frac{W^2(x,t)}{2}dx$

	 	Hemos probado:
	 	\[\left.\begin{array}{r}
	 		e'(t) \leq 0 \\
	 		0 \leq e(t) \\
	 		e(0) = 0
	 	\end{array}\right\} \Rightarrow e \equiv 0 \forall t\]


	 \subsection{Problema de ``unicidad hacia atrás''}

	 	\begin{theorem}

		 	Supongamos que $u$ y $v$ son soluciones de la misma ecuación de calor:

		 	\[\begin{cases}
		 		u_t - u_{xx} = F(x,t) = v_t - v_{xx}, \quad x \in (0,L), t > 0 \\
		 		u(0,t) = h(t) = v(0,t) \\
		 		u(L,t) = g(t) = v(L,t)
		 	\end{cases}\]

		 	En $T > 0$, $u(x,T) = v(x,T)$. Entonces $u(x,t) = v(x,t), \forall t \in [0,T]$

		\end{theorem}

		\begin{proof}

			\[\begin{cases}
				W = u-v\\
				W_t - W_{xx} = 0 \\
				W(0,t) = W(L,t) = 0\\
				W(x,T) = 0
			\end{cases}\]

			Queremos probar $W(x,t) = 0, t < T$

			Método de la energía:

			\[ e(t) = \int_0^L \frac{W^2(x,t)}{2} dx \geq 0 \quad \quad e(T) = 0\]
			\[ e'(t) = \int_0^L WW_t dx = \int_0^L W W_{xx} dx = \left. W W_x \right|_0^L - \int_0^L W^2_x dx \quad (\leq 0) \]
			\[ e''(t) = - \int^L_0 2W_x W_{xt} dx = -2 \left\{ \left. W_x W_t \right|^L_{x=0} - \int_0^L W_{xx} W_t dx \right\} \]

			\[W(0,t)  = 0, \forall t \Rightarrow  W_t(0,t) > 0 \forall t \]
			\[W(L,t)  = 0, \forall t \Rightarrow  W_t(L,t) > 0 \forall t \]

			Entonces:
			\[ \left. \begin{array}{r} e'(t) = - \int_0^L W^2_x dx \\
			 e''(t) = 2 \int_0^L (W_{xx})^2 dx \end{array} \right| e(t) = \frac{1}{2} \int_0^L W^2 \]

			Lo cual se obtiene de:

			\[ \int_0^L W^2_x dx = - \int_0^L W W_{xx} dx = - \pesc{W, W_{xx}} \in L^2(0,L)\]

			\[ \leq \left( \int_0^L W^2 dx  \right)^{\frac{1}{2}} \left( \int_0^L W^2_{xx}  \right)^{\frac{1}{2}}\]

			\[ \left( \int_0^L W^2_x  \right)^{2} \leq \int_0^L W^2 \cdot \int_0^L W_{xx}^2 \]

			Entonces llegamos a:

			\[ (e'(t))^2  \leq e(t) e''(t) \quad\quad\quad e(T) = 0 \]

			Si $e(t) = 0$, entonces $W(x,t) = 0$. Supongamos $e(t_1) > 0$ para algún $t_1 \in (0,T)$

			(DIBUJO)

			\[f(t) = \log (e(t))\]
			\[t_2 = \sup\{t \in [t_1,T] / e(t) > 0 \text{ en } [t_1,t)\}\]
			\[f'(t) = \frac{e'(t)}{e(t)} \leq 0\]
			\[f''(t) = \frac{e''(t) e(t)- (e'(t))^2}{e^2(t)} \geq 0\]

			Entonces sabemos que $f$ es decreciente y convexa (en $[t_1,t2)$). Tomamos $t \in ( t_1 , t_2 )$.

			(DIBUJO)

			Convexidad:
			\[f(zt_1 + (1-z)t) \leq zf(t_1) + (1-z) f(t), z \in (0,1)\]

			Y tomando exponenciales:
			\[e(zt_1 + (1-z)t) \leq e(t_1)^z e(t)^{1-z} \forall t \in (t_1,t_2)\]

			hacemos tender $t$ a $t_2$ y obtenemos que $e(t)$ tiende a 0.
			\[ 0 \leq e(zt_1 + (1-z)t_2) \leq e(t_1)^z \cdot 0 = 0\]

			Donde $(zt_1 + (1-z)t_2)$ es un punto intermedio entre $(t_1,t_2)$.

			\[e(zt_1+(1-z)t_2) = 0\]

			Y esto es una contradicción con la definición de $t_2$.

		\end{proof}

	\subsection{Ecuación de difusión en todo el espacio}

		\[\begin{cases}
			u_t - \Delta u = 0 \text{ en } \real^n\\
			u(\bar{x},0) = f(\bar{x})
		\end{cases}\]

		Una de las primeras características que vamos a ver es como es la dispersión instantánea al infinito del calor. En estos sistemas, en cuanto el tiempo es positivo veremos como el calor concentrado en puntos se dispersa instantáneamente. La velocidad de propagación es infinita. Esto nos dará problemas con la unicidad, que solucionaremos añadiendo condiciones de contorno en el infinito. Condiciones mejores que ``el valor en el infinito es 0''. Intentaremos usar condiciones del tipo ``En el infinito las soluciones crecen como máximo como un polinomio''.

		Punto de partida: Solución fundamental (Núcleo de Gauss). Vamos a suponer que la temperatura inicial es finita. Y la normalizamos con una cantidad de calor = 1. Así buscaremos soluciones que conserven la cantidad total de calor.

		\[\begin{cases}
			u_t - \Delta u = 0 \text{ en } \real^n\\
			u(\bar{x},0) = f(\bar{x}) \\
			\int\limits_{\real^N} f(\bar{x}) d\bar{x} = 1
		\end{cases}\]

		\begin{example}[Dimensión espacial 1]
			Realizamos un cambio de escala:
			\[\begin{cases}
				x = \lambda y\\
				t = \mu z
			\end{cases}\]

			Queremos ver que valores de $\lambda$ y $\mu$ hacen que $v$ siga siendo solución.

			Veremos que no se pueden cambiar aleatoriamente y tenemos que respetar la relación entre tiempo y espacio $\lambda = \mu^2$ para realizar un cambio de variables adecuado. Y veremos que esto nos ayudará a pasar a una EDO.
		\end{example}

		% Clase 25-4-2016

		Vamos a estudiar ahora a fondo el problema, estudiando la ecuación
		\[u_t - \Delta u = 0 \qquad x \in \real^n,\, t > 0\]

		Buscaremos una solución particular, y además vamos a normalizar, esto es, hacer que el ``calor total'' sea 1:
		\( \int\limits_{\real^n} u(\bar{x},t) \dif \bar{x} = 1\; \forall t > 0 \label{eq:Calor:Normalizacion} \)


		Vamos a ir simplificando el problema. La primera simplificación que haremos será escribir $u$ como una función radial, esto es, $u = u(r)$ con $r^2 = x^2_1 + \dotsb  + x^2_n$. Sacando el laplaciano tenemos que
		\[ Δu =  u_{x_1 x_1} + u_{x_2 x_2} + \dotsb + u_{x_n x_n} = \dotsc = u_{x_r x_r} + \frac{n-1}{r}u_r \]

		Por el otro lado, aplicamos el cambio de variables a la normalización de \eqref{eq:Calor:Normalizacion}, y tenemos que
		\[ 1 = \int\limits_{\real^n}  u(\bar{x},t) \dif \bar{x} \eqreasonup{polares} \int_{\crc[n-1]} \int_0^\infty u(r,t) r^{n-1} \dif r \dif \omega = ω_n \int_0^\infty u(r,t) r^{n-1} r^{n-1} \dif r \] con $ω_n$ la medida de la esfera $n$-dimensional de radio $1$.

		Con todo esto, llegamos a nuestro problema simplficado:
		\( \begin{cases}
			u_t - u_{rr} - \frac{n-1}{r}u_r  = 0\\
			\displaystyle\int_0^\infty u(r,t) r^{n-1} r^{n-1} \dif r = \frac{1}{\omega}
		\end{cases} \label{eq:Calor:ProblemaSimplificado} \)

		Ahora aplicamos una idea feliz: vamos a estudiar qué efectos tienen los cambios de escala en nuestro problema. Dados dos factores $λ,μ$ de cambio de escala, hacemos la sustitución y estudiamos la solución ``reescalada'' $v$:
		\[\begin{cases}
			r = \lambda s\\
			t = \mu \tau
		\end{cases} \implies v(s,τ) = u(λs, μτ)\]


		Sacamos ahora las derivadas de nuestra nueva función, para prepararnos y sustituir en \eqref{eq:Calor:ProblemaSimplificado}:
		\begin{align*}
			v_\tau (s,\tau) &= u_t (\lambda s, \mu \tau) \cdot (\mu \tau)_{\tau} \\
				&= u_t(\lambda s, \mu \tau) \mu \\
				v_s(s,\tau) &= u_r(\lambda s, \mu \tau) \lambda \\
				v_{ss}(s,\tau) &= u_{rr} (\lambda s, \mu \tau) \lambda^2
		\end{align*}

		Ahora sustituimos en la ecuación diferencial, y vemos qué pasa:
		\begin{align*}
		v_\tau (s,\tau) - v_{ss}(s,\tau) - \frac{n-1}{s} v_s(s,\tau)
			&= \mu v_t(\lambda s, \mu \tau) - u_{rr}(\lambda s, \mu \tau) \lambda^2 - \frac{n-1}{\lambda s} \lambda^2 u_r(\lambda s, \mu \tau) = \\
			&= \mu u_t(\lambda s, \mu \tau) - \lambda^2 \left( u_{rr}(\lambda s, \mu \tau) `\frac{n-1}{\lambda s} u_r(\lambda s, \mu \tau)\right) = \\
			&= (\mu - \lambda^2) u_t(\lambda s, \mu \tau)
		\end{align*}

		A lo que llegamos es a que si $μ = λ^2$, la función $v$ sigue siendo solución del problema. Si los cambios no son independientes, tiene que haber alguna variable subyacente que nos dé ese cambio de escala.

		Por otro lado, buscamos soluciones que conserven la cantidad de calor, así que sustituimos en la integral:
		\begin{align*}
		\frac{1}{\omega_{n}} &= \int_0^\infty v(s, \tau) s^{n-1} \dif s
		= \int_0^\infty C u(\lambda s, \lambda^2 \tau) s^{n-1} \dif s = \\
		&\eqreason{cambio de variable $\lambda s = r$} \int_0^\infty C u(r, \lambda^2 \tau) \frac{r^{n-1}}{\lambda n \dif r}
		= \frac{1}{\lambda^n}  \underbrace{\int_0^\infty   u(r, \lambda^2\tau) r^{n-1} dr}_{= \frac{1}{\omega_n} (\forall \tau)}
		= \frac{C}{\lambda^n}\frac{1}{\omega_n} \\
		C &= λ^n
		\end{align*}

		Así, nuestra solución reescalada ha de ser de la forma:
		\[ v(s,\tau) = \lambda^n u(\lambda s, \lambda^2 \tau)\]

		Con esto hemos llegado a que si existe una solución existen infinitas cambiando la $n$ en la fórmula anterior. Pero también hemos obtenido que las soluciones no solo deben ser $C^2$, sino que tienen que respetar estas restricciones. Ahora, con un espacio de funciones posibles menor vamos a intentar encontrarlas. Estudiamos qué ocurre cuando hacemos el siguiente cambio
		\[ \underbrace{v(s,1)}_{\text{una variable}} = \lambda^n u (\lambda s, \lambda^2) \]

		Recordemos $\lambda^2 = t$, $\lambda s = r$ y $s = \frac{r}{\lambda} = \frac{r}{\sqrt{t}}$.

		\[ u(r,t) = \frac{1}{\lambda^n} v(s,1) = \frac{1}{t^{n/2}} v\left(\frac{r}{\sqrt{t}},1\right)\]

		Parece que hemos llegado a algo, pero ahora estamos haciendo variar $λ$. En cualquier caso, quizás podríamos buscar por funciones que sigan esa forma, $u(r,t) = \frac{1}{t^{n/2}} \Phi\left(\frac{r}{\sqrt{t}}\right)$, con $\Phi: \real \rightarrow \real$.

		Llegamos al problema: Encontrar una función $\Phi$ (de una variable) tal que $u(r,t) = \frac{1}{t^{n/2}} \Phi(\frac{r}{\sqrt{t}})$ sea solución.

		\textbf{Notación: } $\xi = \frac{r}{\sqrt{t}}$, y $\xi_r = \frac{1}{\sqrt{t}}$, y $\xi_t = -\frac{1}{2} t^{-3/2} r$.

		\[ u_t = - \frac{n}{2} t^{-n/2-1} \Phi + t^{-n/2} \Phi' (\xi) \xi_t = -\frac{n}{2} t^{-n/2 - 1} \Phi(\xi) + t^{-n/2} \Phi'(\xi) (-\frac{1}{2}) \]

		(FALTA $u_r$ y $u_{rr}$)

		\[ u_t - u_{rr} - \frac{n-1}{r}u_r = … = - t^{-n/2 - 1} \underbrace{\left\{ \Phi'' + \frac{n-1}{\xi}\Phi' + \frac{\xi}{2}\Phi' + \frac{n}{2}\Phi \right\}}_{\text{EDO}} \]

		Conclusión: tenemos que encontar una solución
		\[ \Phi'' + \frac{n-1}{\phi} \Phi'+ \frac{\xi}{2}\Phi' + \frac{n}{2}\Phi = 0\]

		En el caso $n = 1$:
		\[ \Phi'' + \underbrace{\frac{\xi}{2}\Phi' \frac{1}{2}\Phi}_{\frac{1}{2} (\xi \Phi)'} = 0\]

		\[ \left[ \Phi' + \frac{1}{2} (\xi \Phi)  \right]' = 0\]
		\[ \Phi' + \frac{1}{2} \xi \Phi = 0 \quad \text{cte.}\]
		\[ \frac{\Phi'}{\Phi} = -\frac{1}{2} \xi\]
		\[ \Phi(\xi) = C e^{-\frac{\xi^2}{4}}\]

		Con $n=1$:

		\[ u(r,t) = t^{-\frac{1}{2}} \Phi(\frac{r}{\sqrt{t}}) \eqexpl{C}  \text{algo muy bonito}\]

		Para el caso $n \neq 1$ usamos facotr integrante $\xi^{n-1} + …$

		\[ \underbrace{\xi^{n-1} \Phi'' + (n-1) \xi^{n-2}}_{(\xi^{n-1}\Phi')'} \Phi' + \underbrace{\frac{1}{2}\xi^n \Phi' + \frac{1}{2} n \xi^{n-1} \Phi}_{(\frac{1}{2} \xi^n \Phi)'} = 0 \]

		\[ (\xi^{n-1} \Phi' + \frac{\xi^n}{2}\Phi)' = 0\]

		(FALTA UN POQUITÍN)

		Conclusión:
			\[ u(r,t) = t^{-n/2} \Phi(\frac{r}{\sqrt{t}}) = t^{-\frac{n}{2}} C e^{-\frac{r^2}{4t}} \]

		(DIBUJOS DE $t$ pequeño a $t$ grande)


		% Clase 26-4-2016
		Tenemos que ajustar el valor de $C$ para que

		\[
			1 = \frac{C}{t^{\rfrac{N}{2}}} \int_{\real^N} e^{-\frac{x_1^2+x_2^2+...+x_n^2}{4t}} dx = \frac{C}{t^{\rfrac{N}{2}}}\prod \int_{-∞}^{∞} e^{-\frac{x_i}{4t}} dx_i
		\]

		Haciendo el cambio de variables:

		\[
			z = \frac{x_i}{2\sqrt{t}}
		\]


		Obtenemos:

		\[
			\frac{C}{t^{\rfrac{N}{2}}} \left[ \int_{-∞}^{∞} e^{-z^2}2\sqrt{t}dz \right]^N = ...
		\]


		Hemos llegado a la expresión del \concept{núcleo de Gauss}

		\[G(x,t) = \frac{1}{(\sqrt{4πt})^N}e^{-\frac{\norm{\vx}^2}{4t}}\]

		Esto es una solución particular que tiene la curiosidad de que en $t=0$ no está definida.
		%
		Vamos a estudiar el núcleo de Gauss:

		\paragraph{Propiedades:}

		\begin{itemize}
			\item $G(x,t) > 0$.
			\item $G(x,t)$ es par en $x_i$ (de hecho, es radial)
			\item $G(x,t)$ decreciente en $x_i>0$.
			\item Tomando el límite acercándonos a $t=0$, observamos:

			\[\lim_{t\to 0^+} G(x,t) = \begin{array}{ccc} 0&si&\vec{x} ≠ 0 \\ ∞ & si & \vx = 0\end{array}\]

			\item Si alguien tiene curiosidad, estas 2 últimas propiedades se pueden escribir como que el núcleo de Gauss, converge nosecomo a la delta de dirack.

			\[
				G(x,t) \to_{t\to 0^+} \delta_{x=0}
			\]
		\end{itemize}

		\begin{theorem}
		Sea $f$ una función continua y acotada.

		Sea \[u(x,t) = \int_{\real^n} G(\vx-\vy,t)f(\vy)d\vy\]

		\textbf{Entonces:}

		\begin{itemize}
			\item $u(x,t)\in C^{∞}$
			\item $u_t - Δu = 0, \vx \in \real^n\;,t>0$, es decir, es solución de la ecuación de difusión (o ecuación del calor).
			\item $\lim_{t\to 0^+} u(x,t) = f(x)$ con convergencia puntual.
		\end{itemize}
		\end{theorem}

		\obs Tenemos un \textbf{efecto regularizante}.
		%
		Hemos llegado a soluciones $C^{∞}$ partiendo de cosas que no tendrían porqué serlo.

		Además, tenemos una \textbf{velocidad infinita}, es decir no existe $\vx \tlq u(\vx,ε) = 0$ cuando $ε\to 0$.
		%
		En un tiempo tan pequeño como queramos, encontramos que el calor del dato inicial se ha desplazado a cualquier punto.

		Vamos a justificarlo.
		%
		Supongamos que tenemos una pequeña cantidad de calor en $x=x_1, t=0$.
		%
		La función solución $u(x,t)$ siempre positiva. Al integrar el producto en $\vx = \vec{x_2}$ muy alejado de $\vec{x_1}$

		\[
			\int_{\real^n} G(\vx_2-\vy,t)f(\vy)d\vy
		\]




		Comentarios ``útiles'':

		\begin{equation}
			\abs{\dpa{G}{x_i} (z,t)} \leq … \leq \frac{|x_i-y_i|+1}{2\sqrt{4πt}^N} e^{-\frac{\norm{x-y}(\norm{x-y}-2)}{4t}}
			\label{eq:dejuan}
		\end{equation}

		Este paso clave demuestra que podemos pasar derivadas dentro de integrales, es decir:

		\[
			\dpa{u}{x_i} = \int_{\real^N} \dpa{G}{x_i} f
		\]

		Si tomamos más derivadas, en el término $|x_i-y_i|$ aparecería elevado a alguna potencia.
		%
		Independientemente de la potencia que aparezca, el argumento sigue siendo válido porque la exponencial negativa de \ref{eq:dejuan} manda sobre cualquier polinomio.



		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
		¿Este resultado prueba convergencia uniforme? No, porque en principio el $δ$, podría depender de $\vx$ y podría ocurrir que necesitáramos una prueba para $\vx$.
		%
		Si tomamos uniformemente continua, entonces $\exists δ$ que no depende de $\vx$, con lo que la convergencia es uniforme.


		\begin{proof}
			¿Qué pasa con $\frac{\partial u}{\partial x}$ ?
			\[ \lim_{h \to 0} \frac{u(\bar{x} + hei,t)-u(\bar{x},t)}{h} = \lim_{h \to 0} \int\limits_{\real^n} \frac{G(\bar{x}-\bar{y}+he_i,t)-G(\bar{x}-\bar{y})}{h} f(y) dy
			\]

			Problema: ¿Podemos permutar límite e integral?

			Usaremos el teorema de convergencia dominada:

			\[\left. \begin{array}{r}
				f_x \to f \text{ puntualmente en } \Omega \\
				|f_x(x)| \leq F(x), \forall x \forall k \\
				F \text{integrable}
			\end{array} \right\} \Rightarrow \lim_k \int\limits_{\Omega} f_k = \int\limits_\Omega \lim f_k = \int\limits_\Omega f\]

			\[ \frac{G(\bar{x}-\bar{y}+he_i,t)-G(\bar{x}-\bar{y},t)}{h} = \frac{\partial G}{\partial x}(z,t) \]

			$z$ es un punto intermedio

			\[\frac{\partial G}{\partial X_i}(z,t) = … = \frac{z_i}{2t} \frac{1}{(\sqrt{4\pi t}^n)} e^{-\frac{\|z\|^2}{4t}}\]

			Entonces expresamos $z$, que está entre $\bar{x}-\bar{y}$ y $\bar{x}-\bar{y}+he_i$, como: $z = \bar{x} - \bar{y} + \theta h e_i$ con $\theta \in (0,1)$

			\[ \left| \frac{\partial G}{\partial x}(z,t) \right|  \leq \frac{|z_i}{2t (\sqrt{4\pi t})`n} e^{-\frac{\|z\|}{4t}}\]

			\[\text{ Queremos encontrar} \begin{cases}
				|z_i| \leq |x_i - y_i| + 1 \\
				\| z\|^2 \geq (ALGO)
			\end{cases}\]

			(FALTA)

			Y entonces podemos reescribir lo que queríamos encontrar así:

			\[\begin{cases}
				|z_i| \leq |x_i - y_i| + 1 \\
				\| z\|^2 \geq \|\bar{x}-\bar{y}\| (\|\bar{x}-\bar{y}\| -2)
			\end{cases}\]

			Acotamos la expresión que teníamos así:

			\[ \left| \frac{\partial G}{\partial x}(z,t) \right|  \leq \frac{|z_i}{2t (\sqrt{4\pi t})`n} e^{-\frac{\|z\|}{4t}} \leq \frac{|x_i-y_i| +1}{2t(\sqrt{4 \pi t})^n} e^{-\frac{\|\bar{x}-\bar{y}\| (\|\bar{x}-\bar{y}\| -2)}{4t}}\]

			Lo que es equivalente a $\phi(y)$

			Por lo que hemos acotado:

			\[ \left| \frac{G(x-y+he_i,t) - G(x-y,t)}{h} f(y) \right| \leq \phi(y) g(y) \]

			$f(y)$ está acotada. Y $\phi(y)$ es integrable. Tenemos que hacer que se deje integrar en todo $\real^n$. Tiene que decaer en el infinito, no nos vale que sea continua, pero podemos ver que tiene decaimiento exponencial.

			Hemos demostrado:

			\[ \frac{\partial u}{\partial x_i} = \int\limits_{\real^n}\frac{\partial G}{\partial x} f\]

			Iterando el proceso (pasando todas las derivadas dentro de la integral):
			\[ u \in C^\infty, t> 0\]

			Como por ejemplo:
			\[ u_t - \Delta u = … = \int(G_t- \Delta G) f = 0\]


		\end{proof}

		\begin{example}

			Queremos probar:
			\[ \int\limits_{\real^n} G(x-y,t) f(y) dy \convs[][t][0^+] f(x)\]

			\[ 0 \leq \left| \int\limits_{\real^n} G(x-y,t) f(y) dy - f(x) \int_{\real^n} G(x-y,t) dy \right|\]

			\[ = \left| \int_{\real^n} G(x-y,t) (f(y)-f(x))dy \right| \eqreason[\leq]{$G \geq 0$} \int_{\real^n} G(x-y,t) |f(x) - f(y)| dy \]

			Dado $\epsilon > 0$ encontramos $\delta$ tal que si $\|x-y\| < \delta$, entonces $|f(\bar{x})-f(\bar{y})| < \epsilon$

			\[ \int\limits_{\real^n} = \underbrace{\int\limits_{\|x-y\| < \delta}}_{(1)} + \underbrace{\int\limits_{\|x-y\|>\delta}}_{(2)}\]

			\[ (1) \leq \int\limits_{\|x-y\|\leq \delta} G \epsilon \eqreason[\leq]{$\int_{\real^n} G = 1$} \epsilon\]

			\[ (2): \int\limits_{\|x-y\|>\delta} G(x-y) \underbrace{| f(x) - f(y) |}_{C,f \text{ acotada}} dy \leq C \int\limits_{\|x-y\| > \delta} \frac{1}{(\sqrt{4\pi t})^n} e^{-\frac{\|x-y\|^2}{4t}} dy \convs[exponencial][t][0^+] \epsilon\]

			Entonces hay convergencia puntual:
			\[\int G(x-y,t) f(y) dy \convs[][t][0^+] f(x)\]

		\end{example}

		\obs
				\begin{itemize}
					\item Si $f$ es continua puntualmente $\Rightarrow$ convergencia puntual (que acabamos de demostrar)
					\item Si $f$ es uniformenente contínua $\Rightarrow$ convergencia uniforme
					\item Si $f \in L^2 \Rightarrow u(x,t) \convs[L^2][t][0^+] f(x)$
				\end{itemize}


		% Clase 27-4-2016
		% Copiado por @gjulianm

		Ayer demostrarmos que teníamos convergencia a una función, pero el problema es que no sabemos si es solución única.

		Antes de eso vamos a ver el problema no homogéneo, es decir, con \[ \begin{cases}
		u_t - Δu = F(x,t) \\
		u(x,0) = f(x) \end{cases} \]

		El truco es el de siempre, el que ya usamos al jugar con la ecuación de onda. Asumimos de momento que $f$ y $F$ son tan regulares y acotadas como necesitemos.

 		Para operar, descomponemos $u$ como suma de dos soluciones $v + w$, donde una se lleva el dato inicial y otra la no homogeneidad: \[
 		\begin{cases} v_t - Δv = 0 \\ v(x,0) = f(x) \end{cases} \qquad \begin{cases} w_t - Δw = F(x,t) \\ w(x,0) = 0 \end{cases} \]

 		Aplicamos ahora el principio de Duhamel que vimos en la \fref{sec:PrincipioDuhamel}. Fijamos un tiempo $s > 0$ y resolvemos el sistema \[ \begin{cases} Φ_t - ΔΦ = 0 \\ Φ(x,0) = F(x,s) \end{cases} \] con solución \[ Φ(x,t) = \int_{ℝ^N} G(x-y, t) F(y,s) \dif s \] del dato $F(x,s)$ en $t = 0$. Para ver la solución en $t = s$, hacemos la traslación: \[ Φ(x, t - s) = \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \]

 		Así, la solución $w(x,t)$ será la suma de los efectos de $F$ entre $0$ y $t$, luego \[ w(x,t) = \int_0^t Φ(x, t - s) \dif s = \int_0^t \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \dif s\]

 		Finalmente podemos hallar la solución al problema completo: \( u(x,t) = \int{ℝ^N} G(x-y, t) f(y) \dif y + \int_0^t \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \dif s \label{eq:Calor:SolucionNoHomogenea} \)

 		De nuevo, nos encontramos con el problema de la unicidad. Tenemos $u_1$ y $u_2$ dos soluciones, así que consideramos la función $ψ = u_1 - u_2$ y buscamos soluciones no triviales al sistema \[ \begin{cases} ψ_t - Δψ = 0 \\ ψ(x,0) = 0 \end{cases} \]

 		%Vuelta a @erpheus

 		\subsection{Contraejemplo de Tijonov}
 			También conocido como Tychonoff.

 			\[u_t - u_{xx} = 0\]

 			En la dirección del tiempo tenemos solo una derivada (ecuación de orden uno) y solo necesitamos un dato inicial para fijar el problema.

 			En la dirección de las x tenemos un problema de orden 2, por lo que hacen falta añadir dos datos si queremos fijar la $x$:

 			\[\begin{cases}
 				u_t-u_{xx} = 0 \\
 				u(0,t) = g(t) \\
 				u_x(0,t) = 0
 			\end{cases}\]

 			Tijonov decidió expresar $u(x,t)$ como desarrollo en forma de potencias: $u(x,t) = \sum\limits_{k=0}^\infty a_k(t) x^k = a_0(t) + a_1(t)x + a_2(t)x^2 + …$

 			Formalmente:
 			\[ g(t) = u(0,t) = a_0(t)\]
 			\[ u_x(x,t) \qeq a_1(t) + 2a_2(t)x + 3a_3(t)x^2 + …\]
 			\[ 0 = u_x(0,t) = a_1(t)\]

 			\begin{align*}
 				u_t(x,t) &= a'_0 + a'_1 x + a'_2x^2 + … \\
 				u_x(x,t) &= a_1 + 2a_2x + 3a_3x^2 + … \\
 				u_{xx}(x,t) &= 2a_2 + 3 \cdot 2 a_3 x + 4 \cdot 3 a_4 x^2 + …
 			\end{align*}

 			Para tener $u_t = u_{xx}$ igualamos los coeficientes de caa término en $x^j$.

 			\[ a'_j(t) = (j+2)(j+1) a_{j+2} (t)\]
 			\[a_1 \equiv 0 \Rightarrow a'_1 \equiv 0 \Rightarrow a_3 \equiv 0 \Rightarrow a'_3 \equiv 0 …\]

 			Por lo que llegamos a que $a_{2n+1} = 0 \forall n$. Podemos hacer lo mismo con los pares:

 			\begin{align*}
 				a_0 &= g \\
 				g' &= a'_0 = 2 \cdot 1 a_2 (t) \Rightarrow a_2 = \frac{1}{2} g' \\
 				\frac{1}{2}g'' &= a'_2 = 4 \cdot 3 a_4 (t) \Rightarrow a_4 = \frac{1}{4!} g'' \\
 				\frac{1}{4!}g''' &= a'_4 = 6 \cdot 5 a_6 (t) \Rightarrow a_6 = \frac{1}{6!} g'''
 			\end{align*}

 			Y llegamos a la expresión general: $a_{2n} (t) = \frac{1}{(2n)!} g'^{j} (t)$

 			Solución:
 				\[ u(x,t) = \sum_{n=0}^\infty  \frac{1}{(2n)!} g'^{j} (t) x^{2n}\]

 			¿Como elegimos $g$?

 			(DIBUJO)

 			\[ g(t) = \begin{cases}
 				0,& t \leq 0 \\
 				e^{-t^{-\alpha}},&  t>0
 			\end{cases}\]

 			\[ g \in C^\infty, g'^k(t) \equiv 0, t < 0, g \not\equiv 0\]

 		\subsection{Resultados (parciales) de unicidad}

 			El desarrollo que hemos hecho en Tijonov no funciona bien en el infinito ya que tiene un término de la forma $x^{2n}$.

 			\begin{theorem}[Unicidad de soluciones acotadas]
 				\[\left.\begin{array}{r}
 					u_t - \Delta u = F \\
 					u(x,0) = f
 				\end{array}\right\} \exists M \text{ t.q. } |u(x,t)| < M, \forall x, t \]

 				Si $u_1, u_2$ soluciones de este problema $\Rightarrow u_1 = u_2$
 			\end{theorem}

 			\begin{proof}
 				Definimos $v = u_1 -u_2$ y tenemos el siguiente problema:

 				\[\begin{cases}
 					v_t - \Delta v = 0\\
 					v(x,0) = 0
 				\end{cases}  \quad\quad |v| < M\]

 				Tenemos $-\Delta u = 0$ en $\real^n$, es decir, $u$ está acotada. Intentaremos acotarla y ver que podemos hacerlo con la $v$ también.

 				\[ W(x,t) = \alpha (2t + \frac{\| x\|^2}{N}) …\]

 				(DIBUJO)

 				(FALTA)

 				(DIBUJO FRONTERA PARABÓLICA DE $Q_t$)

 				En $t=0$:

 				\[ \|\bar{x}\| \leq R \left. \begin{cases}
 					W(x,0) = \alpha \frac{\|\bar{x}\|^2}{n}\\
 					v(x,0) = 0
 				\end{cases}\right\} \Rightarrow v \leq W \forall \alpha \]

 				\[ \|x\| = R \Rightarrow W(x,t) = \alpha(2t+\frac{R^2}{n}) \]

 				Y entonces ¿ $W \geq v$ si $\|\bar{x}\| = R$?. $v$ acotada $\Rightarrow v \leq M \leq \alpha (2t + \frac{R^2}{n})$ tomando $\frac{\alpha R^2}{n} > M$, por lo que $R^2 > \frac{nM}{\alpha}$

 				Es decir, podemos componer $v, W_\alpha$ es $Q_t = B_R(\bar{0}) \prod [0,T]$, si $R^2 > \frac{nM}{\alpha}$.

 				(DIBUJOS)

 				Conclusión: Fijamos un punto $(x_0,t_0)$.
 					\[v(x_0,t_0) \leq W(x_0,t_0) = \alpha (2t_0+ \frac{\|x_0\|^2}{n})\]

 				Dado un punto cualquiera $(x_0,t_0)$ con $t_0 < T$ tenemos:
 				\[ v(x_0,t_0) \leq \alpha (2 t_0 + \frac{\|x_0\|^1}{n}) \quad \forall \alpha\]

 				Tomando $\alpha \rightarrow 0$:
 				\[v(x_0,t_0) \leq 0 \Rightarrow v \equiv 0\]

 				Por lo que las soluciones son iguales.

 			\end{proof}

 			\begin{theorem}
 				\[\begin{cases}
 					u_t - \Delta u = 0, x \in \real^n, t>0 \\
 					|u(x,t)| \leq A ea^{\|x\|^2} \\
 					u(x,0) = 0
 				\end{cases}\]

 				Entonces $u(x,t) \equiv 0$

 			\end{theorem}

 			\begin{proof}
 				Vamos a demostrar algo más general:

 				\[\begin{cases}
 					v_t - \Delta v = 0 \\
 					|v(x,t)| \leq A ea^{\|x\|^2} \\
 					v(x,0) = g(x) \text{ (ACOTADA)}
 				\end{cases}\]

 				Es decir, que tendremos un principio del máximo: $v(x,t) \leq M \equiv \sup\limits_{x \in \real^n} g(x)$

 				Queremos ponernos entonces en un caso acotado e ir ampliando los límites hasta que estemos en el case no acotado.

 				Definimos la función auxiliar: $\Phi(x,t) = \frac{\mu}{(T+\epsilon -t)^{n/2}} e^{\frac{\|x\|^2}{4(T + \epsilon - t)}}$. Hemos puesto $\epsilon$ en esta función para poder definir $\Phi(x,T)$.

 				Gauss $\to t$, $\Phi \to c - t$, $\lambda = (c-t)^2$. Y podemos comprobar que $\Phi_t$ es solución:
 				\[ \Phi_t - \Delta \Phi = 0\]

 				Nuestro dominio acotado es $Q_t = \{ \|x\| \leq R \} \times [0,T]$.

 				Definimos:
 				\[ W(x,t) = v(x,t) - \Phi(x,t) \]
 				\[ W_t - \Delta W = 0\]

 				Estudiamos $W$ en la frontera parabólica $\delta_p Q_T$.


 				(DIBUJO FRONTERA PARABÓLICA $Q_T$)

 				En $\{(x,0), \|x\| < R\}$
 				\[ W(x,0) = v(x,0) - \Phi(x,0) = g(x) - \Phi(x,0) \leq g(x) \]

 				En $\{(x,t), \|x\| = R, t \in [0,T]\}$
 				\( W(x,t) = v(x,t) - \Phi(x,t) = v(x,t) - \frac{u}{(T + \epsilon - t)^{n/2}} e^{\frac{R^2}{4(T+\epsilon-t)}} \leq Ae^{aR^2} - \frac{\mu}{(T + \epsilon -t)^{n/2}} e^{\frac{R^2}{4(T + \epsilon - t)}} \label{eq:desigualdad_frontera_prueba_1} \)

 				\obs
 				\[ F(s) = \frac{1}{(c-s)^{n/2}} e^{\frac{B}{C-s}}\]
 				\[F'(s) = … > 0\]
 				(falta un pelin)

 				\[ \ref{eq:desigualdad_frontera_prueba_1} \leq e^{aR^2} \{A-\frac{\mu}{(T+\epsilon)^{n/2}} e^{R^2(\frac{1}{4(T+\epsilon)-a})}\} \equiv (*)\eqexpl[\leq]{?} \sup(g)\]

 				Elegimos $T$, tal que $\frac{1}{4(t+\epsilon)}-a > 0$. Por ejemplo, $T = \frac{1}{8a}$, $\epsilon < \frac{1}{8a}$. Hacemos $R \to 0$. Entonces $(*) \to - \infty$

 				\textbf{Conclusión:} $T = \frac{1}{8a}$, $R > R_0 \Rightarrow W(x,t) \leq \sup(g) \equiv M$.

 				El principio del máximo em $Q_T$ nos lleva a una contradicción. Por lo que hemos demostrado que en toda la banda de anchura temporal $(\frac{1}{8a})$, $W(x,t) \leq M$. $W$ era: $v(x,t) - \frac{\mu}{(T + \epsilon -t)^{n/2}} e^{\frac{\|x\|^2}{4(T + \epsilon - t)}} $, para todo $\mu$ mayor que 0.

 				Haciendo tender $\mu$ a 0 entonces $v(x,t) \leq M, x \in \real^n$, $t \in [0,\frac{1}{8a}]$

 				Ahora miramos el mismo problema empezando en $\frac{1}{8a}$:

 				\[\begin{cases}
 					(v_2)_t - \Delta v_2 = 0 \\
 					|v_2(x,t)| \leq A e^{a\|x\|^2} \\
 					v_2(x,\frac{1}{8q}) = v(x,\frac{1}{8a})
 				\end{cases}\]


 				Tenemos un problema con las mismas constantes del anterior, por lo que podemos iterar, empezando en $\frac{2}{8a}$ esta vez. E iterando el argumento llegamos a donde queramos avanzando $\frac{1}{8a}$ en cada paso.

 			\end{proof}

 			\begin{theorem}{Widder}
 				Dadas las condiciones:
 				\[\begin{cases}
 					u_t - \Delta u = 0, x \in \real^n, t > 0 \\
 					u(x,0) = f(x) \geq 0 \\
 					u(x,t) \geq 0 \forall x \forall t \\
 					(u \in C^1 \text{ en } t, C^2 \text{ en } x)
 				\end{cases} \Rightarrow \text{ Si } u_1,u_2 \text{ soluciones, entonces } u_1 \equiv u_2\]
 			\end{theorem}

 			\begin{proof}

 				\proofpart{paso 1}
	 				\[v(x,t) = \int_0^t u(x,s) ds\]

	 				\[ \begin{array}{l}
	 					v_t - \Delta v = 0\\
	 					v \geq 0\\
	 					v_t \geq 0, v \text{ creciente en } t\\
	 					-\Delta v \leq 0 \text{ para t fijo}
	 				\end{array} \quad \Rightarrow (v \equiv 0 \Rightarrow u \equiv 0) \]

 				\proofpart{paso 2: teorema}

 					Teniendo $u_t - \Delta u = 0, x \in \real^n, t > 0$. $u$ es $C^1$ en $t$, $C^2$ en $x$, y $u \geq 0$.

 					\[ \underbrace{\int\limits_{\real^n} G(x-y,t) u(y,0) dy}_{u_G} \leq u(x,t) \]

 				\proofpart{paso 3}

 					Suponiendo que tenemos: \[
 					\begin{cases}
 						u_t - \Delta u = 0, x \in \real^n, t > 0\\
 						u \text{ es } C^1 \text{ en } t, C^2 \text{ en } x\\
 						u \geq 0\\
 						u(x,0) = 0
 					\end{cases}\]

 					Entonces $|u(x,t)| \leq A e^{a\|x\|^2}$ y teniendo en cuenta el paso 1: $u \equiv 0$.

 				\proofpart{final}

 				Todavía no hemos terminado la demostración totalmente ya que no podemos afirmar que la diferencia entre $u$ y $v$ sea positiva. Pero teniendo en cuenta el paso 2: $u$ solución $\Rightarrow u \geq u_G$. Por lo tanto $u - u_G \geq 0$. Finalmente por el paso tres llegamos a $u \equiv u_G$. Cualquier colución es igual a la de Gauss.

 			\end{proof}


\section*{Comentario para las hojas de ejercicios}

Dado un problema como:

\[\begin{cases}
	u_t - K \Delta u = 0, x \in \real^n, t > 0 \\
	u(x,0) = f(x)
\end{cases}\]

1) Rehacer el cálculo de núcleos de Gauss teniendo en cuenta la constante.

2) Cambio de variables:

\begin{gather*}
	v(x,s) = u(x,cs)\\
	\Delta v(x,s) = \Delta u(x,cs)\\
	v_s(x,s) = u_t (x,cs) C
\end{gather*}

\[ v_s (x,s) - \Delta v(x,s) = c u_t (x,cs) - \Delta u(x,cs) = c u_t (x, cs) - \frac{1}{k} u_t (x,cs) \]
\[ u_t - k \Delta u = 0 \Rightarrow - \Delta u = - \frac{1}{k} u_t = (c - \frac{1}{k}) u_t(x,cs) \to C = \frac{1}{k}\]
\[ v(x,s) = u(x,\frac{s}{k}) \text{ es solución de } v_s - \Delta v = 0\]
Con lo que llegamos a que $ v(x,0) = u(x,0) = f(x)$.

Hemos demostrado que sea $v(x,s) = u(x,\frac{s}{k})$. Entonces $v_s - \Delta v = 0 \Leftrightarrow u_t - k \Delta u = 0$

\[ v(x,s) = \int\limits_{\real^n} G(x-y,s) f(y) dy = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi s})^n} e^{-\frac{\|x-y\|^2}{4s}} f(y) dy \]
\[ u(x,\frac{s}{k}) = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi s})^n} e^{-\frac{\|x-y\|^2}{4s}} f(y) dy \]

Como tebemos $\frac{s}{k} = t$:
\[ u(x,t) = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi kt})^n} e^{-\frac{\|x-y\|^2}{4kt}} f(y) dy\]





