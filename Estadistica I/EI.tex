\documentclass{apuntes}

\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{calc, intersections}
\author{Guillermo Julián Moreno}
\date{13/14 C1}


\title{Estad\'{i}stica I}

\begin{document}

\pagestyle{plain}
\maketitle

\tableofcontents
\newpage
\chapter{Estadística descriptiva}
\section{Estadística descriptiva de datos univariantes}

La estadística descriptiva es el conjunto de técnicas para resumir la información proporcionada por una gran masa de datos. El primer objetivo natural es resumir la información que proporcionan esos datos.

\subsection{Estadísticos de tendencia central}

\begin{defn}[Media]

\[ \avg{x} = \frac{\sum_{i=1}^n x_i}{n} \]

Es la medida de tendencia central más utilizada. Es bastante sensible a los valores atípicos (\textit{outliers}), observaciones anormalmente grandes que aparecen en el conjunto de datos por errores de transcripción o medición.
\end{defn}

\begin{defn}[Mediana]
Es el valor que divide a los datos en dos mitades, de tal forma que la mitad son menores y la otra mitad mayores que la mediana. 

La mediana se calcula de la siguiente forma: dado un conjunto de datos $\{x_1,\dotsc, x_n\}$, la mediana es $x_{\frac{n+1}{2}}$ si $n$ es impar y  el promedio entre $x_{\frac{n}{2}}$ y $x_{\frac{n}{2} + 1}$.
\end{defn} 

\subsection{Estadísticos de dispersión}

\begin{defn}[Varianza]
\[ \sigma^2 = \frac{1}{n} \sum_{i=1}^n \left(x_i - \avg{x}\right)^2 = \frac{1}{n} \sum_{i=1}^n x_i^2 - \avg{x}^2 \]
\end{defn}

\begin{defn}[Desviación\IS típica]
\[\sigma = \sqrt{\sigma^2} \]

La desviación típica es la raíz de la varianza.
\end{defn}

\begin{defn}[Cuantil]
Para $p\in (0, 1)$ se llama cuantil $p$ o $q_p$ al valor que deja el $100p \%$ de los datos a la izquierda.
\end{defn}

\begin{defn}[Cuartil]
Los cuartiles son los tres datos que dejan a la izquierda el 25, 50 y 75 por ciento de los datos respectivamente. Es decir:

\begin{itemize}
\item $Q_1 = q_{0.25}$
\item $Q_2 = q_{0.5}$. El cuartil dos es la mediana.
\item $Q_3 = q_{0.75}$
\end{itemize}
\end{defn}

Hay varios métodos para el cálculo de cuantiles. Para hacerlo a mano, podemos usar el siguiente método.

Si el dato en la posición $p(n+1)$ no es un número entero, entonces se interpola entre las observaciones ordenadas que están en la posición $\floor{p(n+1)}$ y $\floor{p(n+1)} + 1$ de la siguiente forma: sea $j$ la parte entera de $p(n+1)$ y $m$ la parte decimal. Entonces, \[ q_p = (1-m)x_j + m x_{j+1} \]


\begin{defn}[Coeficiente\IS de asimetría]
\index{Skewness}
El tercer momento con respecto a la media se define como \[ \frac{1}{n}\sum_{i=1}^n\left(x_i-\avg{x}\right)^3 \] que, en su versión adimensional dividimos por $\sigma^3$.
\end{defn}

Al ser una función cúbica, los valores que se alejen mucho de la media tendrán un valor muy alto en valor absoluto (positivo o negativo según se aleje por la derecha o izquierda, respectivamente). Si la distribución de datos es muy asimétrica, los valores más altos no se cancelan con los valores altos del otro lado (porque no hay) y saldrá un valor más alejado de cero.\footnote{Está explicado como el p. culo, ya.}

\subsection{Representación gráfica de datos}

\begin{defn}[Box-plot]
El diagrama de caja o \textit{box-plot}  (imagen \ref{imgCaja}) nos permite visualizar las medidas de dispersión respecto a la mediana. Hay que añadir una nueva medida, el \textbf{rango intercuartílico}\index{Rango!intercuartílico}, la diferencia entre el primer y el tercer cuartil: \[RI = Q_3 - Q_1 \]

\easyimg{DiagramaCaja.png}{Diagrama de caja}{imgCaja}
\end{defn}

\begin{defn}[Histograma]
El histograma se trata de una aproximación discreta a la función de densidad continua $f(t)$ de la variable que estamos midiendo. Es un diagrama de frecuencias que \textit{mantiene la forma} de esa función de densidad. 

Definimos una serie, las marcas de intervalos $a^n_1, \dotsc, a^n_n$, donde $n$ es el número de intervalos y la longitud de cada intervalo  es $h_n = a^n_{j+1} - a^n_j$. Sea el conjunto $\{x_i\}_{i=0,\dotsc,m}$ los datos de nuestra muestra. Entonces, el estimador, la función $\hat{f}_n$, se define de la siguiente forma:

\[ \hat{f}^n(t) = \frac{\card{i \tq x_i \in \left( a_j^n, a_{j+1}^n \right]}}{n h_n} = \frac{\sum_{i=1}^m \ind_{(a_j^n, a_{j+1}^n]} (x_i)}{n h_n} \]

Recordemos que \[ \ind_A (n) = \begin{cases} 1 & n \in A \\ 0 & n \notin A\end{cases}\]

A grandes rasgos, lo que hace en una función es definir un número de intervalos fijos de ancho $h_n$. Al evaluar $\hat{f}^n(t)$ buscamos en qué intervalo cae $t$ y contamos cuántas de nuestras mediciones caen también en ese intervalo.

\easyimg{DensidadAHistograma.png}{El histograma es una aproximación de la función de densidad real en base a la muestra que hemos obtenido.}{lblDensidad}

\end{defn}

\subsubsection{Estimadores núcleo o kernel}
\label{secEst}
\begin{defn}[Método de ventana móvil][Ventana móvil]
El método de ventana móvil nos da una estimación de la función de densidad en un punto $t$ midiendo los $x_i$ que están en el intervalo de radio $h_n$ centrado en $t$. Matemáticamente:

\[ \hat{f}_n(t) = \frac{1}{n2h_n}\sum_{i=1}^n \ind_{[t-h_n, t+h_n]}(x_i) = \frac{1}{n2h_n}\sum_{i=1}^n \ind_{[-1,1]}\left(\frac{t-x_i}{h_n}\right) \]
\end{defn}

Podemos reemplazar la función $\frac{1}{2}\ind_{[-1, 1]}$ por otra, llamada la función de densidad $K$, kernel o núcleo:

\begin{defn}[Estimador\IS núcleo]
Dada una función de densidad $K$ simétrica, no necesariamente positiva, definimos el estimador kernel como:

\[ \hat{f}_n(t) = \frac{1}{n}\sum_{i=1}^n K_h (t - x_i)  = \frac{1}{nh_n} \sum_{i=1}^n K\left(\frac{t-x_i}{h_n}\right) \]

con $K_h(x) = \frac{1}{h}K(\frac{x}{h})$.
\end{defn}

La elección del núcleo $K$ no afecta especialmente a lo bien aproximada que esté la función de densidad. Sin embargo, sí que influye la selección de la ventana $h_n$ (figura \ref{lblSuavizado}), también llamada \textit{bandwith} en inglés.  Si escogemos una ventana muy pequeña, damos demasiado peso a los datos de nuestra muestra. Si elegimos una ventana muy grande, nuestra muestra pierde importancia y podemos perder información importante.

La elección del $h_n$ más habitual es el que minimiza la distancia $L^2$ entre $\hat{f}$ y $f$, es decir, el parámetro que minimice $\displaystyle\int\left(\hat{f}_h-f\right)^2$. Sin embargo, hay un problema: no sabemos qué es $f$. Hay trucos que imagino que veremos más tarde.

\easyimgw{Suavizado.png}{Los efectos que causa elegir una ventana más grande o más pequeña en el estimador}{lblSuavizado}{1}

Las funciones kernel más usadas son la uniforme, $\frac{1}{2}\ind_{[-1, 1]}$, la gaussiana $\frac{1}{\sqrt{2 \pi}}e^{-\frac{t^2}{2}}$ y la de Epanechnikov, que matemáticamente es la que mejor aproxima $f$.

El estimador kernel $\hat{f}_n(t)$ es la función de densidad de una medida de probabilidad que es la convolución \footnote{Ya aprenderemos en al algún momento de nuestra vida qué narices es una convolución} de dos medidas de probabilidad: una, $K_h(x)$ (el kernel reescalado) y otra que da probabilidad $\frac{1}{n}$ a cada punto de la muestra $\{x_i\}$ (distribución o medida empírica).

\paragraph{Generación de datos del estimador kernel} Supongamos que $K$ es el núcelo gaussiano. Podemos generar datos artificiales de la densidad así:

\[ x_i^0 = x_i^* + h_n Z_i,\; i=1,\dotsc, k \]

donde $x_i^*$ es una observación elegida al azar entre los datos originales y $Z_i$ una observación aleatoria con probabilidad $N(0,1)$. Es decir, lo que hacemos es añadir un dato aleatorio de la muestra y sumamos una pequeña perturbación aleatoria.

\section{Estadística descriptiva de datos bivariantes}

En esta sección estudiaremos dos variables $(X, Y)$ para explorar la relación entre ambas y tratar de inferir si existe una relación funcional para predecir los valores de una variable en función de los de la otra.

\subsection{Representación gráfica}

\begin{defn}[Diagrama\IS de dispersión]
El diagrama de dispersión representa cada variable en función de la otra para que podamos ver la posible relación entre ambas. Ver figura \ref{lblDispersion}.

\easyimg{Dispersion.png}{Diagrama de dispersión}{lblDispersion}
\end{defn} 

\subsection{Regresión}

\begin{defn}[Recta de regresión]

La recta de regresión de $y$ sobre $x$ es la recta de forma $\hat{y} = \hat{a} + \hat{b}x$ que más se aproxima a los datos, minimizando los cuadrados de la distancia: \[ (\hat{a},\hat{b}) =\argmin_{a, b} \sum_{i=1}^n\left(y_i - a - bx_i)\right)^2 \]
\end{defn}

La recta de regresión se calcula obteniendo primero $\hat{b}$:

\[ \hat{b} = \frac{\sigma_{x,y}}{\sigma^2_x} \]

donde \[ \sigma_{x,y} = \frac{1}{n} \left( \sum_{i=1}^n x_i y_i\right)  - \avg{x}\avg{y} \] y después, sabiendo que la recta pasa por el punto $(\avg{x}, \avg{y})$, obtenemos $\hat{a}$ \[ \hat{a} = \avg{y} - \hat{b}\avg{x} \]

El valor $b$ se denomina \textbf{coeficiente de regresión lineal}\index{Regresión lineal!coeficiente de} o parámetro de la regresión. Cada valor $e_i= y_i - \hat{y}_i$ se denomina \textbf{residuo}\index{Residuo}. Hay que notar que

\begin{gather*}
 \sum_{i=1}^n e_i = \sum_{i=1}^n \left(y_i - \hat{a} -\hat{b}x_i \right)= \sum_{i=1}^n\left( y_i - (\avg{y} - \hat{b}\avg{x}) - \hat{b}x_i \right) = \\
 = \sum_{i=1}^n  \left(y_i - \hat{b}x_i\right) - n\avg{y}  + n\hat{b}\avg{x} = n\avg{y} - n \hat{b}\avg{x}- n\avg{y} + n\hat{b}\avg{x} = 0 \end{gather*}

Esta ecuación ($\sum_{i=1}^n e_i = 0$) junto con \[ \sum_{i=1}^n x_i e_1 = 0 \] son las dos restricciones entre los residuos que nos dan la recta.

\begin{defn}[Varianza\IS residual]
La varianza residual $s_R^2$ o $\hat{\sigma}_e^2$ mide, aproximadamente el \textit{error cuadrático} cometido en la aproximación dada por la recta de regresión:

\[ s_R^2 = \hat{\sigma}_e^2 = \frac{1}{n}\sum_{i=1}^n e_i^2 \]
\end{defn}

\begin{defn}[Coeficiente\IS de correlación lineal]
\index{Coeficiente!de Pearson}
El coeficiente de correlación lineal o coeficiente de Pearson

\[ r = \frac{\hat{\sigma}_{x,y}}{\hat{\sigma}_x \hat{\sigma}_y} \] que cumple las siguientes condiciones:

\begin{gather*}
0 ≤ r^2 ≤ 1 \\
\hat{\sigma}_e^2 = \hat{\sigma}_y^2(1-r^2) \\
r = \hat{b}\frac{\hat{\sigma}_x}{\hat{\sigma}_y} 
\end{gather*}

nos indica el grado de ajuste lineal entre las dos variables. Un valor absoluto más cercano a 1 indica una correlación más fuerte. Un valor absoluto cercano a cero indica una correlación débil. El signo, positivo o negativo, indica si la correlación es creciente o decreciente.
\end{defn}


\chapter{Muestreo aleatorio}

La muestra aleatoria de una cierta v.a. $X$ se denomina como la \textbf{muestra aleatoria} o simplemente \textbf{muestra}.\index{Muestra}

Durante este tema, usaremos conceptos de Probabilidad, que repasaré aquí brevemente porque no me apetece escribir demasiado.

\section{Conceptos de probabilidad}

\begin{defn}[Distribución de una v.a.][Distribución]
\[ \prob[X]{B} = \prob{X \in B} \]
\end{defn}

\begin{defn}[Función\IS de distribución]
\[F(t) = \prob{X ≤ t} \]
\end{defn}

\begin{defn}[Media\IS de una distribución] \index{Esperanza} También llamada esperanza de X:
\[ \esp X  = \int_{-\infty}^\infty F(t)\,dt \]
\end{defn}

\begin{theorem}[Teorema\IS de cambio de espacio de integración] Sea $g$ una función real medible tal que $\esp{g(X)}$ es finita, entonces 

\[ \esp{g(X))} = \int_\real g(x) \, dF(x) = \int_\real g(x)\, dP(x) \]. 

En particular \[ µ =\int_\real x\, dF(x)  \] y \[ \sigma^2 = \int_\real \left(x - µ\right)^2 \, dF(x) \]
\end{theorem}

\begin{defn}[Momento] El momento $µ_k$ es la esperanza de X elevado a una potencia de orden $k$. Es el valor esperado de la distancia de orden $k$ con respecto a la media

\[ µ_k = \esp{(X-µ)^k} \]
\end{defn}

\subsection{Distribuciones aleatorias}

Ver apéndice \ref{secDistr} (página \pageref{secDistr}).

\subsubsection{Criterios de convergencia}

Queremos buscar convergencias entre variables aleatorias.

\begin{defn}[Convergencia\IS en distribución]\index{Convergencia!débil}

Se dice que $X_n$ converge débilmente o en distribución a $X$ si la función de distribución de $X_n$ $F_n(x)$ tiende a $F(x)$ para todo $x$ punto de continuidad de $F$, donde $F$ y $F_n$ son las funciones de distribución de $X$ y $X_n$ respectivamente.

Esto es equivalente a decir que  

\[\lim_{n\to\infty} \prob{X_n\in (-\infty, x]} = \prob{X\in (-\infty, x]} \]
Notación:
\[ X_n  \convdist X \text{ ó }  X_n \convs[w] X \] 
\end{defn}

\begin{defn}[Convergencia\IS en probabilidad] 
Se dice que $X_n$ converge en probabilidad a $X$ si $\forall \epsilon > 0$ se tiene que 

\[\prob{\abs{X_n-X} > \epsilon} \convs 0 \].

 Es decir, que para cualquier error que tomemos el error cometido en la aproximación va a tender a cero siempre que tome un $X_n$ suficientemente grande.

Notación: \[ X_n \convprob X \]
\end{defn}

\begin{defn}[Convergencia\IS casi segura] También denotada c.s o a.s en inglés, convergencia en casi todo punto (c.t.p) o convergencia con probabilidad 1. Se dice que $X_n$ converge a $X$ casi seguro si el conjunto de puntos que no son convergentes tiende a ser vacío. Es decir \[ \prob{X_n \convs X} = 1\]

Más estrictamente, la condición se expresa como \[\prob{\omega \in \Omega\tq X_n(\omega) \convs X(\omega)} = 1\]

Notación \[ X_n\convcs X \]
\end{defn}


\begin{theorem}Se puede probar que si $\{X_n\}$ es una sucesión de variables aleatorias y $X$ es variable aleatoria, 

\[ X_n\convcs X \implies X_n \convprob X \implies X_n \convdist X \]
Al contrario no tiene por qué darse.
\end{theorem}


\begin{theorem}[Teorema\IS de Slutsky]\label{thmSlutsky} Sean $\{X_n\}$, $\{Y_n\}$ sucesiones de variables aleatorias tales que $X_n\convdist X$, $Y_n\convprob c$ con $c\in\real$ constante. Entonces

\begin{enumerate}
\item $X_n + Y_n \convdist X + c$
\item $X_n \cdot Y_n \convdist X \cdot c$
\item $\dfrac{X_n}{Y_n}\convdist \dfrac{X}{c}$ si $c≠0$.
\end{enumerate}
\end{theorem}

\subsubsection{Desigualdades básicas}

\begin{theorem}[Desigualdad\IS de Markov]\label{desMarkov} Sea $X$ v.a. Entonces, $\forall \epsilon > 0$, \[ \prob{\abs{X} > \epsilon} ≤ \frac{\esp{X}}{\epsilon} \]
\end{theorem}

\begin{theorem}[Desigualdad\IS de Chebichev] En las mismas condiciones del teorema anterior, se cumple que  \[ \prob{\abs{X - \esp{X}} > \epsilon} ≤ \frac{\var {X}}{\epsilon^2} \]
\end{theorem}

\section{Problema de inferencia}
\subsection{Interpretación estadística de la ley de los grandes números}

\begin{theorem}[Ley\IS de los grandes números] Sea $\{x_k\}$ una sucesión de v.a.i.i.d con media finita $µ$. Se verifica entonces que 
\label{thmGrandes}
\[ \avg{X} = \frac{\sum_{i=1}^n x_i}{n} \convcs µ \]

\end{theorem}

\subsection{Función de distribución empírica}

\begin{defn}[Función\IS de distribución empírica] La función de distribución empírica asociada a la muestra $\{x_n\}$ se define mediante

\[ \prob{X ≤ t} =  \fd_n(t) = \frac{1}{n}\sum_{i=1}^n \ind_{(-\infty, t]} (x_i) \]

Es decir, $\fd_n(t)$ es la proporción de puntos de la muestra que caen en el intervalo $(-\infty, t]$.
\end{defn}

Sin embargo, surge una duda: ¿converge la función de distribución empírica a la función de distribución original?

Intuitivamente, podemos pensar que cuantos más puntos cojamos más se aproximará a la función de distribución original. De hecho, eso es lo que demuestra el siguiente teorema:

\begin{theorem}[Teorema\IS de Glivenko-Cantelli] Sean $\{x_n\}$ v.a.i.i.d con función de distribución $F$. Se verifica que
\label{thmGlivenko}
\[ \md{\fd_n - F}_\infty=\sup_{t\in\real} \abs{\fd_n(t) - F(t)} \convcs 0 \]

donde $\md{\fd_n - F}_\infty$ es el \index{Estadístico! de Kolmogorov-Smirnov} \textbf{estadístico de Kolmogorov-Smirnov}.

\end{theorem}

\begin{proof}
Empezamos demostrando la convergencia de los términos intermedios. Es decir, queremos demostrar que 

\begin{equation}\label{eqConvCsGC}
\fd_n(t) \convcs F(t)
\end{equation} 

Tenemos que \[ \fd_n(t) = \frac{1}{n}\sum_{i=1}^n \ind_{(-\infty, t]} (x_i) \]

A cada uno de los términos de los términos de la suma $\ind_{(-\infty, t]}(x_i)$ los podemos llamar $y_i$. Estos valores son una muestra de la distribución \[ Y = \ind_{(-\infty, t]}(X) \]. Por lo tanto y por la LGN (\ref{thmGrandes}) \[ \fd_n(t) = \frac{1}{n}\sum_{i=1}^n Y_i = \avg{Y} \convcs \esp{Y} \]

pero

\[ \esp{Y} = \esp{\ind_{(-\infty, t]}(X)} = \prob{X\in (-\infty, t]} = F(t) \] por lo tanto hemos demostrado (\ref{eqConvCsGC}).

Ahora tenemos que demostrar que el límite por la izquierda converge. Es decir, hay que demostrar que \begin{equation}
 \fd_n(t^-) \convcs F(t^-)  \label{eqConvIzq}
\end{equation}. Esa convergencia se da si y sólo si en un conjunto de probabilidad $1$ se tiene que $ \fd_n(t^-) \convs F(t^-) $. Según la definición de límite, esto se da si y sólo si \begin{equation}
 \forall \epsilon > 0\; \exists N \tq n ≥ N \implies \abs{\fd_n(t^-) - F(t^-) } < \epsilon \label{eqLim1} \end{equation}

Sabemos que 
\begin{equation}
	\exists\epsilon >0\tq \fd_n (t^-) = \fd_n (x)\; \forall x \in (t-\delta, t+\delta) \label{eqLim2}
\end{equation}

Seguimos:

\begin{equation}
 F(t^-) = \lim_{x\to t^-} F(x) \dimplies \forall \epsilon > 0 \; \exists \delta > 0 \tq x \in (t - \delta, t) \implies \abs{F(x) - F(t^-)} < \frac{\epsilon}{2}\label{eqLim3} 
\end{equation}

Tomamos $x\in(t-\delta, t)$ con un delta que cumpla tanto la condición en (\ref{eqLim2}) como en (\ref{eqLim3}). Entonces

\[ \abs{\fd_n(t^-) - F(t^-)} =  \abs{\fd_n(x) - F(x) + F(x) - F(t^-)} ≤ \underbrace{\abs{\fd_n(x) - F(x)}}_{(a)} + \underbrace{\abs{F(x) - F(t^-)}}_{(b)} \]

Sabemos que $(a)$ es menor que $\frac{\epsilon}{2}$ por (\ref{eqLim1}) y que $(b)$ también es menor que $\frac{\epsilon}{2}$ por (\ref{eqLim3}), por lo tanto 

\[ \abs{\fd_n(t^-) - F(t^-)}  < \epsilon \]

Buscamos ahora una partición finita de $\real$ dada por $t_0 = -\infty ≤ t_1 ≤ \dotsb ≤ t_k = \infty$ tal que para todo $\epsilon > 0$ se cumpla que $\abs{F(t_i^-) - F(t_{i-1})} ≤ \epsilon$. Lo construimos de forma recursiva: dado $t_{i-1}$ tomamos

\[ t_i =\sup_{z\in\real} \{ F(z) ≤ F(t_{i-1} + \epsilon \} \]

El siguiente paso: para todo $t_{i-1} ≤ t ≤ t_i$ se tiene que 

\[ \fd_n(t) - F(t) ≤ \fd_n(t_i^-) - F(t_i^-) + \epsilon \]

Como $\fd_n$ es no decreciente (es una función de distribución), tenemos también que 

\[ \fd_n(t) - F(t) ≥ \fd_n(t_{i-1}) - F(t_{i-1}) - \epsilon \]

Con estas dos últimas ecuaciones, llegamos a que 

\[ \sup_{t\in\real} \abs{\fd_n(t) - F(t)} ≤ \max\left\lbrace \max_{i=1,\dotsc ,k} \abs{\fd_n(t_i) - F(t_i)},\; \max_{i=1,\dotsc ,k} \abs{\fd_n(t_i^-) - F(t_i^n)} \right\rbrace + \epsilon \]

Por (\ref{eqConvCsGC}), sabemos que $\abs{\fd_n(t_i) - F(t_i)} \convcs 0$, y por lo tanto \[ \max_{i=1,\dotsc ,k} \abs{\fd_n(t_i) - F(t_i)} \convcs 0 \].

De la misma forma, usando (\ref{eqConvIzq}) tenemos que \[ \max_{i=1,\dotsc ,k} \abs{\fd_n(t_i^-) - F(t_i^n)} \convcs 0 \]. Por lo tanto, todo ese máximo enorme vale 0, de tal forma que 

\[ \lim_{n\to\infty} \sup_{t\in\real} \abs{\fd_n(t) - F(t)}  =  \lim_{n\to\infty} \md{\fd_n - F}_\infty ≤ \epsilon \]

para cualquier $\epsilon > 0$ arbitrario que cojamos. Es decir, que \[ \md{\fd_n - F}_\infty=\sup_{t\in\real} \abs{\fd_n(t) - F(t)} \convcs 0 \]
\end{proof}

\section{Estadísticos}

Cuando extraemos una muestra $\{x_n\}$ de $X$ se pueden calcular algunas \textit{medidas resumen}. Cualquiera de ellas se puede expresar matemáticamente como una función $T(x_1,\dotsc,x_n)$ de la muestra. 

\begin{defn}[Estadístico]
Sea $T(x_1,\dotsc,x_n)$ una función cuyo dominio incluye el espacio muestral del vector aleatorio $(X_1, \dotsc, X_n)$. Entonces la variable aleatoria $T$ se denomina \textbf{estadístico}. La única restricción es que un estadístico no puede ser función de un parámetro.
\end{defn}

Como la distribución de $T$ se calcula a partir de la distribución de las variables $X_i$ que constituyen la muestra, la denominaremos distribución de $T$ en el muestreo (\textit{sampling distribution).}

\begin{defn}[Error\IS típico]\index{Error!estándar}
El error estándar o error típico $\sigma$ de un estadístico $T$ es la desviación típica de su distribución en el muestreo. Como en ocasiones depende de alguna cantidad desconocida, también se denomina error típico a una estimación de ese valor.
\end{defn}

En ocasiones, se cumple que $\dfrac{T}{\sigma}$ sigue una distribución t de Student, lo que nos permitirá definir intervalos de confianza.

\subsection{Media muestral y poblacional}

\begin{defn}[Media\IS muestral] La media muestral \[ \avg{X} = \frac{\sum_{i=1}^n X_i}{n} \] se puede expresar de la siguiente forma

\[ \avg{X} = \int_\real x\,d\fd_n(x) \]
\end{defn}

\index{Media!poblacional}
La definición es análoga con la de la \textbf{media poblacional}

\[ µ = \int_\real x \,dF(x) \]

Esto nos da una clave de la estadística: sustituir todo lo que desconozco de la población con su análogo muestral (en este caso, pasamos de la función de distribución teórica a la función de distribución empírica). Sólo quedaría ver si los estimadores que resultan son adecuados.

La media muestral tiene otras relaciones muy importantes con $µ$:

\begin{enumerate}
\item $\avg{X}$ es \index{Estimador!insesgado}\index{Estimador!centrado} \textbf{estimador insesgado o centrado} de µ: $ \esp{\avg{X}} = µ$
\item $\var{\avg{X}} = \dfrac{\sigma^2}{n}$. Como es inversamente proporcional, está claro que cuantos más datos haya mejor nos aproximaremos a lo que queremos estimar.
\end{enumerate}

\begin{theorem}[Teorema\IS central del límite] Suponemos que $\{X_n\}$ son v.a.i.i.d. con media $µ$ y desviación típica $\sigma$ finitas. Entonces
\label{thmCentral}
\[ \sqrt{n}\frac{\avg{X}-µ}{\sigma} \convdist N(0,1) \]

Si denotamos la función de distribución de la normal como \[ \Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}}\] entonces

\[ \forall t\in\real\quad \prob{ \sqrt{n}\frac{\avg{X}-µ}{\sigma} ≤ t } \convs \Phi(t) \]

Por tanto, para $n$ grande se tiene

\[ \prob{\sqrt{n} \left(\avg{X} - µ\right) ≤ x} ≈ \Phi(\frac{x}{\sigma}) \]

\textbf{aunque las $X_i$ no tengan distribución normal.}

\end{theorem}

\subsection{Varianza muestral y poblacional}

Una medida importante de dispersión de una variable aleatoria es la varianza \begin{equation}
 \mathbb{V}(X)=\sigma^2 = \int_\real(x-µ)^2 \,dF(x) \label{eqVarianza}
\end{equation}

\begin{defn}[Varianza\IS muestral]El análogo muestral de $\sigma^2$ es la \textbf{varianza muestral.}. Utilizando el criterio \textit{plugin} en (\ref{eqVarianza})

\[\hat{\sigma}^2_n = \int_\real (x-\avg{X})^2\,d\fd_n(x) = \frac{1}{n}\sum_{i=1}^n(X_i - \avg{X})^2 \]
\end{defn}

\begin{theorem} La varianza muestral cumple lo siguiente

\begin{gather*}
\esp{\hat{\sigma}^2_n} = \frac{n-1}{n}\sigma^2\\
\hat{\sigma}^2_n \convcs \sigma^2
\end{gather*}
\end{theorem}

Por lo tanto, la varianza muestral es un estimador sesgado. No es un problema grande ya que cuando $n\to\infty$ acaba convergiendo a $\sigma^2$ y el sesgo 

\[ \esp{\hat{\sigma}^2_n} - \sigma^2= \frac{n-1}{n}\sigma^2 - \sigma^2 = \frac{-1}{n}\sigma^2 \]

también tiende a cero. Es decir, es \index{Asintóticamente!insesgado} \textbf{asintóticamente insesgado}.

\begin{defn}[Cuasivarianza\IS muestral] En lugar de usar $\hat{\sigma}^2_n$ usamos la cuasivarianza muestral, definida como

\[ S^2 = \frac{n}{n-1}\hat{\sigma}^2_n \] de tal forma que se tiene

\begin{gather*}
\esp{S^2} = \sigma^2 \\
S^2 \convcs \sigma^2 
\end{gather*}
\end{defn}

\subsection{Estadísticos de orden}

\begin{defn}[Estadístico\IS de orden]Dada una muestra $\{X_n\}$, se denotan como \[ X_{(1)} ≤ \dotsb ≤ X_{(n)} \] las observaciones de la muestra ordenadas de menor a mayor, llamados \textbf{estadísticos de orden}. Cuando la distribución de las v.a. es continua, la probabilidad de coincidencia en valores es $0$ y con probabilidad $1$ se tiene que \[ X_{(1)} < \dotsb < X_{(n)} \]
\end{defn}

Los estadísticos de orden pueden utilizarse para definir la mediana o los cuartiles. Sin embargo, podemos usar la función cuantílica para definir mejor estos conceptos.

\begin{defn}[Función\IS cuantílica] La función cuantílica en $p$ es el punto que deja una probabilidad $p$ a la izquierda, de tal forma que una proporción $p$ de los individuos de la población $X$ sería menor que el cuantil poblacional de orden $p$.

La función cuantílica correspondiente a la función de distribución $F$ como la función 



\begin{gather*}
\appl{\inv{F}}{\real}{(0,1)} \\
\inv{F}(p) = \inf \left\lbrace x \tq F(x) ≥ p \right\rbrace 
\end{gather*}
\end{defn}

La función cuantílica nos permite obtener los \textbf{cuantiles poblacionales de orden $p$} \index{Cuantil!poblacional} al valor $\inv{F}(p)$. El análogo es el \textbf{cuantil muestral de orden $p$}, \index{Cuantil!muestral} se define a partir de la función de distribución empírica como $\inv{\fd_n}(p)$.

\chapter{Estimación paramétrica}

En este tema, supondremos que la muestra, absolutamente continua o discreta, con función de densidad o probabilidad $f(.;\theta)$ que es totalmente conocida salvo el valor de un parámetro $\theta$ del cuál sólo se conoce su rango de posibles valores $\Theta$, al que se llama el \textbf{espacio paramétrico.}\index{Espacio!paramétrico}

\section{Estimadores}

\begin{defn}[Estimador] Sean $\{X_n\}$ v.a.i.i.d. con distribución común caracterizada por la función de densidad/masa $f(\cdot;\theta)$, con $\theta$ un parámetro desconocido del que sólo se sabe que pertenece al espacio paramétrico $\Theta \subset \real$.

El \textbf{estimador} es una función medible $\hat{\theta}_n = T_n(X_1,\dotsc, X_n)$ que se utiliza para estimar o aproximar el valor de $\theta$.
\end{defn}

Cuando tenemos una muestra aleatoria $\{X_n\}$, cada $T_n(X_1, \dotsc, X_n)$ es un estimador de $\theta$, una variable aleatoria. Si por el contrario tenemos una serie de observaciones de una muestra $\{x_n\}$ entonces $T_n(x_1,\dotsc,x_n)$ es una \textbf{estimación} de $\theta$.

Podemos evaluar la calidad de un estimador con el \textbf{error cuadrático medio} (ECM):

\[ ECM(T_n) = \esp{(T_n - \theta)^2}\]
-
Si sumamos y restamos $\esp{T_n}$, nos queda que 

\[ ECM(T_n) = \var{T_n} + (\text{sesgo}\, T_n)^2 \]

que nos describe el error cuadrático medio en función de la varianza y del sesgo de $T_n$.

\subsection{Propiedades interesantes de los estimadores}
Buscaremos varias propiedades interesantes de los estimadores:

\index{Estimador!insesgado}
\subsubsection{Ausencia de sesgo} Se dice que un estimador $T_n$ es \textbf{insesgado} \index{Estimador!insesgado} si, siempre que $X_i \sim f(\cdot;\theta)$ se tiene que \[\esp{T_n} = \theta\; \forall \theta \in \Theta \]

\subsubsection{Consistencia}\index{Consistencia!en probabilidad} Se dice que $\{T_n\} = \{ T_n(X_1, \dotsc, X_n) \}$ es consistente en probabilidad si, siempre que $X_i \sim f(.;\theta)$ se tiene que $T_n \convprob \theta \; \forall \theta \in \Theta$.

Si reemplazamos la consistencia en probabilidad por la convergencia casi segura, se obtiene la \textbf{consistencia fuerte} o casi segura. \index{Consistencia!casi segura}\index{Consistencia!fuerte}

Para probar la consistencia fuerte, usaremos el siguiente teorema:

\begin{theorem}[Teorema\IS de la aplicación continua] \label{thmApContinua} Sea $\appl{g}{\real}{\real}$ continua en todo punto de un conjunto $C$ tal que $\prob{X\in C} = 1$, entonces

\begin{itemize}
\item Si $X_n\convdist X$ entonces $g(X_n)\convdist  g(X)$.
\item Si $X_n\convprob X$ entonces $g(X_n)\convprob g(X)$.
\item Si $X_n\convcs X$ entonces $g(X_n)\convcs g(X)$.
\end{itemize}

\end{theorem}
 
Otra forma de probarlo sería usar la desigualdad de Markov (\ref{desMarkov}). Buscamos probar que 

\[ \prob{\abs{T_n - \theta} > \epsilon} \convs 0 \]

entonces

\[ \prob{\abs{T_n - \theta} > \epsilon}   = \prob{(T_n - \theta)^2 > \epsilon^2} \]

que por Markov tenemos que

\[ \prob{(T_n - \theta)^2 > \epsilon^2} ≤ \frac{\esp{T_n-\theta}^2}{\epsilon^2} \]

y entonces sólo nos quedaría probar que $\esp{T_n-\theta}^2 \convs 0$.

También podemos usar condiciones suficientes

\begin{theorem}[Condición\IS de Borel-Cantelli] Si se cumple que 

\[ \sum_{n=1}^\infty \prob{\abs{T_n-\theta} > \epsilon} < \infty\;\forall\epsilon > 0 \]

entonces $T_n \convcs \theta$.
\end{theorem}

Con esta condición, bastaría ver que la probabilidad o la esperanza convergen y automáticamente se cumpliría la condición.

\begin{example} Sean $\{X_n\}$ v.a.i.i.d con distribución uniforme en el intervalo $[0,\theta]$ con $\theta > 0$. Estudiar la consistencia de los siguientes estimadores de $\theta$

\paragraph{a)}

\[ T_n = 2\avg{X} \]

Este estimador se basa en que $\esp{X} = \frac{\theta}{2}$. Esto se estima mediante la media muestral $\avg{X}$, y por lo tanto un estimador razonable sería duplicar esa media muestral: $T_n = 2 \avg{X}$.

Como $T_n$ se expresa como una función continua de la media muestral, por la LFGN y el teorema de la aplicación continua 

\[ T_n = g(\avg{X}) \convcs g(µ) = 2µ = 2\esp{X} = \theta \]

y por lo tanto tiene consistencia fuerte.

\paragraph{b)}

\[ T_n=X_{(n)} = \max \{ X_1,\dotsc,X_n\} \]

Aquí usaremos la segunda herramienta: estudiar la probabilidad que el estimador no se aleja del valor esperado en más de $\epsilon$:

\[ \prob{\abs{T_n - \theta} > \epsilon} = \prob{\abs{X_{(n)} - \theta} > \epsilon} = \prob{\theta - X_{(n)} > \epsilon} = \prob{X_{(n)} < \theta - \epsilon} \]

Si pedimos que el máximo sea mayor que $\theta - \epsilon$, es lo mismo que pedir que lo sean todas las observaciones:

\[ \prob{X_{(n)} < \theta - \epsilon} = \prob{X_1 < \theta - \epsilon, \dotsc , X_n < \theta - \epsilon} \]

Y con esto logramos quitarnos los estadísticos de orden, que nos causan problemas al tratar de seguir con la demostración. Como las variables de la muestra son independientes, podemos expresarlo todo como producto

\[ \prod_{i=1}^n \prob{X_i < \theta - \epsilon} = \left(\frac{\theta - \epsilon}{\theta}\right)^n \]

Esta probabilidad está contenida en el intervalo $(0, 1)$ y por lo tanto converge a cero cuando $n\to \infty$. Entonces, $T_n$ es un estimador de $\theta$ consistente en probabilidad.

Para examinar si se cumple la condición de Borel-Cantelli, examinamos la serie 

\[ \sum_{n=1}^\infty \prob{\abs{T_n - \theta} > \epsilon} = \sum_{n=1}^\infty \left(\frac{\theta - \epsilon}{\theta}\right)^n < \infty \]

se cumple la condición y es un estimador consistente casi seguro.

Si quisiésemos explorar cuál de los dos estimadores es mejor, usaríamos el error cuadrático medio.

\end{example}

\subsubsection{Normalidad asintótica}\index{Asintóticamente!normal}\index{Normalidad!asintótica} Se dice que una sucesión de estimadores $\{T_n\}$ del parámetro $\theta$ es \textbf{asintóticamente normal} con tasa $\sqrt{n}$ si

\[ \sqrt{n} (T_n - \theta) \convdist N(0,\sigma) \]

¿Cómo se puede probar la normalidad asintótica? La herramienta se llama el \textbf{método delta}\label{defMetDelta} \index{Método!delta} y es consecuencia casi inmediata del teorema del valor medio y de las propiedades de la convergencia en distribución: intentaremos expresar el estimador que se propone como una función $C^1$ de la media muestral y aplicar entonces el Teorema Central del Límite (\ref{thmCentral}).

Si llamamos $T_n = g(\avg{X})$ con $g\in C^1$ entonces podemos expresar, con un $µ^\ast$ entre $\avg{X}$ y $µ$

\[ \sqrt{n} (g(\avg{X}) - g(µ)) \underset{TVM}{=} g'(µ^\ast) \sqrt{n}(\avg{X} -µ) \]

Como $\avg{X}\convcs µ$ entonces $µ^\ast \convcs µ$ y por lo tanto y usando el Thm. de la aplicación continua (\ref{thmApContinua}) $g'(µ^\ast)\convcs g'(µ)$. Al final 

\[ g'(µ^\ast) \sqrt{n}(\avg{X} -µ) \convdist N(0, \abs{g'(µ)}\sigma) \]

En general, se habla de normalidad asintótica con tasa $a_n$ si se cumple que \[ a_n (T_n - \theta) \convdist N(0,\sigma) \], con $a_n$ sucesión creciente y mayor que cero.

\subsection{Estimador de máxima verosimilitud (EMV)}

En lo que sigue vamos a suponer que $\{X_n\}$ es una muestra formada por v.a.i.i.d. cuya distribución tiene una función de densidad o de masa $f(.;\theta_0)$ perteneciente a una familia de funciones $\{f(.;\theta) \tq \theta \in \Theta\}$. $\theta_0$ nos indica el valor real, y $\theta$ es un parámetro genérico.

Intuitivamente, lo que pensamos con este método es que la función de masa mide lo verosímil que es que salga un cierto parámetro. 

\begin{defn}[Función\IS de verosimilitud] También llamada \textit{likelihood function}. Dada una muestra fija $\{x_n\}$, se define como

\[ L_n(\theta;x_1,\dotsc,x_n) = L_n(\theta) = \prod_{i=1}^n f(x_i;\theta) \]
\end{defn}

\begin{defn}[Estimador\IS de máxima verosimilitud] También llamado EMV o MLE (\textit{maximum likelihood estimator}) es el argumento que maximiza la función de verosimilitud:

\[ \hat{\theta}_n = \hat{\theta}_n(x,\dotsc,x_n) = \argmax_{\theta\in\Theta} L_n(\theta;x_1,\dotsc,x_n) \]

cuando ese máximo está bien definido.
\end{defn}

Para evitar usar derivadas en un producto potencialmente muy largo, podemos maximizar el logaritmo de la verosimilitud, que es creciente y está bien definido porque la densidad es siempre mayor que cero, y los casos en los que sea cero no los estudiamos porque no ocurren (probabilidad 0).

\subsubsection{Cálculo efectivo}

El valor del estimador se obtiene como solución de la \index{Ecuación!de verosimilitud} \textbf{ecuación de verosimilitud}.

\[ \dpa{}{\theta}\log L_n = \dpa{}{\theta}\sum_{i=1}^n\log f(\theta;x_i) = 0 \]

\paragraph{Ejemplos}

\subparagraph{Distribución de Poisson de parámetro $\lambda$}. Suponemos que $X\sim \text{Poisson}\,(\lambda)$ con $\lambda > 0$, de tal forma que

\[ \prob{X = x} = e ^{-\lambda}\frac{\lambda^x}{x!}; \; x\in \ent^+ \]

Dada una muestra $\{x_n\}$ de $X$. Entonces

\[ L_n(\lambda) = \prod_{i=1}^n f(x_i;\lambda) = \prod_{i=1}^n \prob{X=x} = \prod_{i=1}^n e ^{-\lambda}\frac{\lambda^x}{x!} = e^{-n\lambda}\frac{\lambda^{\sum_{i=1}^nx_1}}{x_1!\dotsb x_n!} \]

Tomamos logaritmos:

\[ \log  L_n(\lambda) = -n\lambda + \log\lambda \sum_{i=1}^n x_i- \log\left(x_1!\dotsb x_n!\right) \]

y derivando

\[ \dpa{}{\lambda}\log  L_n(\lambda)  = -n +\frac{1}{\lambda} \sum_{i=1}^n x_i \]

de tal forma que nos queda \[ \hat{\lambda} = \frac{\sum_{i=1}^n x_i}{n} = \avg{x} \].

En la imagen (\ref{imgPoisson}) vemos cómo las diferentes funciones se aproximan a $\lambda = 1$.

\easyimg{VerosimilitudPoisson.png}{Diferentes funciones de verosimilitud para diferentes muestras de la distribución de Poisson}{imgPoisson}

\subparagraph{Distribución normal de parámetros $µ,\sigma$} Tenemos \[f(x;µ,\sigma) = \frac{1}{\sqrt{2\pi}\sqrt{\sigma^2}}e^{\frac{-1}{2}\frac{(x-µ)^2}{\sigma^2}} \]

La función de verosimilitud es

\[ L_n = \prod_{i=1}^n f(x_i;µ,\sigma) = \frac{1}{(2\pi)^{n/2} (\sigma^2)^{n/2}} e^{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-µ)^2} \]

Tomamos logaritmos:

\[ \log L_n = - \frac{n}{2}\log 2\pi - \frac{n}{2} \log \sigma^2 - \frac{1}{2\sigma^2} \sum_{i=1}^n(x_i-µ)^2 \]

Derivamos con respecto de $µ$

\[ \dpa{\log L_n}{µ} = - \frac{1}{\sigma^2} \sum_{i=1}^n(x_i-µ)(-1) = - \frac{1}{\sigma^2}\left( \sum_{i=1}^nx_i - nµ\right) \]

de tal forma que $\hat{µ} = \avg{x}$.

Hacemos lo mismo con $\sigma$

\[ \dpa{\log L_n}{\sigma} = - \frac{n}{2}\frac{1}{\sigma^2} - \frac{1}{2}\sum_{i=1}^n(x_i-µ)^2 \frac{-1}{\sigma^4} = \frac{1}{2\sigma^2}\left(-n + \sum_{i=1}^n\left(x_i-µ\right)^2\frac{1}{\sigma^2}\right) = 0 \]

y por lo tanto \[\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n(x_i-\avg{x})^2 = \sigma^2 \]

\subparagraph{Distribución Weibull} La función de densidad de la distribución de Weibull, que toma dos parámetros $k$ y $\theta$, es

\[ f(x; \theta, k) = \frac{k}{\theta}\left(\frac{x}{\theta}\right)^{k-1}e^{-\left(\frac{x_i}{\theta}\right)^k}\ind_{[0, \infty)}(x) \]

La función de verosimilitud para los dos parámetros es:

\begin{gather*}
 L_n(k,\theta) = \prod_{i=1}^n f(x_i, \theta, k) = \prod_{i=1}^n \frac{k}{\theta}\left(\frac{x_i}{\theta}\right)^{k-1}e^{-\left(\frac{x_i}{\theta}\right)^k} = \\
 = k^n \theta^{-n}\left(\prod_{i=1}^n x_i\right)^{k-1} \theta^{-n(k-1)} e^{-\frac{1}{\theta^2}\sum_{i=1}^nx_i^k} = k^n\theta^{nk} \left(\prod_{i=1}^n x_i\right)^{k-1} e^{-\frac{1}{\theta^k}\sum_{i=1}^nx_i^k}
 \end{gather*}

Tomamos logaritmos:

\[ \log L = n\log k - nk\log \theta + (k-1)\sum_{i=1}^n\log x_i - \frac{1}{\theta^k} \sum_{i=1}^n \left(\frac{x_i}{\theta}\right)^k\]

y derivamos con respecto de ambas variables

\[ \dpa{\log L}{\theta} = -nk \frac{1}{\theta} - (-k) \theta^{-k-1} \sum_{i=1}^nx_i^k = \frac{k}{\theta}\left(-n + \frac{1}{\theta^k}\sum_{i=1}^nx_k^k\right) = 0 \]

\[ \dpa{\log L}{k} = \frac{n}{k} -n\log\theta + \sum_{i=1}^n \log x_i - \sum_{i=1}^n\left(\frac{x_i}{\theta}^k\right) \log\frac{x_1}{\theta} = 0 \]

Con la primera ecuación, tenemos que

\[ \frac{1}{\theta^k} = \frac{\sum_{i=1}^n x_i^k}{n} \therefore \hat{\theta} = \left(\frac{n}{\sum_{i=1}^n x_i^k}\right)^\frac{1}{k} \]

De la segunda ecuación resulta prácticamente imposible despejar $k$. Sin embargo, podemos usar métodos numéricos para obtener el valor de $k$. 

\begin{theorem}[Invarianza del EMV] Si $\tau$ es una función biyectiva y $\hat{\theta}$ es el e.m.v. de $\theta$, entonces el e.m.v. de $\tau(\theta)$ es $\tau(\hat\theta)$
\end{theorem}

Por ejemplo, tomamos $X\sim N(µ, \sigma)$. Ya habíamos calculado el e.m.v. de la varianza, que era la varianza muestral. ¿Cómo calcular entonces el e.m.v. de la desviación típica? Sabiendo que $\sigma = \sqrt{\sigma^2}$, tomamos $\tau(\theta) = \sqrt{\theta}$ que es una función biyectiva en $\real^+$ y por lo tanto podemos decir que $\text{emv}\,(\sigma) = \sqrt{\hat\sigma^2}$

\subsubsection{Motivación del método}
Estudiamos la siguiente función
\[ \frac{1}{n}\log L_n(\theta) = \frac{1}{n} \log \left(\prod_{i=1}^nf(X_i,\theta)\right) = \frac{1}{n}\sum_{i=1}^n \log f(X_i;\theta) \]

que por la L.G.N. (\ref{thmGrandes}) converge a una función $\Psi(\theta)$ que es el valor esperado de esos logaritmos de las muestras:

\[ \frac{1}{n}\log L_n(\theta) \convcs \Psi(\theta) \]

donde \[ \Psi(\theta) = \mathbb{E}_{\theta_0} \left[\log f(X;\theta)\right] = \int\log f(x;\theta) f(x;\theta_0) \, dx \]

\begin{theorem}[Teorema\IS MV1] \label{thmMV} Sea $X\sim f(.;\theta_0)$. Supongamos que se satisfacen las siguientes condiciones:

\subparagraph{MV0) Parametrización adecuada} Las distribuciones son distintas si el parámetro $\theta$ es distinto.

\subparagraph{MV1) Soporte común} Las distribuciones $f(.;\theta)$ tienen un soporte común. Es decir, que las funciones de densidad o de masa tienen valor distinto de cero en los mismos puntos.

\subparagraph{MV2)} $\Psi(\theta)$ es finita para todo $\theta \in \Theta$.

Entonces $\theta_0$ es el único máximo de la función $\Psi(\theta)$ y además 

\[ \mathbb{P}_{\theta_0} \left\lbrace L_n(\theta_0;X_1,\dotsc,X_n) >  L_n(\theta;X_1,\dotsc,X_n) \right\rbrace \convs 1\; \forall \theta \neq \theta_0 \]

\end{theorem} 

En el teorema se habla del soporte, definámoslo formalmente:

\begin{defn}[Soporte] El soporte de una función de distribución o masa $f$ es el conjunto de puntos en el que el valor de $f$ es distinto de 0. Es decir, \[ \mathrm{soporte}\; f = \{ x \in \real \tq f(x) \neq 0 \} \]
\end{defn}

Para la demostración, primero veremos la siguiente desigualdad:

\begin{theorem}[Desigualdad\IS de Jensen] Supongamos que $X$ es una v.a. tal que $\esp{X}< \infty$ (su esperanza existe y es finita) y que $\varphi$ es una función convexa (como una parábola, más o menos) tal que $\esp{\varphi(X)} < \infty$.

Entonces \[ \esp{\varphi(X)} ≥ \varphi(\esp{X}) \] \label{desJensen}
\end{theorem}

Con esto, podemos pasar a la demostración del teorema (\ref{thmMV}):

\begin{proof} Decir que \[ L_n(\theta_0;X_1, \dotsc, X_n) > L_n(\theta; X_1,\dotsc,x_n) \] es equivalente a que 

\begin{gather*}
\log L_n(\theta_0;X_1, \dotsc, X_n) >\log L_n(\theta; X_1,\dotsc,x_n) \\
\sum_{i=1}^n \log f(X_i;\theta_0) > \sum_{i=1}^n \log f(X_i;\theta) \\
0 > \frac{1}{n}\sum_{i=1}^n \left[\log f(X_i;\theta) - \log f(X_i;\theta_0)\right] = \\
= \frac{1}{n}\sum_{i=1}^n \log \frac{f(X_i;\theta)}{f(X_i;\theta_0)}\convprob \mathbb{E}_{\theta_0}  \left(\log \frac{f(X_i;\theta)}{f(X_i;\theta_0)}\right) =  - \mathbb{E}_{\theta_0}  \left(-\log \frac{f(X_i;\theta)}{f(X_i;\theta_0)}\right) < 0
\end{gather*} 

usando la L.G.N (\ref{thmGrandes}). Aplicando ahora la desigualdad  de Jensen (\ref{desJensen})

\[ - \mathbb{E}_{\theta_0}  \left(-\log \frac{f(X_i;\theta)}{f(X_i;\theta_0)}\right) > - \log  \mathbb{E}_{\theta_0}  \frac{f(X_i;\theta)}{f(X_i;\theta_0)} \]

Entonces \[  \mathbb{E}_{\theta_0}  \frac{f(X_i;\theta)}{f(X_i;\theta_0)} = \int \frac{f(x;\theta)}{f(x;\theta_0)} f(x;\theta_0) \,dx = \int f(x;\theta)\, dx = 1 \] 

y por lo tanto  \[ - \mathbb{E}_{\theta_0}  \left(-\log \frac{f(X_i;\theta)}{f(X_i;\theta_0)}\right) = - \log 1 = 0 \]

Entonces, $\forall \epsilon > 0$ 

\begin{gather*}\prob{\abs{\frac{1}{n} \sum_{i=1}^n \log \frac{f(X_i;\theta)}{f(X_i;\theta_0)} - \mathbb{E}_{\theta_0}\left(\log \frac{f(X;\theta)}{f(X;\theta_0)}\right)} > \epsilon} \convs 0 \dimplies \\
\prob{\abs{\frac{1}{n} \sum_{i=1}^n \log \frac{f(X_i;\theta)}{f(X_i;\theta_0)} - \mathbb{E}_{\theta_0}\left(\log \frac{f(X;\theta)}{f(X;\theta_0)}\right)} ≤ \epsilon} \convs 1
\end{gather*}

Tomo $\displaystyle \epsilon = \frac{1}{2}\abs{\mathbb{E}_{\theta_0}\left(\log \frac{f(X;\theta)}{f(X;\theta_0)}\right)}$ y entonces 

\[ \prob{\frac{1}{n}\sum_{i=1}^n\log\frac{f(X_i;\theta)}{f(X_i;\theta_0)}  <  \frac{1}{2}\abs{\mathbb{E}_{\theta_0}\left(\log \frac{f(X;\theta)}{f(X;\theta_0)}\right)} < 0 } \convs 1 \]
\end{proof}

\subsubsection{Consistencia del método}

\begin{theorem}[Teorema\IS MV2]\label{thmMV2} Supongamos que se cumplen las condiciones del teorema MV1 (\ref{thmMV}) y adicionalmente

\subparagraph{MV3)} El espacio paremétrico $\Theta$ es un intervalo abierto no necesariamente finito y, para casi todo $x$, $f(x;\theta)$ es diferenciable respecto a $\theta$ con derivada continua.

Entonces, con probabilidad tendiente a 1, la ecuación

\begin{equation}
 \dpa{}{\theta} \log L_n (\theta;X_1,\dotsc,X_n) = 0 \label{eqMV2}
\end{equation}
tiene una raíz $\hat\theta_n = \hat\theta_n(x_1,\dotsc,x_n)$ que \textbf{converge en probabilidad a $\theta_0$} (el verdadero valor del parámetro). Si además suponemos que la raíz es única, entonces $\hat\theta_n$ maximiza la verosimilitud $L_n$ y por lo tanto es el estimador de máxima verosimilitud.
\end{theorem}

\begin{proof}
Sea $\epsilon > 0$. Entonces para casi todo\footnote{Casi todo: puntos con probabilidad no nula} $x$ en el intervalo $\Omega = (\theta_0 - \epsilon, \theta_0 + \epsilon)$ se tiene que $f(x;\theta)$ es diferenciable con derivada continua.

\begin{center}
\begin{tikzpicture}
\draw (-4,0) -- (4,0);
\node[fill=white, circle, draw, inner sep=2pt, label=below:$\theta_0 - \epsilon$] at (-2, 0) {};
\node[fill=white, circle, draw, inner sep=2pt, label=below:$\theta_0$] at (0, 0) {};
\node[fill=white, circle, draw, inner sep=2pt, label=below:$\theta_0 +\epsilon$] at (2, 0) {};

\node[fill=black, circle, draw, inner sep=1pt, label=above left:$L_n(\theta_0 - \epsilon)$] (A) at (-2, 0.8) {};
\node[fill=black, circle, draw, inner sep=1pt, label=above:$L_n(\theta_0)$] (B) at (0, 1.3) {};
\node[fill=black, circle, draw, inner sep=1pt, label=above right:$L_n(\theta_0 +\epsilon)$] (C) at (2, 0.6) {};
\end{tikzpicture}
\end{center}

Cogemos entonces un conjunto $S_n$ definido de la siguiente forma:

\begin{align*}
S_n = \{ (x_1,\dotsc,x_n) &\tq L_n(\theta_0;x_1, \dotsc,x_n) > L_n(\theta_0 - \epsilon; x_1, \dotsc, x_n) \\
&\y  L_n(\theta_0;x_1, \dotsc,x_n) > L_n(\theta_0 + \epsilon; x_1, \dotsc, x_n) \} 
\end{align*}

Aplicando el teorema MV1 (\ref{thmMV}), tenemos que $\mathbb{P}_{\theta_0}(S_n) \convs 1$. 

En algún punto del interior del intervalo $\Omega$ hay un máximo local. Como puede haber varios máximos locales, tomo $\hat\theta_n$ como el punto de máximo local más cercano a $\theta_0$. 

Se cumple que cada uno de esos puntos de máximo satisfacen la ecuación de verosimilitud (\ref{eqMV2}). En consecuencia $\hat\theta_n$ satisface también esa misma ecuación. Por lo tanto

\[ \prob{\abs{\hat\theta_n - \theta_0} < \epsilon} \convs 1 \dimplies \prob{\abs{\hat\theta_n - \theta_0} ≥ \epsilon} \convs 0 \]

y entonces

\[ \hat\theta_n \convprob \theta_0 \]
\end{proof}

\subsubsection{Información de Fisher}

Supongamos el conjunto de todos los estimadores de un parámetro $\theta$. Su error cuadrático medio es 

\[ \ECM \hat\theta = \var{\hat\theta} + \sesgo^2 \hat\theta \]

Si queremos buscar el \textit{mejor} estimador, buscamos los que minimicen el ECM. Por lo tanto, nos interesaremos en el subconjunto de estimadores insesgados ($\sesgo \hat\theta = 0$). Sin embargo, no tenemos una forma clara de distinguir cuál es mejor entre esos estimadores insesgados. En esta sección vamos a buscar una \textit{escala}, a la que llamaremos la \textbf{información de Fisher}, que nos dará una cota para la varianza de un estimador. 

Suponemos que en la integral $\int f(x;\theta)\,dx$ se puede derivar dos veces bajo el signo integral (esto es, que $\int \frac{∂^2}{∂\theta^2} f(x;\theta)\,dx$ existe) y que además se puede permutar la integral y la derivada parcial (vemos condiciones suficientes en el apéndice \ref{secConds}, página \pageref{secConds}). Entonces

\[ \int f(x;\theta)\, dx = 1 \implies \dpa{}{\theta} \int f(x;\theta)\,dx = 0 \]

Por tanto

\[ \int \dpa{}{\theta}(\log f(x;\theta) ) f(x;\theta) \, dx = \mathbb{E}_\theta\left(\dpa{}{\theta}\log f(X;\theta)\right) = 0 \]

Si derivamos de nuevo en la integral

\begin{gather*}
\frac{∂^2}{∂\theta^2} \int f(x;\theta)\,dx = 0  = \int \frac{∂^2}{∂\theta^2} f(x;\theta)\,dx = \\
=\int \frac{∂^2}{∂\theta^2} \log f(x;\theta) f(x;\theta)\,dx + \int\dpa{}{\theta} \log f(x;\theta) \cdot \dpa{}{\theta}f(x;\theta)\,dx = \wtf \\
=\int \frac{∂^2}{∂\theta^2}\log f(x;\theta) f(x;\theta)\, dx + \int \left(\dpa{}{\theta}\log f(x;\theta)\right)^2 f(x;\theta)\,dx = \\
= \mathbb{E}_\theta \left[\frac{∂^2}{∂\theta^2}\log f(X;\theta) \right] 
	+ \mathbb{E}_\theta \left[ \left(\dpa{}{\theta} \log f(X;\theta)\right)^2\right] = 0
\end{gather*}

El segundo valor se llama información de Fisher:
\begin{defn}[Información\IS de Fisher] Se denota por $I(\theta)$ la información de Fisher del parámetro $\theta$

\[ I(\theta) =\left[\left(\dpa{}{\theta} \log f(X;\theta)\right)^2\right] \]

Representa intuitivamente la \textit{cantidad de información} acerca del valor del parámetro $\theta$ contenida en una observación de $X$.
\end{defn}

¿En qué consiste esa cantidad de información? Tomemos, por ejemplo, una normal $N(0,\theta)$ con $\theta$ pequeña. Una observación $X$ que hagamos nos dará mucha información sobre el modelo, ya que todos los valores de la normal están muy agrupados, y por lo tanto $I(\theta)$ será grande. Si tomamos $\theta$ grande, una observación $X$ no nos dará mucha información sobre el modelo porque los valores están más dispersos, y por lo tanto tendremos un valor de $I(\theta)$ pequeño.

La información de Fisher nos da una cota inferior para la varianza.

\begin{theorem}[Cota\IS de Fréchet-Cramér-Rao] Dado $\hat\theta$ un estimador insesgado de $\theta$, entonces
\label{thmCotaFCR}
\[ \var{\hat\theta} ≥ \frac{1}{nI(\theta)} \]

donde $\frac{1}{nI(\theta)}$ se llama la \textbf{cota de Fréchet-Cramér-Rao}.
\end{theorem}

\begin{proof} Tomamos la v.a. $Z$ como la derivada del logaritmo de la verosimilitud

\[ Z = \dpa{}{\theta}\log L_n (X,\theta) = \sum_{i=1}^n \dpa{}{\theta} \log f(X_i;\theta) \]

La desigualdad de Cauchy-Schwartz establece que \footnote{Por ejemplo, porque no tengo ni idea de dónde sale esto.}

\[ \var[\theta]{T_n} ≥ \frac{\text{Cov}_\theta^2 (Z,T_n)}{\var[\theta]{Z}} \]

Veremos que el numerador vale 1 si $T_n$ es un estimador insesgado, y que $\var[\theta]{Z} = n I(\theta)$.

Primero observamos que

\[ \esp[\theta]{Z} = \sum_{i=1}^n \esp{\frac{∂}{∂\theta} \log f(X_i;\theta)} = 0 \]

Y la varianza

\[ \var[\theta]{Z} = \sum_{i=1}^n \var[\theta]{\frac{∂}{∂\theta} \log f(X_i;\theta)} = \sum_{i=1}^n \esp{\left(\dpa{}{\theta} \log f(X;\theta)\right)^2}[\theta] = n I(\theta) \]

La primera parte está demostrada.

Ahora vemos que, si $\esp[\theta]{Z} = 0$, entonces

\[ \text{Cov }(Z,T_n) = \esp[\theta]{ZT_n} - \underbrace{\esp[\theta]{Z}}_0 \esp[\theta]{T_n} = \esp[\theta]{ZT_n}  \]

Como $Z$ y $T_n$ dependen de la muestra

\[ \esp[\theta]{ZT_n} = \esp[\theta] {Z(X_1,\dotsc,X_n) \cdot T_n(X_1,\dotsc,X_n)}= \int_{\real^n} Z(x_1,\dotsc,x_n) \cdot T_n(x_1,\dotsc,x_n) \cdot f_\theta(x_1,\dotsc,x_n)\,d(x_1, \dotsc, x_n) \]

Como las $X_1,\dotsc,X_n$ son independientes, 

\[ f_\theta(x_1,\dotsc,x_n) = \prod_{i=1}^nf(x_i;\theta)\ \]

y la integral nos queda entonces como una serie de integrales iteradas

\[ \int_\real \dotsb \int_\real Z(x_1,\dotsc,x_n) \cdot T_n(x_1,\dotsc,x_n)  \prod_{i=1}^nf(x_i;\theta)\,dx_i \]

Vemos cuánto vale $Z$:

\[ Z = \dpa{}{\theta}\log f(x_i;\theta) = \sum_{i=1}^n \frac{\dpa{}{\theta}f(x_i;\theta)}{f(x_i;\theta)} \]

Pero 

\[ \sum_{i=1}^n \frac{\dpa{}{\theta}f(x_i;\theta)}{f(x_i;\theta)}  \prod_{i=1}^nf(x_i;\theta)\,dx_i  = \sum_{i=1}^n\left[ \dpa{}{\theta}f(x_i;\theta \cdot \prod_{\substack{j=1\\j\neq i}}^n f(x_j;\theta) \right] \]

que por la regla de la cadena es igual a 

\[ \dpa{}{\theta}\left[\prod_{i=1}^n f(x_i;\theta) \right] \]

y entonces nos queda que

\begin{gather*}
\cov (Z,T_n) = \esp[\theta]{ZT_n} = \int_\real \dotsc \int_\real T_n(x_1,\dotsc,x_n) \dpa{}{\theta} \prod_{i=1}^n f(x_i;\theta)\, dx_i = \\
 = \dpa{}{\theta} \int_\real \dotsc \int_\real T_n(x_1,\dotsc,x_n) \prod_{i=1}^n f(x_i;\theta)\, dx_i =\\
 = \dpa{}{\theta} \esp[\theta]{T_n} 
 \end{gather*}

Como $T_n$ es un estimador insesgado $\esp[\theta]{T_n}  = \theta$ y entonces $\text{Cov}\,(Z,T_n) = 1$. Por lo tanto, nos queda que 

\[ \var{\hat\theta} ≥ \frac{1}{nI(\theta)} \]

Además, si $T_n$ no fuese un estimador insesgado

\[ \var{\hat\theta} ≥ \frac{\left(dpa{}{\theta} \esp[\theta]{T_n} \right)^2}{n I(\theta)} \]

y por lo tanto

\[ \text{ECM}(T_n) ≥ \frac{\left(\dpa{}{\theta} \esp[\theta]{T_n}\right)^2}{n I(\theta)} + \text{Sesgo }^2 (T_n) \]

\end{proof}

\begin{defn}[Estimador\IS eficiente] Se dice que un estimador es eficiente si su varianza es igual a la cota de Fréchet-Cramér-Rao (\ref{thmCotaFCR}), es decir
\[ \var{\hat\theta} = \frac{1}{nI(\theta)} \]
\end{defn}


\subsubsection{Eficiencia asintótica}
\begin{theorem}[Teorema\IS MV3] Supongamos que se verifican las condiciones MV0 - MV3 (ver teoremas \ref{thmMV}, \ref{thmMV2}) y además:

\subparagraph{MV4)} La integral $\int f(x;\theta)\,dx$ se puede derivar dos veces bajo el signo integral.
\subparagraph{MV5)} Para cada $x$ la densidad $f(x;\theta)$ es tres veces diferenciable con respecto a $\theta$, con la tercera derivada continua en $\theta$.
\subparagraph{MV6)} La información de Fisher es estrictamente positiva y finita: $0 < I(\theta_0) < \infty$
\subparagraph{MV7)} Para cada $\theta_0\in \Theta$ existen un número $c > 0$ y una función $M(x)$, que pueden depender de $\theta_0$, tales que \[ \esp[\theta_0]{M(X)} < \infty \] y \[ \abs{\frac{∂^3\log f}{∂\theta^3}(x;\theta)} ≤ M(x)\; \forall x;\;\forall\theta \in (\theta_0 - c,\theta_0 + c) \]
\end{theorem}

\begin{proof}

\begin{gather}
 \tilde\Psi_n(\theta) = L_n  \\
 \tilde\Psi_n' = \dpa{\Psi_n(\theta)}{\theta} \label{eqT3_2} \\
 f' = \dpa{f}{\theta}f
 \end{gather}
 
 donde la función \ref{eqT3_2} se llama el \textbf{score} (quizás).
 
 Recordemos que $\hat\Psi_n(\theta)$ depende de la muestra. Para cada muestra fija se tiene
 
 \[ \tilde\Psi_n(\hat\theta_n) = \hat\Psi_n'(\theta_0) + (\hat\theta_n-\theta_0)\Psi_n''(\theta_0) + \frac{\left(\hat\theta_n-\theta_0\right)^2}{2}\tilde\Psi_n'''(\theta_n^\ast) \]

Para algún $\theta_n^\ast$ entre $\hat\theta_ n$ y $\theta_0$. Como el primer miembro es 0, resulta

\[ \sqrt{n}\left(\hat\theta_n-\theta_0\right) = \frac{\frac{1}{\sqrt{n}}\tilde\Psi_n'(\theta)^2}{-\frac{1}{n}\Psi_n''(\theta_0) - \frac{1}{2n}\left(\hat\theta_n-\theta_0\right)\tilde\Psi_n'''(\theta_n^\ast)} \]

Vamos a demostrar que esto converge en tres pasos:

\begin{itemize}
\item Numerador converge a $N(0,\sqrt{I(\theta_0)}$.
\item Primera parte converge a $I(\theta_0)$.
\item Segunda parte denom. converge a 0 en prob.
\end{itemize}

Usando además el teorema de Slutsky (\ref{thmSlutsky}), que nos dice que NO DICE NADA PORQUE LO HA BORRADO.

\paragraph{Parte 1: Numerador}

\[ \frac{1}{\sqrt{n}}\tilde\Psi_n'(\theta_0) = \frac{\sqrt{n}}{n}\sum_{i=1}^n \left[\frac{f'(X_i;\theta_0)}{f(X_i;\theta_0)} - \esp[\theta_0]{\frac{f'(X_i;\theta_0)}{f(X_i;\theta_0)}}\right] \]

Como $\esp[\theta_0]{\frac{f'(X_i;\theta_0)}{f(X_i;\theta_0)}} = 0$ (vete tú a saber por qué), la aplicación del TCL (\ref{thmCentral}) a las variables $Y_i = \frac{f'(X_i;\theta_0)}{f(X_i;\theta_0)}$ y la definición de $I(\theta_0)$ proporcionan directamente

\[ \frac{1}{\sqrt{n}}\hat\Psi_n'(\theta_0) \convdist N(0,\sqrt{\var{Y}}) \]

Calculamos ahora esa desviación típica:

\begin{gather*}
 \var[\theta]{Y} = \esp[\theta]{Y^2} - \esp[\theta]{Y}^2 = \esp[\theta]{Y^2} = \\
 = \esp[\theta]{\left(\dpa{}{\theta}\log f(X;\theta)\right)^2} = I(\theta)
\end{gather*}

Y por lo tanto nos queda que 

\[ \frac{1}{\sqrt{n}}\hat\Psi_n'(\theta_0) \convdist N\left(0,\sqrt{I(\theta_0)}\right) \]

\paragraph{Parte 2: Denominador A}

Operamos con

\[ -\frac{1}{n}\Psi_n''(\theta_0) \]

Si derivamos de nuevo $\tilde\Psi_n''$ con respecto a $\theta$ tenemos que 

\[ \tilde\Psi_n''(\theta) = \sum_{i=1}^n \frac{f''(x_i;\theta)f(x_i;\theta) - \left(f'(x_i;\theta)\right)^2}{f^2(x_i;\theta)} \]

Entonces $\frac{1}{n}\Psi_n''(\theta_0)$ es un promedio, y por la LGN (\ref{thmGrandes}) 

\begin{align*}
- \frac{1}{n}\Psi_n''(\theta_0) & \convprob - \esp[\theta_0]{\frac{f''(x_i;\theta)f(x_i;\theta) - \left(f'(x_i;\theta)\right)^2}{f^2(x_i;\theta)}} =\\ & =\underbrace{\esp[\theta_0]{\left(\frac{f'(X_i;\theta_0)}{f(X_i;\theta_0)}\right)^2}}_{I(\theta_0)}- \esp[\theta_0]{\frac{f''(X_i;\theta_0)}{f(X_i;\theta_0)}} 
\end{align*}

Operamos ahora con la segunda parte 

\begin{gather*}
\esp[\theta_0]{\frac{f''(X_i;\theta_0)}{f(X_i;\theta_0)}} = \int_\real \frac{f''(X_i;\theta_0)}{f(X_i;\theta_0)}f(X_i;\theta_0)\,dx = \\
= \int_\real \left.\frac{∂^2}{∂\theta^2}f(x;\theta)\right|_{\theta=\theta_0}\,dx 
\end{gather*}

y como según el enunciado del teorema podemos permutar la derivada con la integral dos veces, tenemos que

\[ \int_\real \left.\frac{∂^2}{∂\theta^2}f(x;\theta)\right|_{\theta=\theta_0}\,dx =  \left.\frac{∂^2}{∂\theta^2}\int_\real f(x;\theta)\,dx\right|_{\theta=\theta_0} = \left.\frac{∂^2}{∂\theta^2}0\right|_{\theta=\theta_0}  = 0 \]

Por lo tanto

\[ - \frac{1}{n}\Psi_n''(\theta_0) \convprob I(\theta_0) \]

\paragraph{Paso 3: Algo}

\[\frac{1}{2n}\left(\hat\theta_n-\theta_0\right)\tilde\Psi_n'''(\theta_n^\ast) \convprob 0 \]

Por hipótesis del teorema, $\hat\theta_n$ se considera consistente y entonces \[ \left(\hat\theta_n-\theta_0\right) \convs 0 \]. Analizaremos ahora la segunda parte de esa ecuación, $\tilde\Psi_n'''(\theta_n^\ast)$, y demostraremos que tiende a una constante.

\[ \tilde\Psi_n'''(\theta_n^\ast) = \frac{1}{n}\sum_{i=1}^n \frac{∂^3}{∂\theta^3}\log f(X_i;\theta) \]

Como $\hat\theta_n$ es consistente, $\theta_n^\ast$, que es un punto intermedio entre $\hat\theta_n$ y $\theta_0$, también tiende a $\theta_0$ en probabilidad. Entonces podemos aplicar la hipótesis MV7 del teorema y acotar la derivada parcial:

\[ \abs{\frac{∂^3}{∂\theta^3}\log f(X_i;\theta)} ≤ M(X_i) \]

y por lo tanto podemos acotar en probabilidad

\[ \abs{\tilde\Psi_n'''(\theta_n^\ast)} < \frac{1}{n}\sum_{i=1}^n M(X_i) \] 

Este término converge a una constante por lo tanto, y entonces se cumple que 

\[\frac{1}{2n}\left(\hat\theta_n-\theta_0\right)\tilde\Psi_n'''(\theta_n^\ast) \convprob 0 \]
\end{proof}


\subsection{Método de los momentos}
\index{Estimador!por el método de los momentos}
Sea $X\sim f(x;\theta)$, donde $\theta = (\theta_1,\dotsc,\theta_p)$ es un parámetro p-dimensional, con $p≥1$. 

Si los momentos $\alpha_k(\theta) = \esp[\theta_0]{X^k},\;k=1,\dotsc,p$ son funciones sencillas de los $\theta_i$, un procedimiento natural para obtener un estimador de $\theta$ es resolver en $\theta_1,\dotsc,\theta_p$ el sistema de ecuaciones

\begin{gather*}
m_1 = \alpha_1(\theta) \\
\dotsb \\
m_p = \alpha_p(\theta) 
\end{gather*}

donde cada $m_k$ es el momento muestral:

\[ m_k = \frac{\sum_{i=1}^n X_i^k}{n} \]

La idea es estimar el parámetro de tal forma que los momentos muestrales coincidan con los momentos poblacionales. Por la LGN, cuando $n\to\infty$ entonces $m_k \to \alpha_k(\theta_0)$. 

El método de los momentos se utiliza poco ya que da peores estimadores que el EMV. Sin embargo, puede resultar muy útil en casos en los que el EMV se calcula difícilmente o directamente no se puede calcular. Ahí hay que usar métodos numéricos de aproximación, y usando el método de los momentos podemos encontrar una primera aproximación que mejore la convergencia de los algoritmos numéricos de búsqueda de raíces.

\subsubsection{Ejemplos}

Si se tiene el modelo \[f(x;\theta) = \frac{1+\theta x}{2}\ind_{[-1,1](x)}\,\theta\in[-1,1] \] no es sencillo calcular el EMV pero sí obtener el estimador por el método de los momentos:

\[ \esp[\theta]{X} = \int_{-1}^1 x f(x;\theta)\,dx = \frac{\theta}{3} \]

Por tanto, la solución de $\avg{X} = \esp[\theta]{X}$ es $\tilde\theta_n = 3\avg{X}$, cuya varianza es 

\[ \var[\theta]{\tilde\theta_n} = \var[\theta]{3\avg{X}} = 9\frac{\sigma^2}{n} = \frac{3-\theta^2}{n} \]

ya que \[ \sigma^2 = \var[\theta]{X}= \esp[\theta]{X^2} - \esp[\theta]{X}^2 = \frac{1}{3}-\frac{\theta^2}{9} \]. Este estimador es consistente ya que, por la LGN, $3\avg{X} \convs 3\esp[\theta]{X}$.

Supongamos un ejemplo más complicado: $X\sim Beta(a,b)$.

\[ f(x;a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} x^{a-1}(1-x)^{b-1} \ind_{[0,1]}(x) \]

y

\begin{align*}
\esp[\theta]{X} &= \int_0^1\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} x^{a}(1-x)^{b-1}\,dx = \\
&= \frac{\Gamma(a+b)}{\Gamma(a)}\frac{\Gamma(a+1)}{\Gamma(a+b+1)}\underbrace{\int_0^1\frac{\Gamma(a+b+1)}{\Gamma(a+1)\Gamma(b)} x^{a}(1-x)^{b-1}\,dx}_{=1 \text{ (f. densidad)}} = 
\end{align*}

Sabiendo que $\Gamma(p+1) = p\Gamma(p)$

\[ \frac{\Gamma(a+b)}{\Gamma(a)}\frac{\Gamma(a+1)}{\Gamma(a+b+1)} = 
	\frac{\Gamma(a+b)}{\Gamma(a)}\frac{a\Gamma(a)}{(a+b)\Gamma(a+b)} = \frac{a}{a+b} \]
	
y los estimadores quedan como
	
\begin{gather*}
\hat{a} = \avg{X}\left(\frac{\avg{X}(1-\avg{X})}{s^2}-1\right) \\
\hat{b} = (1-\avg{X})\left(\frac{\avg{X}(1-\avg{X})}{s^2}-1\right) 
\end{gather*}

\subsection{Metodología bayesiana}
\index{Distribución!a priori}

En muchos casos se tiene cierta información a priori, antes de extraer la muestra, sobre la probabilidad de los diferentes valores del parámetro $\theta$. En estos casos se sabe, o se supone, que ciertos intervalos de valores de $\theta$ son \textit{más probables que otros} y se concreta esta información en una \textbf{distribución a priori sobre $\theta$} cuya función de densidad se denota $\pi(\theta)$.

De manera formal, la estadística bayesiana considera que el parámetro es una variable aleatoria y que la información previa se puede expresar a través de la distribución a priori del parámetro.

Entonces, si antes teníamos una v.a. $X\sim f(x;\theta)$, ahora lo que diremos es que $X$ sigue una distribución condicionada por un parámetro: $X\sim f(x|\theta)$.

En este caso, la muestra $X_1,\dotsc,X_n$ contiene información de la muestra y también de nuestro parámetro. Es decir, que podemos considerar la función de distribución de la muestra como \[ \prod_{i=1}^n f(x_i|\theta) \]. Para juntar toda esta información usaremos el Teorema de Bayes:

\begin{theorem}[Teorema\IS de Bayes] Sea $A_1,A_2,\dotsc$ una partición del espacio muestral y sea $B$ un suceso cualquiera. Entonces

\[ \prob{A_i|B} = \frac{\prob{A_i\cap B}}{\prob{B}} = \frac{\prob{B|A_i}\cdot \prob{A_i}}{\sum_j \prob{B|A_j}\cdot \prob{A_j}} \]

Esta formulación se refiere a sucesos probabilísticos. Podemos reformularla con la información a priori del parámetro:

\begin{equation}
\label{eqBayes}
 \pi(\theta | x_1,\dotsc,x_n) = \frac{f(x_1,\dotsc,x_n|\theta)\pi(\theta)}{\displaystyle \int_\Theta f(x_1,\dotsc,x_n|\tau)\pi(\tau)\,d\tau} 
 \end{equation}

donde $\Theta$ es todo el espacio paramétrico. A $ \pi(\theta | x_1,\dotsc,x_n) $ se le denomina \textbf{distribución a posteriori}\index{Distribución!a posteriori}
\end{theorem}

Como $\pi$ es una función de distribución, tenemos que 

\[ \int_\Theta \pi(\theta|x_1,\dotsc,x_n)\,d\theta = 1 \]

para toda posible muestra $(x_1,\dotsc,x_n)$. Estudiaremos entonces la siguiente integral

\[ \int_\Theta \frac{f(x_1,\dotsc,x_n|\theta)\pi(\theta)}{\displaystyle \int_\Theta f(x_1,\dotsc,x_n|\tau)\pi(\tau)\,d\tau} \]

En esta, integral, el término \[ \int_\Theta f(x_1,\dotsc,x_n|\tau)\pi(\tau)\,d\tau \] es constante. Por lo tanto, lo que nos interesará será el numerador, la integral \[ \int_Theta f(x_1,\dotsc,x_n|\theta)\pi(\theta)\,d\theta \] que nos dará la información que necesitamos.

\begin{defn}[Estimador\IS Bayes] Se define, para cada muestra dada $(x_1,\dotsc,x_n)$ como la esperanza de la distribución a posteriori:

\[ T_n(x_1,\dotsc,x_n) = \int_\Theta \theta\pi(\theta|x_1,\dotsc,x_n)\,d\theta \]
\end{defn}


\subsubsection{Ejemplos}

La estadística bayesiana se suele usar para estimar los votantes de un partido político. Por ejemplo, sea $\theta$ la proporción de votantes de un partido $P$, y sea $X$ la v.a. Bernoulli que toma valor 1 cuando un votante elige $P$ y 0 en otro caso. Es decir

\[ \begin{cases}
f(x|\theta) = \theta &\text{si } x=1 \\
f(x|\theta) = 1 - \theta &\text{si } x=0 \\
\end{cases} \]

Entonces tenemos que \[ f(x_1,\dotsc,x_n|\theta) = \prod_{i=1}^n f(x_i|\theta) = \theta^{\sum_{i=1}^n x_i} (1-\theta)^{n -\sum_{i=1}^n x_i} \]

SUponemos que la distribución a priori es una Beta(4,10):

\[ \pi(\theta) = \frac{\Gamma(14)}{\Gamma(4)\Gamma(10)}\theta^3(1-\theta)^9\ind_{[0,1]}(\theta) \]

Así pues, aplicando la fórmula de Bayes (\ref{eqBayes}) nos queda 

\begin{equation}\label{eqE1}
\theta^{\sum x_i}(1-\theta)^{n-\sum x_1} \theta^3 (1-\theta)^9 = \theta^{3+\sum x_i} (1-\theta)^{\sum 9 + \sum x_i} 
\end{equation} y entonces

\[  \pi(\theta | x_1,\dotsc,x_n)  \sim Beta(4 + \sum x_i, 10 + n - \sum x_i) \]

El estimador Bayes es, por lo tanto

\[ T_n = \frac{4 + \sum x_i}{14 + n} = \underbrace{\frac{n}{4 + 10 + n}\avg{x}}_{(A)} + \underbrace{\frac{4+10}{4+10+n}\frac{4}{4+10}}_{(B)} \]

Es decir, pondera las dos información que teníamos: la media de la distribución a priori $(B)$ y la media muestral $(A)$. Si nos fijamos en la expresión, si tenemos un tamaño muestral muy grande ($n\to\infty$) damos mucho más peso a la información de la muestra que a la distribución a priori. Sin embargo, si tenemos menos muestras nuestra distribución a priori influirá más en el resultado.

Con los datos $\sum x_i = 125$ y $n = 1000$, el estimador Bayes toma valor $0.127$, mientras que el e.m.v. valdría $0.125$. Es decir, nuestro estimador bayesiano pondera la información que teníamos previamente y considera que en nuestra distribución a priori era más probable valores más altos.

Curiosamente, en (\ref{eqE1}) hemos pasado de una distribución a priori a una distribución a posteriori fácilmente identificable con una distribución Beta. Esto tiene que ver con el concepto de familias conjugadas.

\subsubsection{Familias conjugadas}

\begin{defn}[Familias\IS conjugadas] Sea $\mathcal{F}$ una familia de distribuciones paramétricas $f(\cdot | \theta),\;\theta\in\Theta$; y sea $\Pi$ una familia de distribuciones a priori $\pi(\theta)$ sobre el parámetro $\theta$. 

Diremos que $\Pi$ es la familia de dsitribuciones a priori conjugada de $\mathcal{F}$ si la distribución a posteriori $ \pi(\theta | x_1,\dotsc,x_n) $ también pertence a $\Pi$ para toda muestra $ ( x_1,\dotsc,x_n) $ y para toda a priori de $\Pi$.
\end{defn}

Tenemos varias familias conjugadas identificadas:
\begin{table}[hbtp]
\centering
\begin{tabular}{c|c}
$\mathcal{F}$ & $\Pi$ \\
\hline 
Binomial & Beta \\ 
\hline 
Normal & Normal \\ 
\end{tabular} 
\caption{Familias conjugadas}
\end{table}

\section{Estimación por intervalos de confianza}

Al igual que en el tema anterior, vamos a obtener información sobre un parámetro desconocido $θ∈Θ$ a partir de una meustra $X_1,…,X_n$. Habíamos logrado una estimación puntual, pero, ¿por qué va a ser válido sólo ese valor? ¿Podría ser válido un valor cercano al estimador?

Este tema responde a esa pregunta: ofrece un intervalo que típicamente contiene a un estimador puntual, de posibles valores para un parámetro. Veremos cómo construir ese intervalo y la información que ofrecen.

\begin{defn}[Intervalo\IS de confianza] Sea una muestra $X_1,…,X_n$ de una v.a. con una función de distribución $F(.;θ)$, con $θ∈Θ⊂ℝ$ un parámetro desconocido. Sean dos estadísticos $T_n^{(1)}(X_1,…,X_n)$ y $T_n^{(2)}(X_1,…,X_n)$ con $T_n^{(1)} < T_n^{(2)}$ y un valor $α∈(0,1)$. Supongamos que se verifica

\[ \prob[θ]{T_n^{(1)}(\sample ) < θ < T_n^{(2)}(\sample) } = 1-α\; ∀θ\]

Entonces para una realización concreta de la muestra $\sample[x]$ se dice que el intervalo $(T_n^{(1)}(\sample[x]) ,T_{n}^{(2)}(\sample[x]))$ es un intervalo de confianza para $θ$ con nivel de confianza $1-α$ y lo denotaremos como

\[ IC_{1-α}(θ) \]
\end{defn}

Probemos esta definición con una muestra $\sample$ de v.a.i.i.d. $N(μ,σ)$ donde $μ$ es un parámetro desconocido y $σ$ es conocida. Se sabe que 

\[ \avg{X} \sim N\left(μ,\frac{σ}{\sqrt{n}}\right) \]

y, tipificando,

\[ \frac{\avg{X}-μ}{\frac{σ}{\sqrt{n}}} \sim~ N(0,1) \]

Por tanto, si para cualquier $α∈(0,1)$, $z_α$ denota el cuantil $1-α$ en la normal estándar ($Φ(z_α) = 1-α$, siendo $Φ$ la función de distribución de la $N(0,1)$) tenemos

\[ \prob[μ]{-z_{α/2} < \frac{\avg{X}-μ}{\frac{σ}{\sqrt{n}}}  < z_{α/2}} = 1-α \]

y, despejando

\[ \prob[μ]{\avg{X} - z_{α/2}\frac{σ}{\sqrt{n}} < μ < \avg{X} + z_{α/2}\frac{σ}{\sqrt{n}}} = 1-α \]

Y por lo tanto, el intervalo

\[ \left(\avg{x} - z_{α/2}\frac{σ}{\sqrt{n}}, \avg{x} + z_{α/2}\frac{σ}{\sqrt{n}}\right)\]

es un \textbf{intervalo de confianza de nivel $1-α$ para $μ$}.

Intuitivamente y en términos frecuentistas, si por ejemplo $1-α=0.95$ y extraemos muchas muestras de una $N(0,1)$ aproximadamente en el 95\% de los casos el intervalo 

\subsection{Intervalos de confianza asintóticos basados en el TCL}

Si $X$ no es normal, sabemos que si $μ$ y $σ$ son finitas, encontes $\avg{X} \sim N\left(μ,\frac{σ}{\sqrt{n}}\right)$ por el TCL (\ref{thmCentral}). Entonces

\[ 1-\alpha = \simeq \prob{-z_{α/2} ≤ \frac{\avg{X} - μ}{\frac{σ}{\sqrt{n}}}≤z_{α/2}} \]

Es decir, obtenemos un intervalo de confianza aproximado si el tamaño de la muestra es grande.

\paragraph{Aplicación: Intervalo de confianza aproximado para una proporción $p$} Sean $\sample$ i.i.d. Bernoulli($p$). Por el TCL

\[ \frac{\avg{X}-p}{\sqrt{\frac{p(1-p)}{n}}} \sim N(0,1) \]

y reemplazando $p$ por su estimador natural $\hat{p} = \avg{X}$ obtenemos que el intervalo de confianza aproximado para $p$ es 

\[ \left( \avg{x} - z_{α/2} \sqrt{\frac{\avg{x}(1-\avg{x})}{n}}, \avg{x} + z_{α/2} \sqrt{\frac{\avg{x}(1-\avg{x}}{n}} \right) \]

\subsection{Método de la cantidad pivotal}
\index{Cantidad!pivotal}
Una metodología general para obtener un intervalo de confianza para $θ$ consiste en encontrar una función $Q(θ;\sample)$, llamada \textbf{cantidad pivotal} cuya distribución no dependa de $θ$ y sea conocida, al menos de modo aproximado. A partir de esta distribución, fijado un valor $α∈(0,1)$ se obtienen dos valores $q_1(α), q_2(α)$ tales que 

\[ \prob[θ]{q_1(α) < Q(θ;\sample) < q_2(α)} = 1-α \]

Despejando $θ$ se obtiene una expresión del tipo 

\[ \prob[θ]{T_n^{(1)}(\sample) < } \]

\subsection{Construcción de intervalos de confianza habituales}

\subsubsection{Distribución $χ^2$}
\index{Distribución!$χ^2$}
Estamos interesados en obtener intervalos de confianza exactos, válidos para cualquier $n$, para $σ^2$ en una normal. Para ello presentaremos una distribución auxiliar que tiene una especial importancia en estadística, la \textbf{distribución $χ_k^2$}, que en realidad es la distribución $Γ(\frac{1}{2}, \frac{k}{2})$. 
Esta distribución surge del estudio de la distribución de las formas cuadráticas $X'AX$. En particular, si $\{Z_n\}$ son vectores aleatorios, entonces
\[ \sum Z_k^2 \sim χ^2 \]

De hecho, aplicando esto a una suma de varias v.a. $\sample$ $S^2$, nos queda que

\[ \frac{(n-1)S^2}{σ^2} \sim χ^2_{n-1} \]

Este resultado proporciona directamente una cantidad pivotal y, en consecuencia, un intervalo de confianza de nivel $1-α$ para $σ^2$:

\[ \left(
	 \frac{(n-1)s^2}{χ^2_{n-1;α/2}},\; \frac{(n-1)s^2}{χ^2_{n-1;1-α/2}}
\right) \]

\subsubsection{Distribución $t$ de Student}
\index{Distribución!$t$ de Student}
Sea $Z\sim N(0,1)$ y $W\sim χ_k^2$. Supongamos que $Z$ y $W$ son independientes. Entonces la distribución de la v.a.

\[ T = \frac{Z}{\sqrt{W/k}} \]

se denomina distribución $t$ de Student con $k$ grados de libertad. Su forma se aproxima a una normal $N(0,1)$.

\todo{Lema de Fisher-Cochran}

\subsection{Intervalos de confianza bayesianos}

En iun problema de inferencia con un enfoque bayesiano, el elemento fundamental para realizar la inferencia es la distribución a posteriori $π(θ|\sample[x])$. A partir de esa distribución se define una \textbf{región creíble}\index{Región!creíble} de nivel $1-α$ como un subconjunto $A⊆Θ$ tal que 

\[ \int_A π(θ|\sample[x])\,dθ=1-α \]

\appendix
\chapter{Anexos}
\section{Condiciones suficientes para permutar la derivada con la integral}

\label{secConds}
Sea una función $p(x,\theta)$ con $x\in \real$ y $\theta \in \mathbb{T}$ donde $\mathbb{T}$ es un intervalo abierto de los reales. Supongamos que
\begin{enumerate}
\item $p(x,\theta)$ es integrable con respecto a $x$ para cada $\theta$ (se cumple automáticamente si $p$ es función de densidad.
\item Para casi todo punto\footnote{Para todo $x$ salvo los que tienen probabilidad 0} existe $\dfrac{∂}{∂\theta} p(x,\theta)\;\forall\theta$.
\item Existe una función integrable $\appl{g}{\real}{\real}$ tal que \[ \abs{\dfrac{∂}{∂\theta} p(x,\theta)}≤g(x)\;\forall\theta \]
\end{enumerate}

Entonces para todo $θ$ 
\[ \dpa{}{\theta}\int_\real p(x,\theta)\,dx=\int_\real \dpa{}{\theta} p(x,\theta)\,dx \]

\section{Distribuciones notables}
\label{secDistr}
\includepdf[pages={2-last}, nup=1x3]{_Distribuciones.pdf}

\chapter{Ejercicios}
\input{EI_Ejercicios.tex}

\newpage
\printindex
\end{document}

